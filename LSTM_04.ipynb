{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./dataset/Google_Stock_Price_Train.csv').values\n",
    "test_data = pd.read_csv('./dataset/Google_Stock_Price_Test.csv').values\n",
    "\n",
    "# parameter\n",
    "input_days = 40\n",
    "epochs = 200\n",
    "batch_size = 250\n",
    "offset = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix data string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 5)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "# the data[4:6] must be fix\n",
    "def str2float(data):\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            data[i] = data[i].replace(',', '')\n",
    "        except AttributeError:\n",
    "            data[i] = data[i]\n",
    "    return np.asarray(data, dtype=np.float)\n",
    "    \n",
    "# fix all data in dataset\n",
    "def fixStr2Float(dataset):\n",
    "    shape = dataset.shape\n",
    "    dataset_t = np.zeros((0, shape[-1]), np.float)\n",
    "    for i, data in enumerate(dataset):\n",
    "        dataset_t = np.append(dataset_t, np.expand_dims(str2float(data), axis=0), axis=0)\n",
    "    return dataset_t\n",
    "\n",
    "# trainsform\n",
    "train_data_t = fixStr2Float(train_data[:, 1:])\n",
    "test_data_t = fixStr2Float(test_data[:, 1:])\n",
    "\n",
    "print(train_data_t.shape)\n",
    "print(test_data_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    __min = 0.\n",
    "    __max = 1.\n",
    "    __range = 1.\n",
    "    __feature_range = (0, 1)\n",
    "    __scale = 1.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getScalerData(self, dataset, offset=0.1, feature_range=(0, 1)):\n",
    "        data_max = np.max(dataset)\n",
    "        data_min = np.min(dataset)\n",
    "        self.__range = (data_max - data_min) * (1 + offset)\n",
    "        self.__min = data_max - self.__range\n",
    "        self.__max = data_min + self.__range\n",
    "        self.__feature_range = feature_range\n",
    "        self.__scale = (feature_range[1] - feature_range[0]) / self.__range\n",
    "        return self.getTransformData(dataset)\n",
    "    def getTransformData(self, dataset):\n",
    "        return (dataset - self.__min) * self.__scale + self.__feature_range[0]\n",
    "    def getInverseData(self, scalerDataset):\n",
    "        return (scalerDataset - self.__feature_range[0]) / self.__scale + self.__min\n",
    "    def getParameter(self):\n",
    "        return self.__min, self.__max, self.__range, self.__feature_range, self.__scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset_global(dataset, day_in=60, day_out=1):\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(dataset[i-day_in:i, :])\n",
    "        y.append(dataset[i:i+day_out, :])\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def genQuteChange(dataset):\n",
    "    return (dataset[1:] - dataset[:-1]) / dataset[:-1]\n",
    "\n",
    "def createDataset_local(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(sc.getScalerData(dataset[i-day_in:i, :], offset=offset))\n",
    "        y.append(sc.getTransformData(dataset[i:i+day_out, :]))\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def createDataset_mix(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x_data = dataset[i-day_in:i, :]\n",
    "        y_data = dataset[i:i+day_out, :]\n",
    "        x_mean = np.mean(x_data)\n",
    "        x.append(sc.getScalerData(x_data, offset=offset))\n",
    "        y.append((y_data - x_mean) / x_mean)\n",
    "    return (np.asarray(x), y_sc.getScalerData(np.asarray(y))), y_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1218, 40, 2) (1218, 1, 1)\n",
      "(60, 40, 2) (60, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# append to a big dataset total\n",
    "dataset = np.append(train_data_t, test_data_t, axis=0)\n",
    "test_count = len(test_data_t)\n",
    "\n",
    "# Split dataset to Volume and Open\n",
    "open_data = dataset[:, :1]\n",
    "volume_data = dataset[:, -1:]\n",
    "\n",
    "# use global norm to volume data (with offset)\n",
    "volume_sc = MinMaxScaler()\n",
    "volume_norm = volume_sc.getScalerData(volume_data, offset=0.05, feature_range=(0, 1))\n",
    "\n",
    "# create dataset\n",
    "volume_dataset = createDataset_global(volume_norm, day_in=input_days)\n",
    "open_dataset, label_sc = createDataset_mix(dataset[:, :1], day_in=input_days, offset=offset)\n",
    "\n",
    "# create total dataset\n",
    "dataset_x = np.append(open_dataset[0], volume_dataset[0], axis=-1)\n",
    "dataset_y = np.append(open_dataset[1], volume_dataset[1], axis=-1)\n",
    "\n",
    "# split to train and test dataset\n",
    "train_x = dataset_x[:-test_count]\n",
    "train_y = dataset_y[:-test_count, :, :1]\n",
    "test_x = dataset_x[-test_count-input_days:]\n",
    "test_y = dataset_y[-test_count-input_days:, :, :1]\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 40, 50)            10600     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 50)            20200     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               256128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                5160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 292,129\n",
      "Trainable params: 292,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (input_days, 2), dropout=0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True, dropout=0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dense(units = 40, activation='relu'))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "model.summary()\n",
    "plot_model(model, 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with Open data and Volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1218 samples, validate on 60 samples\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "1218/1218 [==============================] - 3s 2ms/sample - loss: 0.0962 - val_loss: 0.0411\n",
      "Epoch 2/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0431 - val_loss: 0.0043\n",
      "Epoch 3/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0276 - val_loss: 0.0161\n",
      "Epoch 4/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0211 - val_loss: 0.0051\n",
      "Epoch 5/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0183 - val_loss: 0.0079\n",
      "Epoch 6/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0158 - val_loss: 0.0053\n",
      "Epoch 7/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0142 - val_loss: 0.0056\n",
      "Epoch 8/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0122 - val_loss: 0.0047\n",
      "Epoch 9/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0118 - val_loss: 0.0049\n",
      "Epoch 10/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0112\n",
      "Epoch 00010: saving model to ./model/LSTM_04_check_point/cp-0010.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "1218/1218 [==============================] - 1s 603us/sample - loss: 0.0116 - val_loss: 0.0047\n",
      "Epoch 11/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 12/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0103 - val_loss: 0.0041\n",
      "Epoch 13/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0103 - val_loss: 0.0038\n",
      "Epoch 14/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 15/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0098 - val_loss: 0.0040\n",
      "Epoch 16/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0087 - val_loss: 0.0038\n",
      "Epoch 17/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0089 - val_loss: 0.0038\n",
      "Epoch 18/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0095 - val_loss: 0.0036\n",
      "Epoch 19/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0096 - val_loss: 0.0033\n",
      "Epoch 20/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00020: saving model to ./model/LSTM_04_check_point/cp-0020.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 513us/sample - loss: 0.0090 - val_loss: 0.0040\n",
      "Epoch 21/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0093 - val_loss: 0.0035\n",
      "Epoch 22/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0091 - val_loss: 0.0031\n",
      "Epoch 23/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0089 - val_loss: 0.0032\n",
      "Epoch 24/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 25/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0090 - val_loss: 0.0029\n",
      "Epoch 26/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 27/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 28/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0085 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0084 - val_loss: 0.0040\n",
      "Epoch 30/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0081\n",
      "Epoch 00030: saving model to ./model/LSTM_04_check_point/cp-0030.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0080 - val_loss: 0.0029\n",
      "Epoch 31/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 32/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0083 - val_loss: 0.0030\n",
      "Epoch 33/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 34/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 35/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 36/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 37/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 38/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0077 - val_loss: 0.0026\n",
      "Epoch 39/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 40/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0083\n",
      "Epoch 00040: saving model to ./model/LSTM_04_check_point/cp-0040.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 41/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 42/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0079 - val_loss: 0.0027\n",
      "Epoch 43/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0075 - val_loss: 0.0028\n",
      "Epoch 44/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 45/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 46/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0082 - val_loss: 0.0024\n",
      "Epoch 47/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 48/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0074 - val_loss: 0.0031\n",
      "Epoch 49/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 50/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00050: saving model to ./model/LSTM_04_check_point/cp-0050.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 577us/sample - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 51/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 52/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0066 - val_loss: 0.0026\n",
      "Epoch 53/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0073 - val_loss: 0.0023\n",
      "Epoch 54/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 55/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0064 - val_loss: 0.0023\n",
      "Epoch 56/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 57/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 58/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0061 - val_loss: 0.0023\n",
      "Epoch 59/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 60/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00060: saving model to ./model/LSTM_04_check_point/cp-0060.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 61/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0064 - val_loss: 0.0021\n",
      "Epoch 62/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 63/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 64/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 65/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 66/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 67/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 68/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 69/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 70/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00070: saving model to ./model/LSTM_04_check_point/cp-0070.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 551us/sample - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 71/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 72/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 73/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 74/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 75/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 76/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 77/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 78/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 79/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 80/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00080: saving model to ./model/LSTM_04_check_point/cp-0080.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 552us/sample - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 81/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 82/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 83/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 84/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 85/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 86/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 87/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 88/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 89/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 90/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00090: saving model to ./model/LSTM_04_check_point/cp-0090.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 91/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 92/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 93/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 94/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 95/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 96/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 97/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 98/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 99/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 100/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00100: saving model to ./model/LSTM_04_check_point/cp-0100.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 101/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 102/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 103/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 105/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 106/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 107/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 108/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 109/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 110/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00110: saving model to ./model/LSTM_04_check_point/cp-0110.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 111/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 112/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 113/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 114/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 115/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 116/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 117/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 118/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 119/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 120/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00120: saving model to ./model/LSTM_04_check_point/cp-0120.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 121/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 122/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 123/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 124/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 125/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 126/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 127/200\n",
      "1218/1218 [==============================] - 1s 436us/sample - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 128/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 129/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 130/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00130: saving model to ./model/LSTM_04_check_point/cp-0130.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 131/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 132/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 133/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 134/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 135/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 136/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 137/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 138/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 139/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 140/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00140: saving model to ./model/LSTM_04_check_point/cp-0140.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 141/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 142/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 143/200\n",
      "1218/1218 [==============================] - 1s 500us/sample - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 144/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 145/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 146/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 147/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 148/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 149/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 150/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00150: saving model to ./model/LSTM_04_check_point/cp-0150.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 151/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 152/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 153/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 154/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 155/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 156/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 157/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 158/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 159/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 160/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00160: saving model to ./model/LSTM_04_check_point/cp-0160.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 161/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 162/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 163/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 164/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 165/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 166/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 167/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 168/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 169/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 170/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00170: saving model to ./model/LSTM_04_check_point/cp-0170.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 539us/sample - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 171/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 172/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 173/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 174/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 175/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 176/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 177/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 178/200\n",
      "1218/1218 [==============================] - 1s 513us/sample - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 179/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 180/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00180: saving model to ./model/LSTM_04_check_point/cp-0180.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 526us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 181/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 182/200\n",
      "1218/1218 [==============================] - 1s 487us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 183/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 184/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 185/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 186/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 187/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 188/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 189/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 190/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00190: saving model to ./model/LSTM_04_check_point/cp-0190.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 513us/sample - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 191/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 192/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 193/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 194/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 195/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 196/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 197/200\n",
      "1218/1218 [==============================] - 1s 475us/sample - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 198/200\n",
      "1218/1218 [==============================] - 1s 462us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 199/200\n",
      "1218/1218 [==============================] - 1s 449us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 200/200\n",
      "1000/1218 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00200: saving model to ./model/LSTM_04_check_point/cp-0200.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001ED84656588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1218/1218 [==============================] - 1s 552us/sample - loss: 0.0027 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "name = 'LSTM_04'\n",
    "checkpoint_file = './model/' + name + '_check_point/cp-{epoch:04d}.ckpt'\n",
    "try:\n",
    "    os.mkdir('./model/' + name + '_check_point/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# get what we want\n",
    "train_input = train_x\n",
    "train_label = train_y\n",
    "test_input = test_x\n",
    "test_label = test_y\n",
    "train_label = np.squeeze(train_label, axis=1)\n",
    "test_label = np.squeeze(test_label, axis=1)\n",
    "\n",
    "# create callback function\n",
    "cp_callback = ModelCheckpoint(checkpoint_file, save_weights_only=True, verbose=1, period=10)\n",
    "\n",
    "# train the model\n",
    "train = model.fit(train_input, train_label, epochs=epochs, batch_size=batch_size, callbacks=[cp_callback], \n",
    "                  validation_data=(test_input, test_label))\n",
    "\n",
    "# save model\n",
    "model.save('./model/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XmYXGWd9//3t6p637fsIelskIUQIIRdEGQJyiaIoCDjOAM8iuP8FBQelVHGccSZcXtEEQdmEARBEI0SJOyiQCAJCdlI0lm7s3a6k07vS9X9++M+vaS7qrsTUt1N+vO6rr666pxTVXedrj6furdzzDmHiIhIb0KDXQARERn6FBYiItInhYWIiPRJYSEiIn1SWIiISJ8UFiIi0ieFhcj7ZGb/a2bf6ee2W8zsI+/3eUQGmsJCRET6pLAQEZE+KSxkWAiaf243s3fNrN7MHjCzkWb2rJnVmtkLZlbQZfvLzGy1me03s1fMbHqXdSea2bLgcY8D6d1e62Nmtjx47OtmNvswy/yPZlZmZtVmtsDMxgTLzcx+aGZ7zKwmeE+zgnWXmNmaoGzbzey2w9phIt0oLGQ4uQq4AJgGXAo8C/xfoBj/v/BPAGY2DXgM+GegBFgI/NHMUs0sFfg98DBQCPw2eF6Cx54EPAjcDBQBvwAWmFnaoRTUzM4D/h24BhgNbAV+E6y+EPhQ8D7ygU8CVcG6B4CbnXM5wCzgpUN5XZFEFBYynPw/59xu59x24DVgsXPuHedcM/A0cGKw3SeBZ5xzzzvnWoH/BDKAM4DTgBTgR865Vufck8DbXV7jH4FfOOcWO+eizrmHgObgcYfi08CDzrllQfnuBE43s4lAK5ADHAeYc26tc25n8LhWYIaZ5Trn9jnnlh3i64rEpbCQ4WR3l9uNce5nB7fH4L/JA+CciwHlwNhg3XZ38Bk4t3a5PQH4StAEtd/M9gPjg8cdiu5lqMPXHsY6514CfgrcC+w2s/vNLDfY9CrgEmCrmb1qZqcf4uuKxKWwEOlpB/6gD/g+AvwBfzuwExgbLGt3TJfb5cC/Oefyu/xkOucee59lyMI3a20HcM79xDl3MjAT3xx1e7D8befc5cAIfHPZE4f4uiJxKSxEenoC+KiZnW9mKcBX8E1JrwNvAG3AP5lZxMw+Dszr8thfAreY2alBR3SWmX3UzHIOsQyPAp81szlBf8d38c1mW8zslOD5U4B6oAmIBn0qnzazvKD57AAQfR/7QaSDwkKkG+fcOuB64P8Be/Gd4Zc651qccy3Ax4G/A/bh+zd+1+WxS/D9Fj8N1pcF2x5qGV4Evgk8ha/NTAauDVbn4kNpH76pqgrfrwJwA7DFzA4AtwTvQ+R9M138SERE+qKahYiI9ElhISIifVJYiIhIn5IaFmZ2sZmtC05ZcEec9R8KTpvQZmZXd1t3o5ltCH5uTGY5RUSkd0nr4DazMLAef3qFCvws1+ucc2u6bDMRP7LjNmBBMBsWMysElgBzAQcsBU52zu1L9HrFxcVu4sSJyXgrIiJHraVLl+51zpX0tV0kiWWYB5Q55zYBmNlvgMuBjrBwzm0J1sW6PfYi4HnnXHWw/nngYvz5euKaOHEiS5YsOZLlFxE56pnZ1r63Sm4z1Fj8bNZ2FcGyI/ZYM7vJzJaY2ZLKysrDLqiIiPQumWFhcZb1t82rX491zt3vnJvrnJtbUtJnLUpERA5TMsOiAn8+nXbj8Oe7SfZjRUTkCEtmn8XbwFQzK8Wf/Oxa4FP9fOxzwHe7XIzmQvwpmkVEjqjW1lYqKipoamoa7KIkVXp6OuPGjSMlJeWwHp+0sHDOtZnZrfgDfxh/bv7VZnY3sMQ5t8DMTsFfR6AAuNTMvu2cm+mcqzazf6XzOgF3t3d2i4gcSRUVFeTk5DBx4kQOPpnw0cM5R1VVFRUVFZSWlh7WcySzZoFzbiH+KmNdl93V5fbb+CameI99EH/FMRGRpGlqajqqgwLAzCgqKuL9DATSDG4RGfaO5qBo937f47APi501jfxg0To2VdYNdlFERIasYR8Wew4085OXythSVT/YRRGRYWj//v387Gc/O+THXXLJJezfvz8JJYpv2IdFOOSrZm1RXddDRAZeorCIRnu/yOHChQvJz89PVrF6SGoH9wdBe1jEdBEoERkEd9xxBxs3bmTOnDmkpKSQnZ3N6NGjWb58OWvWrOGKK66gvLycpqYmvvSlL3HTTTcBnac4qqurY/78+Zx11lm8/vrrjB07lj/84Q9kZGQc0XIqLNprFjGFhchw9+0/rmbNjgNH9DlnjMnlXy6dmXD99773PVatWsXy5ct55ZVX+OhHP8qqVas6hrg++OCDFBYW0tjYyCmnnMJVV11FUVHRQc+xYcMGHnvsMX75y19yzTXX8NRTT3H99Uf2iroKiyAsogoLERkC5s2bd9BciJ/85Cc8/fTTAJSXl7Nhw4YeYVFaWsqcOXMAOPnkk9myZcsRL9ewD4uIwkJEAr3VAAZKVlZWx+1XXnmFF154gTfeeIPMzEzOPffcuDPN09LSOm6Hw2EaGxuPeLmGfQd3yNQMJSKDJycnh9ra2rjrampqKCgoIDMzk/fee48333xzgEvXSTWLcNDBrbAQkUFQVFTEmWeeyaxZs8jIyGDkyJEd6y6++GLuu+8+Zs+ezbHHHstpp502aOUc9mERVs1CRAbZo48+Gnd5Wloazz77bNx17f0SxcXFrFq1qmP5bbfddsTLB2qG0tBZEZF+UFhoUp6ISJ8UFqpZiIj0adiHRSTkd4H6LEREEhv2YRFkheZZiIj0YtiHRXvNQmEhIpLYsA+LoMtCzVAiMigO9xTlAD/60Y9oaGg4wiWKb9iHhZkRDpkm5YnIoPighMWwn5QHfmKeahYiMhi6nqL8ggsuYMSIETzxxBM0Nzdz5ZVX8u1vf5v6+nquueYaKioqiEajfPOb32T37t3s2LGDD3/4wxQXF/Pyyy8ntZwKC/zwWQ2dFRGevQN2rTyyzznqeJj/vYSru56ifNGiRTz55JO89dZbOOe47LLL+Mtf/kJlZSVjxozhmWeeAfw5o/Ly8vjBD37Ayy+/THFx8ZEtcxzDvhkKfFhoUp6IDLZFixaxaNEiTjzxRE466STee+89NmzYwPHHH88LL7zA1772NV577TXy8vIGvGyqWeDDIhqLDXYxRGSw9VIDGAjOOe68805uvvnmHuuWLl3KwoULufPOO7nwwgu56667BrRsqlngr2kRVTOUiAyCrqcov+iii3jwwQepq6sDYPv27ezZs4cdO3aQmZnJ9ddfz2233cayZct6PDbZVLMAQiHTPAsRGRRdT1E+f/58PvWpT3H66acDkJ2dzSOPPEJZWRm33347oVCIlJQUfv7znwNw0003MX/+fEaPHp30Dm5zR8k36rlz57olS5Yc1mNP//cXOXtqMd+/+oQjXCoRGerWrl3L9OnTB7sYAyLeezWzpc65uX09Vs1Q+KvlaeisiEhiCgv81fI0KU9EJDGFBZqUJzLcHS3N8b15v+9RYYEm5YkMZ+np6VRVVR3VgeGco6qqivT09MN+Do2GQpPyRIazcePGUVFRQWVl5WAXJanS09MZN27cYT9eYUH7pDyFhchwlJKSQmlp6WAXY8hTMxSalCci0pekhoWZXWxm68yszMzuiLM+zcweD9YvNrOJwfIUM3vIzFaa2VozuzOZ5dSkPBGR3iUtLMwsDNwLzAdmANeZ2Yxum30O2OecmwL8ELgnWP4JIM05dzxwMnBze5AkQ0RhISLSq2TWLOYBZc65Tc65FuA3wOXdtrkceCi4/SRwvpkZ4IAsM4sAGUALcCBZBdWkPBGR3iUzLMYC5V3uVwTL4m7jnGsDaoAifHDUAzuBbcB/Ouequ7+Amd1kZkvMbMn7GcmgSXkiIr1LZlhYnGXdj8iJtpkHRIExQCnwFTOb1GND5+53zs11zs0tKSk57IKqZiEi0rtkhkUFML7L/XHAjkTbBE1OeUA18Cngz865VufcHuBvQJ8nujpcEU3KExHpVTLD4m1gqpmVmlkqcC2woNs2C4Abg9tXAy85P41yG3CeeVnAacB7ySqoJuWJiPQuaWER9EHcCjwHrAWecM6tNrO7zeyyYLMHgCIzKwO+DLQPr70XyAZW4UPnf5xz7yarrJqUJyLSu6TO4HbOLQQWdlt2V5fbTfhhst0fVxdvebJEQiFNyhMR6YVmcKNJeSIifVFYoEl5IiJ9UVjgh84qLEREElNYoJqFiEhfFBb4PgtNyhMRSUxhgSbliYj0RWFB+6S82GAXQ0RkyFJYoEl5IiJ9UVigK+WJiPRFYYEm5YmI9EVhgYbOioj0RWGBn5QXc+DUFCUiEpfCAl+zAFS7EBFJQGGB77MANDFPRCQBhQWdNQtNzBMRiU9hgZ9nAapZiIgkorCgMyyiurSqiEhcCgu6dHCrGUpEJC6FBZ0d3BoNJSISn8ICDZ0VEemLwgI/KQ8UFiIiiSgsgEhYYSEi0huFBZ01Cw2dFRGJT2EBREJ+N6hmISISn8KCLvMsFBYiInEpLFBYiIj0RWGBJuWJiPRFYUHXSXmxQS6JiMjQpLCg66S8QS6IiMgQpbCg69BZpYWISDwKCzon5SkrRETiU1igmoWISF+SGhZmdrGZrTOzMjO7I876NDN7PFi/2Mwmdlk328zeMLPVZrbSzNKTVU6dSFBEpHdJCwszCwP3AvOBGcB1Zjaj22afA/Y556YAPwTuCR4bAR4BbnHOzQTOBVqTVVbNsxAR6V0yaxbzgDLn3CbnXAvwG+DybttcDjwU3H4SON/MDLgQeNc5twLAOVflnIsmq6AKCxGR3iUzLMYC5V3uVwTL4m7jnGsDaoAiYBrgzOw5M1tmZl+N9wJmdpOZLTGzJZWVlYddUE3KExHpXTLDwuIs6340TrRNBDgL+HTw+0ozO7/Hhs7d75yb65ybW1JSctgF1ZXyRER6l8ywqADGd7k/DtiRaJugnyIPqA6Wv+qc2+ucawAWAiclq6Dq4BYR6V0yw+JtYKqZlZpZKnAtsKDbNguAG4PbVwMvOecc8Bww28wygxA5B1iTrILqehYiIr2LJOuJnXNtZnYr/sAfBh50zq02s7uBJc65BcADwMNmVoavUVwbPHafmf0AHzgOWOiceyZZZe2clKewEBGJJ2lhAeCcW4hvQuq67K4ut5uATyR47CP44bNJF1bNQkSkV5rBjYbOioj0RWGBLqsqItIXhQUQZIXCQkQkAYUFXWoWmpQnIhKXwgLVLERE+qKwQH0WIiJ9UVgAwWAoDZ0VEUlAYQGYGeGQaVKeiEgCCotA2Ew1CxGRBBQWgXDIiOqyqiIicSksApGQEVVWiIjEpbAIhFSzEBFJqF9hYWZfMrNc8x4Irl53YbILN5AiIdOkPBGRBPpbs/h759wB/LWxS4DPAt9LWqkGga9ZKCxEROLpb1i0X/70EuB/nHMriH9J1A+siMJCRCSh/obFUjNbhA+L58wsBziqGvhDGjorIpJQfy9+9DlgDrDJOddgZoX4pqijRiSsSXkiIon0t2ZxOrDOObffzK4HvgHUJK9YA0+T8kREEutvWPwcaDCzE4CvAluBXyWtVIMgrD4LEZGE+hsWbc45B1wO/Ng592MgJ3nFGngKCxGRxPrbZ1FrZncCNwBnm1kYSElesQaewkJEJLH+1iw+CTTj51vsAsYC/5G0Ug0CTcoTEUmsX2ERBMSvgTwz+xjQ5Jw7qvosNClPRCSx/p7u4xrgLeATwDXAYjO7OpkFG2ialCciklh/+yy+DpzinNsDYGYlwAvAk8kq2EDTpDwRkcT622cRag+KQNUhPPYDIRJWzUJEJJH+1iz+bGbPAY8F9z8JLExOkQZHyBQWIiKJ9CssnHO3m9lVwJn4Ewje75x7OqklG2DqsxARSay/NQucc08BTyWxLIMqHAopLEREEug1LMysFoh3BDXAOedyk1KqQRAJGa26rqqISFy9hoVz7qg6pUdvMlPDNLZGB7sYIiJD0lE1oun9yEwL09CisBARiafffRZHrVgM2prIToH65rbBLo2IyJCU1JqFmV1sZuvMrMzM7oizPs3MHg/WLzazid3WH2NmdWZ2W9IKuWMZfHc00xuW0NwWo039FiIiPSQtLIIz094LzAdmANeZ2Yxum30O2OecmwL8ELin2/ofAs8mq4wAhHzlKiPsQ6JB/RYiIj0ks2YxDyhzzm1yzrUAv8FfD6Ory4GHgttPAuebmQGY2RXAJmB1EssIYX+m9cywH/SlpigRkZ6SGRZjgfIu9yuCZXG3cc614S/VWmRmWcDXgG/39gJmdpOZLTGzJZWVlYdXypAPi/SgZlHfrJqFiEh3yQwLi7Os+5yNRNt8G/ihc66utxdwzt3vnJvrnJtbUlJyeKUMB81QoaAZqkU1CxGR7pI5GqoCGN/l/jhgR4JtKswsAuQB1cCpwNVm9n0gH4iZWZNz7qdHvJRBzSItpJqFiEgiyQyLt4GpZlYKbAeuBT7VbZsFwI3AG8DVwEvBtb7Pbt/AzL4F1CUlKADCqQCkh3xIqGYhItJT0sLCOddmZrcCzwFh4EHn3GozuxtY4pxbADwAPGxmZfgaxbXJKk9C4W41C03MExHpIamT8pxzC+l2KnPn3F1dbjfhr77X23N8KymFaxcMnU1rr1loNJSISA863UdQs0g1X7OoU1iIiPSgsAg6uFNo77NQM5SISHcKi1AYgLBrIzUSol4d3CIiPSgszHztItZKVmqYBg2dFRHpQWEBvt8i2kpWWkQ1CxGROBQW4MMi1kZWakQ1CxGROBQW4Juhoi1kpoVVsxARiUNhAZ3NUKkRnXVWRCQOhQUEHdxtZKbq0qoiIvEoLMCfeVYd3CIiCSksoGPobKaGzoqIxKWwgKDPoo1s1SxEROJSWEAwdLaVzNQITa0xorHu12gSERneFBYQDJ1tJSvNn/pDtQsRkYMpLKBj6Gxmqj9dufotREQOprAAf02LmGoWIiKJKCxANQsRkT4oLKDzrLOqWYiIxKWwgGBSnj+RIECDwkJE5CAKC+hRs6htUliIiHSlsAAIp0K0leLsNAAqa5sHuUAiIkOLwgJ8M1SsjbyMFDJSwuzY3zTYJRIRGVIUFtBxPQszY3R+OrsONA52iUREhhSFBXQMnQUYk5ehmoWISDcKC+i4ngXA6Lx0dtaoZiEi0pXCAjquZwEwOj+DPbXNtEZjg1woEZGhQ2EBHUNnwdcsnIPdB9QUJSLSTmEBfuisi0Esxui8dAB21SgsRETaKSzAN0MBxFoZk58BwA6FhYhIB4UF+GYogGhrR81i5351couItFNYgB86CxBtISc9hZy0CDtVsxAR6aCwAH89C+gYPjsqL50dqlmIiHRIaliY2cVmts7Myszsjjjr08zs8WD9YjObGCy/wMyWmtnK4Pd5ySxnZ82ic/isahYiIp2SFhZmFgbuBeYDM4DrzGxGt80+B+xzzk0BfgjcEyzfC1zqnDseuBF4OFnlBDr7LILhsxMKM9m8t542zbUQEQGSW7OYB5Q55zY551qA3wCXd9vmcuCh4PaTwPlmZs65d5xzO4Llq4F0M0tLWkk7aha+GerUSYXUNbfx7vaapL2kiMgHSTLDYixQ3uV+RbAs7jbOuTagBijqts1VwDvOueSdNzx8cM3i9Em+CK+X7U3aS4qIfJAkMywszjJ3KNuY2Ux809TNcV/A7CYzW2JmSyorKw+7oF2HzgIUZacxfXQufyurOvznFBE5iiQzLCqA8V3ujwN2JNrGzCJAHlAd3B8HPA18xjm3Md4LOOfud87Ndc7NLSkpOfySdqtZAJw5uYil2/bR1Bo9/OcVETlKJDMs3gammlmpmaUC1wILum2zAN+BDXA18JJzzplZPvAMcKdz7m9JLKPXPnQ22iUsphTT0hZjyZZ9SX95EZGhLmlhEfRB3Ao8B6wFnnDOrTazu83ssmCzB4AiMysDvgy0D6+9FZgCfNPMlgc/I5JV1u5DZwHmlRaSGg7x6vo9SXtZEZEPikgyn9w5txBY2G3ZXV1uNwGfiPO47wDfSWbZDhLq2QyVlRbh1EmFvPjeHr7+0e4jfkVEhhfN4IYeQ2fbnX/cCDZV1rN5b/0gFEpEZOhQWMDBHdxNB8D5AVnnTx8JwItrdw9WyUREhgSFBXQ2Qx3YAf8xGTa9AsD4wkymjczmpffUbyEiw5vCAjprFtWbIdoCVWUdqy6cMYo3N1WxraphkAonIjL4FBbQOXS2IZix3bS/Y9UNp08gEgrxy9c2DULBRESGBoUFdNYs6oNZ4I2dYTEyN50rTxzLE0vK2VuXvDOOiIgMZQoL6OyzqA9qFl3CAuCmcybREo3x6OJtA1wwEZGhQWEBnTWLhuBcUE0Hh8XkkmxOKy3id8sqcK776a1ERI5+Cgvo7LNIULMAuPLEsWypamB5ec91IiJHO4UFQDjV/44GfRJNPQNh/vGjSIuEePqd7QNYMBGRoUFhAZ3NUO3i1Cxy0lO4YMZInlpawf/+bTP1zW09thEROVopLABCYQ66tEacmgXA7Rcdy8yxeXzrj2s48e7n+cKjy2hp06VXReTop7Bo17V20VJ30Blo200oyuLxm07jyVtO5+q543jm3Z38Xs1SIjIMKCzahbo1RTXFv/62mTF3YiH/dsUsZo7J5WevlNEWjVHT0EosppFSInJ0Uli0CwcjoiIZ/necfouuzIwvnjeFLVUNnHnPS5xw9yKmfuNZ/mvRuiQXVERk4CX1ehYfKO01i/xjYO+6hP0WXV04YxQfPraE5rYYN54xkaVb9vHTl8s4bVIRv3xtE6PzMvjulbMwM1qjMZ55dye7DjQxdUR2xxltRUQ+CBQW7dr7LAom+LBo7PtyqqGQ8T+fnddxv7aplY/84FWuf2Bx+1nOOW1SIedPH8nnf72Mv6yv7Nj20hPGUNvUSmVtM3MnFHDqpCJOn1REQVYqNQ2trNtdyykTCzCz7i8rIjLgFBbt2sMif4L/3UczVDw56Sncffksbv/tCr531Wx++dom7nhqJSFbSVNbjO9eeTyXnjCaX7y6iXtfKWNMXgYTijJ5YkkFD72xlazUMP/fBdP41Rtb2VbdwMkTCvjsmRM5YVw+5dUNYDC+IJPxhZlH8I2LiPRNYdEu1KVmAb4ZKtracw5GHy6aOYoLpo8kFDJmjM7lm39YRWlxFpeeMIZTJhYCcNtFx3LzOZPISo0QChktbTFWbt/PPX9ex3eeWUtRVipfuWAajyzeyq2PvtPjNa49ZTxfvmAaoZDxr39aw86aJuaMz+ecaSXMKy0kJRy/K8o5x91/WsNfN+zlvhtOZnJJdo9t9tY18/ya3VTsa+BL508jNaJuLREBO1rOdTR37ly3ZMmSw3+Ce0+FyvfgmofhiRvgtM/DO4/ApT+CWVcduYL2Ihpz/HHFDk4pLWRsfgbRmGPZtn2s313LxKIsDHh53R4e/NsWYs6RmRKmNeaYPjqXtTsP0NIW45jCTL5/9WxOLS2kNerYvLeeJVurqaxtpry6kaeWVZCeEiI9JcyInDTqm6N87qxSPjZ7NEu37uP2J9+lLphw+G9XzuLTp05gzY4DfPWpFWSmRPjXK2axZmcNI3PSOWNK8YDsFxFJHjNb6pyb2+d2CovAz8+C3Svhs3+GRz4OGYVwoAKO+xhc++sjV9AjYGNlHc+8u5NNlXXccu5kjhuVS0NLG6+sq+R7z77HtuoGUsMhYs7R1m0472fPnMjfnTGRO55aSWokRFNrlMWbqzvWnzA+n+9eOYtv/H4Vu2qa+MKHp/DtP64mLyOV5rYotU0+SNJTQjzzT2fz6OJtVOxr4N8/PpvCrNQB3Q8i8v4pLA7V/efCjnfg/7wBj1wFtTv88tQc+OomiHwwDoQNLW08tbSC7fubCIdgyohsThxfwNiCDOqb28jP7Pk+3tm2j5Xba4jFHNedegxpkTCvbajkhgfeAuDsqcX8+NoTaWyN8vSyCo4dlcttv11BzDlqm9oIGYzJz+C7Vx5PzDm+88xactIjnH/cCP7PuVMIh4zGlihR58hICRMOqdNeZKjob1ioz6Jde59Feh5k5PuwSM/zk/PKF0Pp2YNbvn7KTI1ww+kT466LFxQAJx5TwInHFBy07KwpxVwzdxzZaSnceclxHf0gt543FYDvXDGLLz72Dv9wVikfO2EMX3xsGZ950IfLlBHZhMz4z0XrWV5eQ0NLG69v9Kd/N4PS4izuv2Eu4FiwYifXn3oMI3LTj8C7F5FkUVi0C3cJi/R8f/uML8Ir98D6P4OFYPQJkNazU/hoZGZ8/+oTEq6/9IQxnFpaSElOGmbGC18+h8ffLmdvXQufP3cy6Slh/vu1TXznmbUUZqXyxfOmkJMeoa45yqOLt3Lt/W/S0NJGQ0uUB/+6mRtOn8DssXn86d2djC3I4PaLjiUlHOL1sr3c8buV5GZEuHjmKL7w4SkaTiwyCBQW7cIpYGFIzfI1C/D9FZtehTd+6n+mfAQ+9VsIaYQQcFBtIC0S5jPdajT/cPYkzpxSzNiCDHLTO0eVfWz2aD71y8UcOyqHO+dP579f28T9f9lENObISYtQ29zGivL9nDG5mJ+/WsbovAwyUyL856L17Kxp4qsXHUdeZgrNbVEWrtxJeXUj82eNYsqIbAWJSJIoLNqFUnytwgzyxkPeMVBynK9dZBZC7lh482fw9M3Q1gg5o2HaRTDpPIVHL6aPzu2xbNrIHP76tQ+TFglhZswrLaS6voW1Ow9w8oQC/rhiB3f/cQ2LN1dz3KgcHv7cqRRnp3LPn9dx36sb+fXibWSmhonGHM3BWX9/8Px6UsMhCrNSKcpOpSg7jdKiTD57ZikZqWHe2bYf5xzrd9expaqey+aM4dxpJQeFSyzm+P5z69i+v5F/vXxmwmY7keFIHdztHrsO9qyFLy2H5jpoqYecLqfkcA5+dxOsfMIHScNeaG2Akulw0mdg6gVQPBU2vQJv3AtzPg3TL0scJM75YJK4nHPUNbd1zEVpX/b6xipW76hhz4FmHHDOtBKOG53DotW7Kd/XQHVdC3vrmqmub2Hd7lpa2mJ0HRBmBjlpEQ40tZESNtIjYdJTw0wqzqJ1FRVMAAAU4UlEQVQgM5U/r95FyGB0XgZjCzKoDbYrzEplVG46o/LSGZWbzs6aJh59axtnTy3mjouP43fvbGdUbjqXnjCGvXXNvL2lmi1765lXWsTscXkdwZjovfqyJf481DW3sWVvPTPH5Kr2JEeURkMdqiUPQk0FnH9X4m2ibVC7E/LHQ1szrPkD/O3HsHuVXz/mJNi5wl+mNdoMhZNh5hUQbYHMIphxORROgvWL4Hf/ACdcBx/5NqQEzTnOwYZFMHYuZBX1fP2yF+HV78PVD0Le2MN/r71Z+ycomgIjjkvO8w+gPbVNPPzGVtJTwpwxuYjUSIix+RlkpkZYuHIn63fX0tgapbElyltbqtlUWc8t50zmopkj+c4zawmbkZuRQjQWY29dCztrmthb19zx/CdPKGDZNn9amPZ/o5z0SMfw4q6yUsN8bPYYTptcSHV9K8vL97Opso599S1U1bcwKi+db106k/qWNt7cVEV5dSPzSgs5Z1oJz63exa/e2EpNYytTR2QzIjeNA41tXD5nDOceW0JGaoR99S1Ewsbo3AzyMlOCMjneKd9Pxb5GirNSOWlCAekp4V73WWNLlL11zTpLwDCisBhI+7b64Fj6vzByBlz2U9jwvL+/9a8QTuu8ZOuo42HPe5A9Ag5sh+Jj4aLv+r6SV++BTS/DyOPhs89AWi7U7oLmWsgqhp+dBnW7YdK5cP3Th9/8teF5Hzon/x2c+OnO5VUb4adzYcQMuPm1zuev3gxbXvO1qPGnHPZuGsqcc+ypbWZkH6OyWtpi7KltwswYm5/BS+/t5k8rdvL3Z5WytaqBF9/bzYzRuZwysZAJRZm8vrGKzXvr2bK3nj+9u5PG1igAI3PTmD46l6KsNAqzUnhx7R427a0HfM1nZF46ZXvqAF8bOv+4kZwzrZjfL99BW9Q3va2oiH8a/bOnFjOuIJO/rK9k+/7GjuUFmSlMH53Le7tqmViUyexx+aRGQkRCRkNLlDU7D7B8235aojFOPCafmWNyyUgJc+kJY2hqjfHXDZVEnWNETjq5GRF+9vJG6prbuOLEsYzMSSMzNcK4wgxOOsaHknOOHTVN7KppBPz+ioSNv27Yy6SSLGaNyWNFxX5WlO9nX0MrV5w4ltLiLADqm9sIh6zPcOtNNOao2NdAQ0uU40bl8E75fp54u5y8jBQunDmKkycU4Jxjb1AbLc5OoygrtaMmO1woLIaK1kaIpENNuQ+U1U9DWg584iHYvgSe+Qrs2+K3TcmEuX8Pi++D7FH+IkztZ79Nz/NNY6f8Iyz+OUw+D7JK/KzzzGJfa0nLgeyRMO4UaK33IVa7E3LH+DJULIFlv4LyN/39aAtc+G8Qa4XSD8HiX8CKx/zrXfWA75P5853wzsN+WWoO3PQKFE8ZuP23ezW8eLev8Y2cOXCvmwQHghNH5mWkUJSVelBzUlNrlD8s3874wkxOLS0iHDJWba9hzc4DnDOtJG6Ird5RQ9meOhpaohRkphCNwbpdB/jt0grqmto4dVIR82eN4vhxeZRXN/Dk0grK9zVw3KhcNlbWUba7jraYIxpzpISNqSNzOGViAUXZaTy9bDuVdc3UNbd1XA3SDMJmHRM9J5VkMb4gk79sqKTrYSQ3PcKxo3JYv7uOmsaeFxFr170WZgYTi7IIGWzeW0/IfJnCITCMjBTfZLivvoWNlXWcMbmYOePzWLm9hoLMVPIzU9lV04iZcaCxlcWbqzvORjBlRDab99aTHgnRGnW0xWJ8/KRxvLGx6qBATY2EGJmbRko4xMicdE6fXMT63bXUNLZy4vh8Glqi7G9sJTc9hZMnFDB7XB4bK+tITwkzqSSLETnplFc3sGzbPuaMzycjJcy26gaq6ltYv6uWzVX1XD5nLGdNKWbXgSbeLd9PfUuUMfnpLN5UjQNu+tAkGluirN5Rg5mxq6aRtTtrWbm9hvEFGZw1tYRwCEbl+nPLbatuID0lzJzx+Yf1uVRYfFC0NvkAyciHcfN889OaP/hmsYJS/y3fDFY+CTOvhFNv9gfwshd8EBVP8d/892/tfE4LgUtwudfCSTDvZjjhk/DI1T6wwDeduRiceosfAVa7w99vroXTb/XB8fgNPqBmXuknMG57w48QK5riax4jZwX3J/uz9u7b4su2b4uvWU36MIw9yc+Ob6yGtiZfc3pvIWSXwJzr/ai05gN+fsv+cvjzHT4wCyfDza/6QASIRf1z5x/Tc8Jk7S4//DlleM7dcM7hHEfkG3JNYyvPvLuTzNQwF8wYSWZqmJ01TWytamDuxAJSwiHqg0CpbWpjw55a/rhiBxX7Gpk2Kofpo3MZX5CBA8qrG6hrbuPMycUsL9/Pior9nD21mNMnFRMKwWOLy9mwx/czTR+dS2s0xpqdBwiZ4ZzzTYatMbJSw4wvyOT5tbuprm9hYlEmB5raONDYyqi8dMwgNRzi1ElFzBmXT3M0xpNLK5g+Kof/+9HphM34xu9X8fQ72zm1tJD5s0ZRnJNGVV0LO/Y3sutAE20xx8Y9dby3q5aSHF/jWLe7lrRIiMLMVPY3ttLQEu2xv0bmprGntplEh9X2gAwZdL9WWsjAAUVZqdQ0ttIa7dwgPSXEzDE+mPY39Azgi2eO4r4bTj6sv7HCYjhxDqrKggPoRl+DyCz0Z9DNGe2bu1ob/TfzkbM6m5daGmDXu77m8cK3YPNf4Ja/QeVaeOY2GH+qb6pqb3ra+BI8caM/mOeOgwln+DkoLXW+ea1yvR8p1l3OGB88dbvilz8tD1pq4wdcQSmc8zX4w+f9+0nP8yd4rKmA5hpfq5p6Qec8mb1lsO11H0gzLvNNgGk5/qehyr+GhXyNKxTx2+1YBrE2XyMbN9cPYGip9QMdmmv9QIb0PF9rS8/14bZnjX//I6b7YGpr8kOvzeDADh/+I2b4/R5r88sbqiElwzc9hoLmFTPf/9V0wD93JM0vj7b5beJ1Zh/YAeVvwZTzO8Ozu2ir/0KxYZEv+4e+CqlHVz9Ec5vvb2oftRaLucQB2X6c67I/G1rayEztfUBoTUMruRkRzPxZCNIiIUIhIxpzvLW5mrLKOqaNyKYlGmP97jpWlO9nQlEm5x03glXba4jGHBOKsyjOSuOYwkwyUsP8/p3tbK2uZ3ReBrPG5pGTHmFbdQPHj81ja1UDP3lxA1NGZHPRzFGEDEbmpjMmP4NwyGiLxtha3UDIjK1V9ZTva2RCYSbHjsrpswk1EYWFHLpYrH/9IF3/8Vrq/cEus9Df3rnCN39lFkLBRH+AT0n3j9m9Gvau9wftzCLfT5Oa5WtUdbthw3O+eSwtx/fXZJX4WktKOix/FN59AsKpPhiySnxAbXwJti/tLFtGAcy4wg862PSKL2NzHbiof2woxTe75Yzy4Vq3B0bP9ut2LI8fdj0Ew6trth3GTsaHVCwoT1aJDy4XfEvNKvHNkTXlfl9klQTvOdUHTUaBD/Vosw/Z4qm+FhZJ92GQEvxsX+rDOSXLN0kWTvZh1NoEY0/2AyRCEf/+XdSH4u41fl/njfOPS0n3V4486Hc67Frpv5CUHOvDMi23M5BTfZ8D9ZW+iTSrxIds8wEf1ClZvjYYa/VfcLYthtzRUHoOVG/yf6/2ywREW/znJqvE/81b6v37N/O1x1DYP19qpt83KZk+sDe/6r9MTL/UD3lf9ww893W/D4//BMy+xpd553L/eU3J9Ptk/zb/nOPn+ce1NfnPclaJf+/Vm/0+zBrhy7dvi/8sF5b6bSLp/R/hWL3Zf3YnnuX3Y7tom7+eTmqW/6JTtcH/D4TTfBNxzig47qP+/ToX/C86/5k8zD7MIREWZnYx8GMgDPy3c+573danAb8CTgaqgE8657YE6+4EPgdEgX9yzj3X22spLCShWMwfMFOze/4zdx3CHG31IVNXGRz8sv3vlCzfFFa7yx8Ex57sT2V/YIc/YDTuD/55Yz4Eckb57fZuCP7pU/0BObPIH9j3rPGh1dbkQzJvnO+jaqrxAdTS4IO2tdE/T7TF105a6vzBfexJPhDffRzq9wa1rRZ/MG1t8I/PP8bXCief55sIX/gXf6CNpMP2ZX7oN/hloYg/GI2c4YP/wA7/2m2NPlzaGg+u9aVm+1pY5brOc6jFY+HOEEwke6Q/4MZ6jiA7okbPCYL21W41WMMfbI8AC/vPTCgl+ExZgt/42n677FF+H6dk+dBuqe353OFU/zdOZObH4RP/c3jFHuywMLMwsB64AKgA3gauc86t6bLN54HZzrlbzOxa4Ern3CfNbAbwGDAPGAO8AExzLvEnT2EhcghiUf/T3xNkRluDAGny4dTRXNbqD3DtPy11gPlmuMLJPmTrK31TXSjst9m/1R/88sb5WkRDtf+WXxIM164p9wfecHDQrav0NZGUTP98sahvXnWxIBzrO8OtrdkHQ/54WPtHvz5/gg/XcARqd8PaBf45xszxtdOmA76GUVjqH799iX/NUNgvq9/rn79wki9/w17/2nnjfY1i32b/HlrqfC021tr5jb/H72B/FkyEY+fDxhd9821qpg/5SJpv/o02+6AumuRrcrW74KQb/Wtv+RsdtYn2EBpxnB/kchiGQlicDnzLOXdRcP9OAOfcv3fZ5rlgmzfMLALsAkqAO7pu23W7RK+nsBAROXT9DYtknqdiLFDe5X5FsCzuNs65NqAGKOrnYzGzm8xsiZktqays7L5aRESOkGSGRbyenu7VmETb9OexOOfud87Ndc7NLSkpOYwiiohIfyQzLCqA8V3ujwO694Z1bBM0Q+UB1f18rIiIDJBkhsXbwFQzKzWzVOBaYEG3bRYANwa3rwZecr4TZQFwrZmlmVkpMBV4K4llFRGRXiTtFOXOuTYzuxV4Dj909kHn3GozuxtY4pxbADwAPGxmZfgaxbXBY1eb2RPAGqAN+EJvI6FERCS5NClPRGQYGwqjoURE5CihsBARkT4dNc1QZlYJbO1zw8SKgb1HqDhHksp1aFSuQzdUy6ZyHZrDLdcE51yfcw+OmrB4v8xsSX/a7QaaynVoVK5DN1TLpnIdmmSXS81QIiLSJ4WFiIj0SWHR6f7BLkACKtehUbkO3VAtm8p1aJJaLvVZiIhIn1SzEBGRPiksRESkT8M+LMzsYjNbZ2ZlZnbHIJZjvJm9bGZrzWy1mX0pWP4tM9tuZsuDn0sGqXxbzGxlUIYlwbJCM3vezDYEvwsGuEzHdtkvy83sgJn982DsMzN70Mz2mNmqLsvi7h/zfhJ85t41s5MGuFz/YWbvBa/9tJnlB8snmlljl/12X7LK1UvZEv7tzOzOYJ+tM7OLBrhcj3cp0xYzWx4sH7B91ssxYmA+Z865YfuDP8HhRmASkAqsAGYMUllGAycFt3Pwl6SdAXwLuG0I7KstQHG3Zd8H7ghu3wHcM8h/y13AhMHYZ8CHgJOAVX3tH+AS4Fn8dVtOAxYPcLkuBCLB7Xu6lGti1+0GaZ/F/dsF/wsrgDSgNPi/DQ9Uubqt/y/groHeZ70cIwbkczbcaxbzgDLn3CbnXAvwG+DwLmT7PjnndjrnlgW3a4G1xLk64BBzOfBQcPsh4IpBLMv5wEbn3PuZxX/YnHN/wZ85uatE++dy4FfOexPIN7PRA1Uu59wi569MCfAm/noxAy7BPkvkcuA3zrlm59xmoAz//zug5TIzA64BHkvGa/eml2PEgHzOhntY9OvyrQPNzCYCJwKLg0W3BtXIBwe6qacLBywys6VmdlOwbKRzbif4DzIwYpDKBv709l3/gYfCPku0f4bS5+7v8d8+25Wa2Ttm9qqZnT1IZYr3txsq++xsYLdzbkOXZQO+z7odIwbkczbcw6Jfl28dSGaWDTwF/LNz7gDwc2AyMAfYia8CD4YznXMnAfOBL5jZhwapHD2Yv7jWZcBvg0VDZZ8lMiQ+d2b2dfz1Yn4dLNoJHOOcOxH4MvComeUOcLES/e2GxD4DruPgLyUDvs/iHCMSbhpn2WHvs+EeFkPq8q1mloL/EPzaOfc7AOfcbudc1DkXA35JkqrefXHO7Qh+7wGeDsqxu71aG/zeMxhlwwfYMufc7qCMQ2KfkXj/DPrnzsxuBD4GfNoFDdxBE09VcHspvl9g2kCWq5e/3VDYZxHg48Dj7csGep/FO0YwQJ+z4R4W/bn064AI2kIfANY6537QZXnXNsYrgVXdHzsAZcsys5z22/gO0lUcfFncG4E/DHTZAgd92xsK+yyQaP8sAD4TjFY5Dahpb0YYCGZ2MfA14DLnXEOX5SVmFg5uT8JfznjTQJUreN1Ef7uhcKnljwDvOecq2hcM5D5LdIxgoD5nA9GLP5R/8CMG1uO/EXx9EMtxFr6K+C6wPPi5BHgYWBksXwCMHoSyTcKPRFkBrG7fT0AR8CKwIfhdOAhlywSqgLwuywZ8n+HDaifQiv9G97lE+wffPHBv8JlbCcwd4HKV4duy2z9n9wXbXhX8fVcAy4BLB2GfJfzbAV8P9tk6YP5AlitY/r/ALd22HbB91ssxYkA+Zzrdh4iI9Gm4N0OJiEg/KCxERKRPCgsREemTwkJERPqksBARkT4pLESGADM718z+NNjlEElEYSEiIn1SWIgcAjO73szeCq5d8AszC5tZnZn9l5ktM7MXzawk2HaOmb1pndeNaL/OwBQze8HMVgSPmRw8fbaZPWn+WhO/DmbsigwJCguRfjKz6cAn8SdVnANEgU8DWfhzU50EvAr8S/CQXwFfc87Nxs+gbV/+a+Be59wJwBn42cLgzyL6z/hrFEwCzkz6mxLpp8hgF0DkA+R84GTg7eBLfwb+pG0xOk8u9wjwOzPLA/Kdc68Gyx8CfhucY2usc+5pAOdcE0DwfG+54LxD5q/ENhH4a/LflkjfFBYi/WfAQ865Ow9aaPbNbtv1dg6d3pqWmrvcjqL/TxlC1Awl0n8vAleb2QjouPbxBPz/0dXBNp8C/uqcqwH2dbkYzg3Aq85ff6DCzK4IniPNzDIH9F2IHAZ9cxHpJ+fcGjP7Bv6KgSH8WUm/ANQDM81sKVCD79cAf7ro+4Iw2AR8Nlh+A/ALM7s7eI5PDODbEDksOuusyPtkZnXOuezBLodIMqkZSkRE+qSahYiI9Ek1CxER6ZPCQkRE+qSwEBGRPiksRESkTwoLERHp0/8PocY3aSRIF00AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['loss'])\n",
    "plt.plot(train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1) [[780.0055 ]\n",
      " [777.594  ]\n",
      " [782.6537 ]\n",
      " [784.7703 ]\n",
      " [793.6133 ]\n",
      " [804.1407 ]\n",
      " [813.997  ]\n",
      " [808.987  ]\n",
      " [806.3083 ]\n",
      " [807.27527]\n",
      " [807.21045]\n",
      " [805.5038 ]\n",
      " [806.499  ]\n",
      " [810.40466]\n",
      " [814.79645]\n",
      " [819.3807 ]\n",
      " [826.86676]\n",
      " [831.0089 ]\n",
      " [828.07916]\n",
      " [812.9668 ]]\n"
     ]
    }
   ],
   "source": [
    "# local data\n",
    "# model.load_weights('./model/LSTM_03_check_point/cp-{epoch:04d}.ckpt'.format(epoch=600))\n",
    "testing_data = open_data[-test_count-input_days:]\n",
    "output_prices = []\n",
    "for i in range(test_count):\n",
    "    sc = MinMaxScaler()\n",
    "    test = testing_data[i:i+input_days]\n",
    "    test_mean = np.mean(test)\n",
    "    test = sc.getScalerData(test, offset=offset)\n",
    "    output = np.squeeze(model.predict(np.append(np.expand_dims(test, axis=0), test_x[i:i+1, :, 1:2], axis=-1)), axis=0)\n",
    "    output_prices.append(test_mean * (1 + label_sc.getInverseData(output)))\n",
    "\n",
    "output_prices = np.asarray(output_prices)\n",
    "print(output_prices.shape, output_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(test_data_t[:, 0], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(output_prices, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Time(days)')\n",
    "plt.ylabel('Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlib]",
   "language": "python",
   "name": "conda-env-dlib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
