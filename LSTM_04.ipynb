{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./dataset/Google_Stock_Price_Train.csv').values\n",
    "test_data = pd.read_csv('./dataset/Google_Stock_Price_Test.csv').values\n",
    "\n",
    "# parameter\n",
    "input_days = 20\n",
    "epochs = 500\n",
    "batch_size = 250\n",
    "offset = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix data string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 5)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "# the data[4:6] must be fix\n",
    "def str2float(data):\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            data[i] = data[i].replace(',', '')\n",
    "        except AttributeError:\n",
    "            data[i] = data[i]\n",
    "    return np.asarray(data, dtype=np.float)\n",
    "    \n",
    "# fix all data in dataset\n",
    "def fixStr2Float(dataset):\n",
    "    shape = dataset.shape\n",
    "    dataset_t = np.zeros((0, shape[-1]), np.float)\n",
    "    for i, data in enumerate(dataset):\n",
    "        dataset_t = np.append(dataset_t, np.expand_dims(str2float(data), axis=0), axis=0)\n",
    "    return dataset_t\n",
    "\n",
    "# trainsform\n",
    "train_data_t = fixStr2Float(train_data[:, 1:])\n",
    "test_data_t = fixStr2Float(test_data[:, 1:])\n",
    "\n",
    "print(train_data_t.shape)\n",
    "print(test_data_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    __min = 0.\n",
    "    __max = 1.\n",
    "    __range = 1.\n",
    "    __feature_range = (0, 1)\n",
    "    __scale = 1.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getScalerData(self, dataset, offset=0.1, feature_range=(0, 1)):\n",
    "        data_max = np.max(dataset)\n",
    "        data_min = np.min(dataset)\n",
    "        self.__range = (data_max - data_min) * (1 + offset)\n",
    "        self.__min = data_max - self.__range\n",
    "        self.__max = data_min + self.__range\n",
    "        self.__feature_range = feature_range\n",
    "        self.__scale = (feature_range[1] - feature_range[0]) / self.__range\n",
    "        return self.getTransformData(dataset)\n",
    "    def getTransformData(self, dataset):\n",
    "        return (dataset - self.__min) * self.__scale + self.__feature_range[0]\n",
    "    def getInverseData(self, scalerDataset):\n",
    "        return (scalerDataset - self.__feature_range[0]) / self.__scale + self.__min\n",
    "    def getParameter(self):\n",
    "        return self.__min, self.__max, self.__range, self.__feature_range, self.__scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset_global(dataset, day_in=60, day_out=1):\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(dataset[i-day_in:i, :])\n",
    "        y.append(dataset[i:i+day_out, :])\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def genQuteChange(dataset):\n",
    "    return (dataset[1:] - dataset[:-1]) / dataset[:-1]\n",
    "\n",
    "def createDataset_local(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(sc.getScalerData(dataset[i-day_in:i, :], offset=offset))\n",
    "        y.append(sc.getTransformData(dataset[i:i+day_out, :]))\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def createDataset_mix(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x_data = dataset[i-day_in:i, :]\n",
    "        y_data = dataset[i:i+day_out, :]\n",
    "        x_mean = np.mean(x_data)\n",
    "        x.append(sc.getScalerData(x_data, offset=offset))\n",
    "        y.append((y_data - x_mean) / x_mean)\n",
    "    return (np.asarray(x), y_sc.getScalerData(np.asarray(y))), y_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1238, 20, 2) (1238, 1, 1)\n",
      "(40, 20, 2) (40, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# append to a big dataset total\n",
    "dataset = np.append(train_data_t, test_data_t, axis=0)\n",
    "test_count = len(test_data_t)\n",
    "\n",
    "# Split dataset to Volume and Open\n",
    "open_data = dataset[:, :1]\n",
    "volume_data = dataset[:, -1:]\n",
    "\n",
    "# use global norm to volume data (with offset)\n",
    "volume_sc = MinMaxScaler()\n",
    "volume_norm = volume_sc.getScalerData(volume_data, offset=0.05, feature_range=(0, 1))\n",
    "\n",
    "# create dataset\n",
    "volume_dataset = createDataset_global(volume_norm, day_in=input_days)\n",
    "open_dataset, label_sc = createDataset_mix(dataset[:, :1], day_in=input_days, offset=offset)\n",
    "\n",
    "# create total dataset\n",
    "dataset_x = np.append(open_dataset[0], volume_dataset[0], axis=-1)\n",
    "dataset_y = np.append(open_dataset[1], volume_dataset[1], axis=-1)\n",
    "\n",
    "# split to train and test dataset\n",
    "train_x = dataset_x[:-test_count]\n",
    "train_y = dataset_y[:-test_count, :, :1]\n",
    "test_x = dataset_x[-test_count-input_days:]\n",
    "test_y = dataset_y[-test_count-input_days:, :, :1]\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 20, 50)            10600     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 50)            20200     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                5160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 164,129\n",
      "Trainable params: 164,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (input_days, 2), dropout=0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True, dropout=0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dense(units = 40, activation='relu'))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "model.summary()\n",
    "plot_model(model, 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with Open data and Volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1238 samples, validate on 40 samples\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "1238/1238 [==============================] - 3s 2ms/sample - loss: 0.1215 - val_loss: 0.0094\n",
      "Epoch 2/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0422 - val_loss: 0.0252\n",
      "Epoch 3/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0233 - val_loss: 0.0081\n",
      "Epoch 4/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0198 - val_loss: 0.0159\n",
      "Epoch 5/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0137 - val_loss: 0.0056\n",
      "Epoch 6/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0127 - val_loss: 0.0079\n",
      "Epoch 7/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0105 - val_loss: 0.0041\n",
      "Epoch 8/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0099 - val_loss: 0.0044\n",
      "Epoch 9/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0086 - val_loss: 0.0032\n",
      "Epoch 10/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0087\n",
      "Epoch 00010: saving model to ./model/LSTM_03_check_point/cp-0010.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "1238/1238 [==============================] - 0s 391us/sample - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 11/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 12/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0074 - val_loss: 0.0027\n",
      "Epoch 13/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0076 - val_loss: 0.0024\n",
      "Epoch 14/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 15/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 16/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 17/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0068 - val_loss: 0.0023\n",
      "Epoch 18/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 19/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 20/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0066\n",
      "Epoch 00020: saving model to ./model/LSTM_03_check_point/cp-0020.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0067 - val_loss: 0.0021\n",
      "Epoch 21/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0065 - val_loss: 0.0018\n",
      "Epoch 22/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 23/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 24/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 25/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 26/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 27/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 28/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 29/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0061 - val_loss: 0.0016\n",
      "Epoch 30/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00030: saving model to ./model/LSTM_03_check_point/cp-0030.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 31/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 32/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 33/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 34/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 35/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 36/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0061 - val_loss: 0.0019\n",
      "Epoch 37/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 38/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 39/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 40/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00040: saving model to ./model/LSTM_03_check_point/cp-0040.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 41/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 42/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0054 - val_loss: 0.0016\n",
      "Epoch 43/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 44/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 45/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 46/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 47/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 48/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 49/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 50/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00050: saving model to ./model/LSTM_03_check_point/cp-0050.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 51/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 52/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 53/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 54/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 55/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 56/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 57/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 58/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 59/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 60/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00060: saving model to ./model/LSTM_03_check_point/cp-0060.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 61/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 62/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 63/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 64/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 65/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 66/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 67/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 68/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 69/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 70/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00070: saving model to ./model/LSTM_03_check_point/cp-0070.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 71/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 72/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 73/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 74/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 75/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 76/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 77/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 78/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 79/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 80/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00080: saving model to ./model/LSTM_03_check_point/cp-0080.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 81/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 82/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 83/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 84/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 85/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 86/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 87/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 88/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 89/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 90/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00090: saving model to ./model/LSTM_03_check_point/cp-0090.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 91/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 92/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 93/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 94/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 95/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 96/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 97/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 98/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 99/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 100/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00100: saving model to ./model/LSTM_03_check_point/cp-0100.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 101/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 102/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 103/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 104/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 105/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 106/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 107/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 108/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 109/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 110/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00110: saving model to ./model/LSTM_03_check_point/cp-0110.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 111/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 112/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 113/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 114/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0041 - val_loss: 9.9440e-04\n",
      "Epoch 115/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 116/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0039 - val_loss: 9.6922e-04\n",
      "Epoch 117/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 118/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 119/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 120/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00120: saving model to ./model/LSTM_03_check_point/cp-0120.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 121/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 122/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 123/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 124/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 125/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 126/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0036 - val_loss: 9.5763e-04\n",
      "Epoch 127/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0032 - val_loss: 9.9525e-04\n",
      "Epoch 128/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0033 - val_loss: 9.3809e-04\n",
      "Epoch 129/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 130/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00130: saving model to ./model/LSTM_03_check_point/cp-0130.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0037 - val_loss: 9.5094e-04\n",
      "Epoch 131/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 132/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 133/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 134/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0033 - val_loss: 9.5450e-04\n",
      "Epoch 135/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0034 - val_loss: 9.1823e-04\n",
      "Epoch 136/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 137/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 138/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 139/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 140/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00140: saving model to ./model/LSTM_03_check_point/cp-0140.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 141/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 142/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 143/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 144/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 145/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0032 - val_loss: 9.9641e-04\n",
      "Epoch 146/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 9.6663e-04\n",
      "Epoch 147/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0033 - val_loss: 9.5154e-04\n",
      "Epoch 148/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 149/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 150/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00150: saving model to ./model/LSTM_03_check_point/cp-0150.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 151/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0031 - val_loss: 9.1126e-04\n",
      "Epoch 152/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 153/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0033 - val_loss: 9.3647e-04\n",
      "Epoch 154/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0031 - val_loss: 8.6004e-04\n",
      "Epoch 155/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 9.8882e-04\n",
      "Epoch 156/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0032 - val_loss: 9.3963e-04\n",
      "Epoch 157/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 158/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 159/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 160/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00160: saving model to ./model/LSTM_03_check_point/cp-0160.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0028 - val_loss: 9.3588e-04\n",
      "Epoch 161/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0031 - val_loss: 9.8226e-04\n",
      "Epoch 162/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0033 - val_loss: 9.6845e-04\n",
      "Epoch 163/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 9.7351e-04\n",
      "Epoch 164/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 165/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 166/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 167/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 8.9883e-04\n",
      "Epoch 168/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 9.4931e-04\n",
      "Epoch 169/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 170/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00170: saving model to ./model/LSTM_03_check_point/cp-0170.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 171/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 172/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0029 - val_loss: 9.7883e-04\n",
      "Epoch 173/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 8.9580e-04\n",
      "Epoch 174/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0029 - val_loss: 9.2615e-04\n",
      "Epoch 175/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 176/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.8446e-04\n",
      "Epoch 177/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 8.7648e-04\n",
      "Epoch 178/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0028 - val_loss: 8.5177e-04\n",
      "Epoch 179/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.4765e-04\n",
      "Epoch 180/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00180: saving model to ./model/LSTM_03_check_point/cp-0180.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0027 - val_loss: 9.3101e-04\n",
      "Epoch 181/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 182/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 9.8193e-04\n",
      "Epoch 183/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 8.6644e-04\n",
      "Epoch 184/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 8.7842e-04\n",
      "Epoch 185/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 9.6884e-04\n",
      "Epoch 186/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.7842e-04\n",
      "Epoch 187/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 9.5148e-04\n",
      "Epoch 188/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 189/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 190/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00190: saving model to ./model/LSTM_03_check_point/cp-0190.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 191/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 9.6430e-04\n",
      "Epoch 192/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 8.9881e-04\n",
      "Epoch 193/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0027 - val_loss: 9.9889e-04\n",
      "Epoch 194/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0030 - val_loss: 9.7002e-04\n",
      "Epoch 195/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 9.5420e-04\n",
      "Epoch 196/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 9.2161e-04\n",
      "Epoch 197/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.8031e-04\n",
      "Epoch 198/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 199/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 200/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00200: saving model to ./model/LSTM_03_check_point/cp-0200.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0027 - val_loss: 9.1962e-04\n",
      "Epoch 201/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0029 - val_loss: 8.9885e-04\n",
      "Epoch 202/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 8.7225e-04\n",
      "Epoch 203/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 8.0962e-04\n",
      "Epoch 204/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 8.1609e-04\n",
      "Epoch 205/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0028 - val_loss: 8.5114e-04\n",
      "Epoch 206/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0029 - val_loss: 8.2952e-04\n",
      "Epoch 207/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 9.5554e-04\n",
      "Epoch 208/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.7743e-04\n",
      "Epoch 209/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 8.4887e-04\n",
      "Epoch 210/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00210: saving model to ./model/LSTM_03_check_point/cp-0210.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0025 - val_loss: 8.1935e-04\n",
      "Epoch 211/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 212/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 213/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.8942e-04\n",
      "Epoch 214/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.9221e-04\n",
      "Epoch 215/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 8.8289e-04\n",
      "Epoch 216/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 8.6115e-04\n",
      "Epoch 217/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0024 - val_loss: 8.5862e-04\n",
      "Epoch 218/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.4903e-04\n",
      "Epoch 219/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 8.5819e-04\n",
      "Epoch 220/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00220: saving model to ./model/LSTM_03_check_point/cp-0220.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 221/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 222/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.9739e-04\n",
      "Epoch 223/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.5375e-04\n",
      "Epoch 224/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.4538e-04\n",
      "Epoch 225/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 8.5806e-04\n",
      "Epoch 226/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 8.6016e-04\n",
      "Epoch 227/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0027 - val_loss: 9.6341e-04\n",
      "Epoch 228/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 7.9510e-04\n",
      "Epoch 229/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0026 - val_loss: 8.9388e-04\n",
      "Epoch 230/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00230: saving model to ./model/LSTM_03_check_point/cp-0230.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0025 - val_loss: 9.1469e-04\n",
      "Epoch 231/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 232/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 233/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 234/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0028 - val_loss: 8.5843e-04\n",
      "Epoch 235/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 8.8077e-04\n",
      "Epoch 236/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0026 - val_loss: 9.3483e-04\n",
      "Epoch 237/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 9.1826e-04\n",
      "Epoch 238/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 239/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0028 - val_loss: 8.7732e-04\n",
      "Epoch 240/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00240: saving model to ./model/LSTM_03_check_point/cp-0240.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0024 - val_loss: 8.3491e-04\n",
      "Epoch 241/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0024 - val_loss: 8.4015e-04\n",
      "Epoch 242/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 9.1421e-04\n",
      "Epoch 243/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.3404e-04\n",
      "Epoch 244/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0026 - val_loss: 8.9678e-04\n",
      "Epoch 245/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 246/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 247/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0028 - val_loss: 9.3649e-04\n",
      "Epoch 248/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 8.4979e-04\n",
      "Epoch 249/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.2706e-04\n",
      "Epoch 250/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00250: saving model to ./model/LSTM_03_check_point/cp-0250.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0024 - val_loss: 8.8464e-04\n",
      "Epoch 251/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 252/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 9.2491e-04\n",
      "Epoch 253/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 254/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 255/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 8.5860e-04\n",
      "Epoch 256/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 8.7183e-04\n",
      "Epoch 257/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0023 - val_loss: 9.1099e-04\n",
      "Epoch 258/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0024 - val_loss: 9.0306e-04\n",
      "Epoch 259/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.7821e-04\n",
      "Epoch 260/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00260: saving model to ./model/LSTM_03_check_point/cp-0260.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0024 - val_loss: 8.1060e-04\n",
      "Epoch 261/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.6622e-04\n",
      "Epoch 262/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 263/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 8.9554e-04\n",
      "Epoch 264/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0024 - val_loss: 9.1402e-04\n",
      "Epoch 265/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.8350e-04\n",
      "Epoch 266/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.5473e-04\n",
      "Epoch 267/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 9.9664e-04\n",
      "Epoch 268/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.8785e-04\n",
      "Epoch 269/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0022 - val_loss: 9.0099e-04\n",
      "Epoch 270/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00270: saving model to ./model/LSTM_03_check_point/cp-0270.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0023 - val_loss: 9.0454e-04\n",
      "Epoch 271/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 8.5427e-04\n",
      "Epoch 272/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 8.7961e-04\n",
      "Epoch 273/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0023 - val_loss: 9.5146e-04\n",
      "Epoch 274/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.7738e-04\n",
      "Epoch 275/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0023 - val_loss: 8.5764e-04\n",
      "Epoch 276/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.3380e-04\n",
      "Epoch 277/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 278/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 279/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0025 - val_loss: 9.3470e-04\n",
      "Epoch 280/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00280: saving model to ./model/LSTM_03_check_point/cp-0280.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0024 - val_loss: 9.3066e-04\n",
      "Epoch 281/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 9.1219e-04\n",
      "Epoch 282/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.6763e-04\n",
      "Epoch 283/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 284/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.0928e-04\n",
      "Epoch 285/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 8.6775e-04\n",
      "Epoch 286/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.2669e-04\n",
      "Epoch 287/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 8.7304e-04\n",
      "Epoch 288/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.3412e-04\n",
      "Epoch 289/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 290/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00290: saving model to ./model/LSTM_03_check_point/cp-0290.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0023 - val_loss: 9.6488e-04\n",
      "Epoch 291/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0023 - val_loss: 9.1460e-04\n",
      "Epoch 292/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 8.7613e-04\n",
      "Epoch 293/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 9.4086e-04\n",
      "Epoch 294/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 295/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 296/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 9.2087e-04\n",
      "Epoch 297/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.7559e-04\n",
      "Epoch 298/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 8.5556e-04\n",
      "Epoch 299/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 300/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00300: saving model to ./model/LSTM_03_check_point/cp-0300.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 301/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 302/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0024 - val_loss: 8.5730e-04\n",
      "Epoch 303/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0022 - val_loss: 8.9331e-04\n",
      "Epoch 304/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 305/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 306/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 9.8052e-04\n",
      "Epoch 307/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.2348e-04\n",
      "Epoch 308/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.8628e-04\n",
      "Epoch 309/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.7772e-04\n",
      "Epoch 310/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00310: saving model to ./model/LSTM_03_check_point/cp-0310.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0022 - val_loss: 8.7583e-04\n",
      "Epoch 311/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.9849e-04\n",
      "Epoch 312/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 313/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 314/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.8403e-04\n",
      "Epoch 315/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0022 - val_loss: 8.4381e-04\n",
      "Epoch 316/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 317/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 318/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 9.4062e-04\n",
      "Epoch 319/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 8.7103e-04\n",
      "Epoch 320/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00320: saving model to ./model/LSTM_03_check_point/cp-0320.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 321/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0022 - val_loss: 9.8626e-04\n",
      "Epoch 322/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 323/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0024 - val_loss: 9.3561e-04\n",
      "Epoch 324/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 8.3548e-04\n",
      "Epoch 325/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 9.3465e-04\n",
      "Epoch 326/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 327/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 328/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 329/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0022 - val_loss: 8.6768e-04\n",
      "Epoch 330/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00330: saving model to ./model/LSTM_03_check_point/cp-0330.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0022 - val_loss: 8.6719e-04\n",
      "Epoch 331/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.9198e-04\n",
      "Epoch 332/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 333/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 8.8090e-04\n",
      "Epoch 334/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 335/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 336/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.7038e-04\n",
      "Epoch 337/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.0532e-04\n",
      "Epoch 338/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.7086e-04\n",
      "Epoch 339/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 340/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00340: saving model to ./model/LSTM_03_check_point/cp-0340.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0021 - val_loss: 9.1402e-04\n",
      "Epoch 341/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.3658e-04\n",
      "Epoch 342/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.9522e-04\n",
      "Epoch 343/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.8867e-04\n",
      "Epoch 344/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.7148e-04\n",
      "Epoch 345/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 346/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.7753e-04\n",
      "Epoch 347/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.7017e-04\n",
      "Epoch 348/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.7784e-04\n",
      "Epoch 349/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.6452e-04\n",
      "Epoch 350/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00350: saving model to ./model/LSTM_03_check_point/cp-0350.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 351/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 352/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.5587e-04\n",
      "Epoch 353/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0021 - val_loss: 9.5162e-04\n",
      "Epoch 354/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 355/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 356/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 8.9044e-04\n",
      "Epoch 357/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.9377e-04\n",
      "Epoch 358/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.8156e-04\n",
      "Epoch 359/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.7448e-04\n",
      "Epoch 360/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00360: saving model to ./model/LSTM_03_check_point/cp-0360.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 361/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.1309e-04\n",
      "Epoch 362/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 363/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 364/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 365/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.0625e-04\n",
      "Epoch 366/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 367/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 368/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 369/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0021 - val_loss: 9.7565e-04\n",
      "Epoch 370/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00370: saving model to ./model/LSTM_03_check_point/cp-0370.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0021 - val_loss: 9.1774e-04\n",
      "Epoch 371/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 9.1465e-04\n",
      "Epoch 372/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 373/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.2296e-04\n",
      "Epoch 374/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.9428e-04\n",
      "Epoch 375/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0020 - val_loss: 9.1539e-04\n",
      "Epoch 376/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 9.7452e-04\n",
      "Epoch 377/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.7641e-04\n",
      "Epoch 378/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.7407e-04\n",
      "Epoch 379/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.2201e-04\n",
      "Epoch 380/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00380: saving model to ./model/LSTM_03_check_point/cp-0380.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0021 - val_loss: 9.2794e-04\n",
      "Epoch 381/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 382/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 383/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 9.4105e-04\n",
      "Epoch 384/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.1147e-04\n",
      "Epoch 385/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.5499e-04\n",
      "Epoch 386/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 9.6261e-04\n",
      "Epoch 387/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.1679e-04\n",
      "Epoch 388/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 389/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 390/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00390: saving model to ./model/LSTM_03_check_point/cp-0390.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 379us/sample - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 391/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 9.9731e-04\n",
      "Epoch 392/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.2296e-04\n",
      "Epoch 393/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 394/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 395/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 396/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.3709e-04\n",
      "Epoch 397/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 8.9482e-04\n",
      "Epoch 398/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 399/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 400/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00400: saving model to ./model/LSTM_03_check_point/cp-0400.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 401/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.5476e-04\n",
      "Epoch 402/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0022 - val_loss: 9.3032e-04\n",
      "Epoch 403/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 404/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 405/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 406/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 407/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.4336e-04\n",
      "Epoch 408/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 409/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0019 - val_loss: 9.5197e-04\n",
      "Epoch 410/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00410: saving model to ./model/LSTM_03_check_point/cp-0410.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0020 - val_loss: 9.3662e-04\n",
      "Epoch 411/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 412/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 413/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0020 - val_loss: 9.6977e-04\n",
      "Epoch 414/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.5576e-04\n",
      "Epoch 415/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 9.9145e-04\n",
      "Epoch 416/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 417/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 418/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.4006e-04\n",
      "Epoch 419/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0020 - val_loss: 9.6946e-04\n",
      "Epoch 420/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00420: saving model to ./model/LSTM_03_check_point/cp-0420.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 303us/sample - loss: 0.0019 - val_loss: 9.2470e-04\n",
      "Epoch 421/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 422/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.9274e-04\n",
      "Epoch 423/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 8.8429e-04\n",
      "Epoch 424/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.6729e-04\n",
      "Epoch 425/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 426/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 427/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 428/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0021 - val_loss: 9.4791e-04\n",
      "Epoch 429/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 430/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00430: saving model to ./model/LSTM_03_check_point/cp-0430.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 431/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.3101e-04\n",
      "Epoch 432/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0019 - val_loss: 9.4491e-04\n",
      "Epoch 433/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 434/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.4155e-04\n",
      "Epoch 435/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 436/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 437/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 438/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.9529e-04\n",
      "Epoch 439/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.9452e-04\n",
      "Epoch 440/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00440: saving model to ./model/LSTM_03_check_point/cp-0440.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 441/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 442/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 443/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 444/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 445/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 9.5888e-04\n",
      "Epoch 446/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 447/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 448/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 449/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.3342e-04\n",
      "Epoch 450/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00450: saving model to ./model/LSTM_03_check_point/cp-0450.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 451/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 452/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 453/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 9.5697e-04\n",
      "Epoch 454/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.2796e-04\n",
      "Epoch 455/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 456/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 457/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 458/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 459/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 460/500\n",
      " 750/1238 [=================>............] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00460: saving model to ./model/LSTM_03_check_point/cp-0460.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0020 - val_loss: 9.8400e-04\n",
      "Epoch 461/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 462/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 9.7323e-04\n",
      "Epoch 463/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 464/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.7509e-04\n",
      "Epoch 465/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 466/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 467/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 468/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0021 - val_loss: 9.5445e-04\n",
      "Epoch 469/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 470/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00470: saving model to ./model/LSTM_03_check_point/cp-0470.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 471/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 472/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 473/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 9.6671e-04\n",
      "Epoch 474/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 475/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 476/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.2520e-04\n",
      "Epoch 477/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 9.4385e-04\n",
      "Epoch 478/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 479/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 480/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00480: saving model to ./model/LSTM_03_check_point/cp-0480.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 481/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 482/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 483/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 484/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 485/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 9.8232e-04\n",
      "Epoch 486/500\n",
      "1238/1238 [==============================] - 0s 265us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 487/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 488/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 9.7299e-04\n",
      "Epoch 489/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 490/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00490: saving model to ./model/LSTM_03_check_point/cp-0490.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 290us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 491/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 492/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 493/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 494/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 495/500\n",
      "1238/1238 [==============================] - 0s 227us/sample - loss: 0.0018 - val_loss: 9.9727e-04\n",
      "Epoch 496/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 497/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 9.7530e-04\n",
      "Epoch 498/500\n",
      "1238/1238 [==============================] - 0s 252us/sample - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 499/500\n",
      "1238/1238 [==============================] - 0s 240us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 500/500\n",
      "1000/1238 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00500: saving model to ./model/LSTM_03_check_point/cp-0500.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001703DCC8588>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1238/1238 [==============================] - 0s 315us/sample - loss: 0.0017 - val_loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "name = 'LSTM_04'\n",
    "checkpoint_file = './model/' + name + '_check_point/cp-{epoch:04d}.ckpt'\n",
    "try:\n",
    "    os.mkdir('./model/' + name + '_check_point/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# get what we want\n",
    "train_input = train_x\n",
    "train_label = train_y\n",
    "test_input = test_x\n",
    "test_label = test_y\n",
    "train_label = np.squeeze(train_label, axis=1)\n",
    "test_label = np.squeeze(test_label, axis=1)\n",
    "\n",
    "# create callback function\n",
    "cp_callback = ModelCheckpoint(checkpoint_file, save_weights_only=True, verbose=1, period=10)\n",
    "\n",
    "# train the model\n",
    "train = model.fit(train_input, train_label, epochs=epochs, batch_size=batch_size, callbacks=[cp_callback], \n",
    "                  validation_data=(test_input, test_label))\n",
    "\n",
    "# save model\n",
    "model.save('./model/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['loss'])\n",
    "plt.plot(train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1) [[781.9417 ]\n",
      " [782.86127]\n",
      " [787.5006 ]\n",
      " [787.8069 ]\n",
      " [794.125  ]\n",
      " [807.58093]\n",
      " [809.2654 ]\n",
      " [811.4591 ]\n",
      " [813.9439 ]\n",
      " [814.57385]\n",
      " [811.6305 ]\n",
      " [816.9376 ]\n",
      " [808.82794]\n",
      " [810.353  ]\n",
      " [812.68884]\n",
      " [821.36127]\n",
      " [828.14044]\n",
      " [837.3742 ]\n",
      " [844.6299 ]\n",
      " [823.43286]]\n"
     ]
    }
   ],
   "source": [
    "# local data\n",
    "# model.load_weights('./model/LSTM_03_check_point/cp-{epoch:04d}.ckpt'.format(epoch=600))\n",
    "testing_data = open_data[-test_count-input_days:]\n",
    "output_prices = []\n",
    "for i in range(test_count):\n",
    "    sc = MinMaxScaler()\n",
    "    test = testing_data[i:i+input_days]\n",
    "    test_mean = np.mean(test)\n",
    "    test = sc.getScalerData(test, offset=offset)\n",
    "    output = np.squeeze(model.predict(np.append(np.expand_dims(test, axis=0), test_x[i:i+1, :, 1:2], axis=-1)), axis=0)\n",
    "    output_prices.append(test_mean * (1 + label_sc.getInverseData(output)))\n",
    "\n",
    "output_prices = np.asarray(output_prices)\n",
    "print(output_prices.shape, output_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(test_data_t[1:, 0], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(output_prices, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Time(days)')\n",
    "plt.ylabel('Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlib]",
   "language": "python",
   "name": "conda-env-dlib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
