{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./dataset/Google_Stock_Price/Google_Stock_Price_Train.csv').values\n",
    "test_data = pd.read_csv('./dataset/Google_Stock_Price/Google_Stock_Price_Test.csv').values\n",
    "\n",
    "# parameter\n",
    "input_days = 60\n",
    "epochs = 500\n",
    "batch_size = 250\n",
    "offset = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix data string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 5)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "# the data[4:6] must be fix\n",
    "def str2float(data):\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            data[i] = data[i].replace(',', '')\n",
    "        except AttributeError:\n",
    "            data[i] = data[i]\n",
    "    return np.asarray(data, dtype=np.float)\n",
    "    \n",
    "# fix all data in dataset\n",
    "def fixStr2Float(dataset):\n",
    "    shape = dataset.shape\n",
    "    dataset_t = np.zeros((0, shape[-1]), np.float)\n",
    "    for i, data in enumerate(dataset):\n",
    "        dataset_t = np.append(dataset_t, np.expand_dims(str2float(data), axis=0), axis=0)\n",
    "    return dataset_t\n",
    "\n",
    "# trainsform\n",
    "train_data_t = fixStr2Float(train_data[:, 1:])\n",
    "test_data_t = fixStr2Float(test_data[:, 1:])\n",
    "\n",
    "print(train_data_t.shape)\n",
    "print(test_data_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    __min = 0.\n",
    "    __max = 1.\n",
    "    __range = 1.\n",
    "    __feature_range = (0, 1)\n",
    "    __scale = 1.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getScalerData(self, dataset, offset=0.1, feature_range=(0, 1)):\n",
    "        data_max = np.max(dataset)\n",
    "        data_min = np.min(dataset)\n",
    "        if len(dataset) == 1:\n",
    "            range_temp = dataset * offset\n",
    "        else:\n",
    "            range_temp = (data_max - data_min) * (1 + offset)\n",
    "        self.__min = data_max - range_temp\n",
    "        self.__max = data_min + range_temp\n",
    "        self.__range = self.__max - self.__min\n",
    "        self.__feature_range = feature_range\n",
    "        self.__scale = (feature_range[1] - feature_range[0]) / self.__range\n",
    "        return self.getTransformData(dataset)\n",
    "    def getTransformData(self, dataset):\n",
    "        return (dataset - self.__min) * self.__scale + self.__feature_range[0]\n",
    "    def getInverseData(self, scalerDataset):\n",
    "        return (scalerDataset - self.__feature_range[0]) / self.__scale + self.__min\n",
    "    def getParameter(self):\n",
    "        return self.__min, self.__max, self.__range, self.__feature_range, self.__scale\n",
    "    def updatePatameter(self, parameter):\n",
    "        self.__min, self.__max, self.__range, self.__feature_range, self.__scale = parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset_global(dataset, day_in=60, day_out=1):\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(dataset[i-day_in:i, :])\n",
    "        y.append(dataset[i:i+day_out, :])\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def genQuteChange(dataset):\n",
    "    return (dataset[1:] - dataset[:-1]) / dataset[:-1]\n",
    "\n",
    "def createDataset_local(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(sc.getScalerData(dataset[i-day_in:i, :], offset=offset))\n",
    "        y.append(sc.getTransformData(dataset[i:i+day_out, :]))\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def createDataset_mix(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x_data = dataset[i-day_in:i, :]\n",
    "        y_data = dataset[i:i+day_out, :]\n",
    "        x_mean = np.mean(x_data)\n",
    "        x.append(sc.getScalerData(x_data, offset=offset))\n",
    "        y.append((y_data - x_mean) / x_mean)\n",
    "    return (np.asarray(x), y_sc.getScalerData(np.asarray(y))), y_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1198, 60, 2) (1198, 1, 1)\n",
      "(80, 60, 2) (80, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# append to a big dataset total\n",
    "dataset = np.append(train_data_t, test_data_t, axis=0)\n",
    "test_count = len(test_data_t)\n",
    "\n",
    "# Split dataset to Volume and Open\n",
    "open_data = dataset[:, :1]\n",
    "volume_data = dataset[:, -1:]\n",
    "\n",
    "# use global norm to volume data (with offset)\n",
    "volume_sc = MinMaxScaler()\n",
    "volume_norm = volume_sc.getScalerData(volume_data, offset=0.05, feature_range=(0, 1))\n",
    "\n",
    "# create dataset\n",
    "volume_dataset = createDataset_global(volume_norm, day_in=input_days)\n",
    "open_dataset, label_sc = createDataset_mix(dataset[:, :1], day_in=input_days, offset=offset)\n",
    "\n",
    "# create total dataset\n",
    "dataset_x = np.append(open_dataset[0], volume_dataset[0], axis=-1)\n",
    "dataset_y = np.append(open_dataset[1], volume_dataset[1], axis=-1)\n",
    "\n",
    "# split to train and test dataset\n",
    "train_x = dataset_x[:-test_count]\n",
    "train_y = dataset_y[:-test_count, :, :1]\n",
    "test_x = dataset_x[-test_count-input_days:]\n",
    "test_y = dataset_y[-test_count-input_days:, :, :1]\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 50)            10600     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 50)            20200     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               384128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                5160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 420,129\n",
      "Trainable params: 420,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (input_days, 2), dropout=0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True, dropout=0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dense(units = 40, activation='relu'))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "model.summary()\n",
    "plot_model(model, 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with Open data and Volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1198 samples, validate on 80 samples\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "1198/1198 [==============================] - 3s 3ms/sample - loss: 0.1123 - val_loss: 0.0294\n",
      "Epoch 2/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0381 - val_loss: 0.0046\n",
      "Epoch 3/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 4/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0216 - val_loss: 0.0073\n",
      "Epoch 5/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0185 - val_loss: 0.0100\n",
      "Epoch 6/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0154 - val_loss: 0.0063\n",
      "Epoch 7/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0137 - val_loss: 0.0054\n",
      "Epoch 8/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0126 - val_loss: 0.0044\n",
      "Epoch 9/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0117 - val_loss: 0.0044\n",
      "Epoch 10/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00010: saving model to ./model/LSTM_04_check_point/cp-0010.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "1198/1198 [==============================] - 1s 913us/sample - loss: 0.0106 - val_loss: 0.0043\n",
      "Epoch 11/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0102 - val_loss: 0.0041\n",
      "Epoch 12/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 13/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 14/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 15/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 16/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0096 - val_loss: 0.0068\n",
      "Epoch 17/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 18/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 19/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 20/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00020: saving model to ./model/LSTM_04_check_point/cp-0020.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 21/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 22/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 23/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 24/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 25/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 26/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 27/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 28/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 29/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 30/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00030: saving model to ./model/LSTM_04_check_point/cp-0030.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 31/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0073 - val_loss: 0.0052\n",
      "Epoch 32/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 33/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 34/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 35/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 36/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 37/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 38/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 39/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 40/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00040: saving model to ./model/LSTM_04_check_point/cp-0040.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 41/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0070 - val_loss: 0.0039\n",
      "Epoch 42/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 43/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 44/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 45/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 46/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 47/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 48/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 49/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00050: saving model to ./model/LSTM_04_check_point/cp-0050.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 51/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 52/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 53/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 54/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 55/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 56/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 57/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 58/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 59/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 60/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00060: saving model to ./model/LSTM_04_check_point/cp-0060.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 822us/sample - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 61/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 62/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 63/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 64/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 65/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 66/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 67/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 68/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 69/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 70/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00070: saving model to ./model/LSTM_04_check_point/cp-0070.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 71/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 72/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 73/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 74/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 75/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 76/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 77/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 78/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 79/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 80/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00080: saving model to ./model/LSTM_04_check_point/cp-0080.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 81/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 82/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 83/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 84/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 85/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 86/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 87/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 88/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 89/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 90/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00090: saving model to ./model/LSTM_04_check_point/cp-0090.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 91/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 92/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 93/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 94/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 95/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 96/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 97/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 98/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 99/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 100/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00100: saving model to ./model/LSTM_04_check_point/cp-0100.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 101/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 102/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 103/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 104/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 105/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 106/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 107/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 108/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 109/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 110/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00110: saving model to ./model/LSTM_04_check_point/cp-0110.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 111/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 112/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 113/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 114/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 115/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 116/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 117/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 118/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 119/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 120/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00120: saving model to ./model/LSTM_04_check_point/cp-0120.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 121/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 122/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 123/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 124/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 125/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 126/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 127/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 128/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 129/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 130/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0033\n",
      "Epoch 00130: saving model to ./model/LSTM_04_check_point/cp-0130.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 131/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 132/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 133/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 134/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 135/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 136/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 137/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 138/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 139/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 140/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00140: saving model to ./model/LSTM_04_check_point/cp-0140.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 141/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 142/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 143/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 144/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 145/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 146/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 147/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 148/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 149/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 150/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00150: saving model to ./model/LSTM_04_check_point/cp-0150.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0030 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 152/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 153/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 154/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 155/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 156/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 157/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 158/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 159/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 160/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00160: saving model to ./model/LSTM_04_check_point/cp-0160.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 161/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 162/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 163/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 164/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 165/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 166/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 167/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 168/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 169/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 170/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00170: saving model to ./model/LSTM_04_check_point/cp-0170.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 171/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 172/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 173/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 174/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 175/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 176/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 177/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 178/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 179/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 180/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00180: saving model to ./model/LSTM_04_check_point/cp-0180.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 181/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 182/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 183/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 184/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 185/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 186/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 187/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 188/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 189/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 190/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00190: saving model to ./model/LSTM_04_check_point/cp-0190.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 191/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 192/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 193/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 194/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 195/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 196/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 197/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 198/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 199/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 200/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00200: saving model to ./model/LSTM_04_check_point/cp-0200.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 202/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 203/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 204/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 205/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 206/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 207/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 208/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 209/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 210/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00210: saving model to ./model/LSTM_04_check_point/cp-0210.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 211/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 212/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 213/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 214/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 215/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 216/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 217/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 218/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 219/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 220/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00220: saving model to ./model/LSTM_04_check_point/cp-0220.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 221/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 222/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 223/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 224/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 225/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 226/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 227/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 228/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 229/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 230/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00230: saving model to ./model/LSTM_04_check_point/cp-0230.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 822us/sample - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 231/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 232/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 233/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 234/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 235/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 236/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 237/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 238/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 239/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 240/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00240: saving model to ./model/LSTM_04_check_point/cp-0240.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 241/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 242/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 243/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 244/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 245/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 246/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 247/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 248/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 249/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 250/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00250: saving model to ./model/LSTM_04_check_point/cp-0250.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 251/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 253/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 254/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 255/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 256/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 257/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 258/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 259/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 260/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00260: saving model to ./model/LSTM_04_check_point/cp-0260.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 261/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 262/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 263/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 264/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 265/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 266/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 267/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 268/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 269/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 270/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00270: saving model to ./model/LSTM_04_check_point/cp-0270.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 271/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 272/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 273/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 274/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 275/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 276/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 277/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 278/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 279/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 280/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00280: saving model to ./model/LSTM_04_check_point/cp-0280.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 281/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 282/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 283/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 284/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 285/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 286/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 287/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 288/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 289/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 290/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00290: saving model to ./model/LSTM_04_check_point/cp-0290.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 291/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 292/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 293/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 294/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 295/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 296/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 297/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 298/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 299/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 300/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00300: saving model to ./model/LSTM_04_check_point/cp-0300.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 301/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 303/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 304/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 305/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 306/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 307/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 308/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 309/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 310/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00310: saving model to ./model/LSTM_04_check_point/cp-0310.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 311/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 312/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 313/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 314/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 315/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 316/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 317/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 318/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 319/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 320/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00320: saving model to ./model/LSTM_04_check_point/cp-0320.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 321/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0016 - val_loss: 9.1725e-04\n",
      "Epoch 322/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 323/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 324/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 325/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 326/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 327/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 328/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 329/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 330/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00330: saving model to ./model/LSTM_04_check_point/cp-0330.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 331/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0016 - val_loss: 9.9787e-04\n",
      "Epoch 332/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 333/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 334/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 335/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 336/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 337/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 338/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 339/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 340/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00340: saving model to ./model/LSTM_04_check_point/cp-0340.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 341/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 342/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 343/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 344/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 9.9545e-04\n",
      "Epoch 345/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 346/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 347/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 348/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 349/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 350/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00350: saving model to ./model/LSTM_04_check_point/cp-0350.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 782us/sample - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 351/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 353/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 354/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 355/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 356/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 357/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 358/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 359/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 360/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00360: saving model to ./model/LSTM_04_check_point/cp-0360.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 361/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 362/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 363/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 364/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 365/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 366/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 367/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 368/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 9.1148e-04\n",
      "Epoch 369/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 370/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00370: saving model to ./model/LSTM_04_check_point/cp-0370.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0013 - val_loss: 9.4158e-04\n",
      "Epoch 371/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 372/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 373/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 374/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 375/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 376/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 377/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 9.4319e-04\n",
      "Epoch 378/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 379/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 380/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00380: saving model to ./model/LSTM_04_check_point/cp-0380.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0013 - val_loss: 9.3094e-04\n",
      "Epoch 381/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0013 - val_loss: 9.7881e-04\n",
      "Epoch 382/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 9.4153e-04\n",
      "Epoch 383/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 384/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0017 - val_loss: 9.6986e-04\n",
      "Epoch 385/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0012 - val_loss: 9.6581e-04\n",
      "Epoch 386/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0013 - val_loss: 9.8142e-04\n",
      "Epoch 387/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 388/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 389/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 390/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00390: saving model to ./model/LSTM_04_check_point/cp-0390.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 848us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 391/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 392/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 393/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 394/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 395/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 396/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 397/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0013 - val_loss: 9.1450e-04\n",
      "Epoch 398/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 399/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 400/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00400: saving model to ./model/LSTM_04_check_point/cp-0400.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 401/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 402/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 403/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 404/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 405/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 406/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 9.2420e-04\n",
      "Epoch 407/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 408/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 409/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 410/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00410: saving model to ./model/LSTM_04_check_point/cp-0410.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 821us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 411/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 412/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 9.7176e-04\n",
      "Epoch 413/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0010 - val_loss: 9.9783e-04\n",
      "Epoch 414/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 9.6707e-04\n",
      "Epoch 415/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 416/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 417/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 418/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 419/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 420/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00420: saving model to ./model/LSTM_04_check_point/cp-0420.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 822us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 421/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 422/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 9.7329e-04\n",
      "Epoch 423/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 424/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 425/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 426/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 427/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 9.7973e-04\n",
      "Epoch 428/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 429/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 430/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00430: saving model to ./model/LSTM_04_check_point/cp-0430.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 431/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 432/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 433/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.7159e-04 - val_loss: 9.8588e-04\n",
      "Epoch 434/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0010 - val_loss: 9.2052e-04\n",
      "Epoch 435/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 9.2047e-04\n",
      "Epoch 436/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0012 - val_loss: 9.6899e-04\n",
      "Epoch 437/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0013 - val_loss: 9.3710e-04\n",
      "Epoch 438/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 439/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 440/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00440: saving model to ./model/LSTM_04_check_point/cp-0440.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0011 - val_loss: 9.9841e-04\n",
      "Epoch 441/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 442/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 443/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 9.8055e-04 - val_loss: 9.6267e-04\n",
      "Epoch 444/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 9.8278e-04\n",
      "Epoch 445/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0012 - val_loss: 9.4361e-04\n",
      "Epoch 446/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 9.4048e-04\n",
      "Epoch 447/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 9.7551e-04\n",
      "Epoch 448/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 449/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 9.7223e-04\n",
      "Epoch 450/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00450: saving model to ./model/LSTM_04_check_point/cp-0450.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 795us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 451/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0012 - val_loss: 9.1222e-04\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 453/500\n",
      "1198/1198 [==============================] - 1s 691us/sample - loss: 0.0012 - val_loss: 9.4928e-04\n",
      "Epoch 454/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 455/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 456/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 457/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.5983e-04 - val_loss: 9.2860e-04\n",
      "Epoch 458/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.6609e-04 - val_loss: 9.4502e-04\n",
      "Epoch 459/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 9.3869e-04 - val_loss: 0.0012\n",
      "Epoch 460/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00460: saving model to ./model/LSTM_04_check_point/cp-0460.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 821us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 461/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 462/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.5499e-04 - val_loss: 0.0010\n",
      "Epoch 463/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 464/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 465/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 466/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 9.8903e-04 - val_loss: 0.0013\n",
      "Epoch 467/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 468/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 469/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 470/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 9.9411e-04\n",
      "Epoch 00470: saving model to ./model/LSTM_04_check_point/cp-0470.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 471/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 472/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 8.8998e-04\n",
      "Epoch 473/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 474/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 9.7657e-04 - val_loss: 9.0262e-04\n",
      "Epoch 475/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 9.6222e-04\n",
      "Epoch 476/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0014 - val_loss: 9.8449e-04\n",
      "Epoch 477/500\n",
      "1198/1198 [==============================] - 1s 756us/sample - loss: 0.0011 - val_loss: 8.1933e-04\n",
      "Epoch 478/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 9.4842e-04\n",
      "Epoch 479/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 480/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 9.8728e-04\n",
      "Epoch 00480: saving model to ./model/LSTM_04_check_point/cp-0480.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 9.9823e-04 - val_loss: 0.0011\n",
      "Epoch 481/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 9.3941e-04 - val_loss: 8.9314e-04\n",
      "Epoch 482/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 8.8558e-04 - val_loss: 8.2483e-04\n",
      "Epoch 483/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0011 - val_loss: 9.6872e-04\n",
      "Epoch 484/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.6638e-04 - val_loss: 0.0013\n",
      "Epoch 485/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 486/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 487/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 488/500\n",
      "1198/1198 [==============================] - 1s 743us/sample - loss: 9.3561e-04 - val_loss: 9.4059e-04\n",
      "Epoch 489/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 9.4844e-04 - val_loss: 0.0011\n",
      "Epoch 490/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00490: saving model to ./model/LSTM_04_check_point/cp-0490.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 491/500\n",
      "1198/1198 [==============================] - 1s 769us/sample - loss: 0.0011 - val_loss: 9.0869e-04\n",
      "Epoch 492/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 9.9050e-04 - val_loss: 9.2869e-04\n",
      "Epoch 493/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 8.9531e-04\n",
      "Epoch 494/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0011 - val_loss: 9.0635e-04\n",
      "Epoch 495/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 9.4459e-04 - val_loss: 9.7701e-04\n",
      "Epoch 496/500\n",
      "1198/1198 [==============================] - 1s 704us/sample - loss: 8.4762e-04 - val_loss: 0.0012\n",
      "Epoch 497/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 9.6776e-04 - val_loss: 9.4834e-04\n",
      "Epoch 498/500\n",
      "1198/1198 [==============================] - 1s 717us/sample - loss: 9.8794e-04 - val_loss: 8.2852e-04\n",
      "Epoch 499/500\n",
      "1198/1198 [==============================] - 1s 730us/sample - loss: 0.0010 - val_loss: 8.8472e-04\n",
      "Epoch 500/500\n",
      "1000/1198 [========================>.....] - ETA: 0s - loss: 9.1377e-04\n",
      "Epoch 00500: saving model to ./model/LSTM_04_check_point/cp-0500.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x000001D6C7E8C470>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1198/1198 [==============================] - 1s 808us/sample - loss: 9.1390e-04 - val_loss: 8.3939e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "name = 'LSTM_04'\n",
    "checkpoint_file = './model/' + name + '_check_point/cp-{epoch:04d}.ckpt'\n",
    "try:\n",
    "    os.mkdir('./model/' + name + '_check_point/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# get what we want\n",
    "train_input = train_x\n",
    "train_label = train_y\n",
    "test_input = test_x\n",
    "test_label = test_y\n",
    "train_label = np.squeeze(train_label, axis=1)\n",
    "test_label = np.squeeze(test_label, axis=1)\n",
    "\n",
    "# create callback function\n",
    "cp_callback = ModelCheckpoint(checkpoint_file, save_weights_only=True, verbose=1, period=10)\n",
    "\n",
    "# train the model\n",
    "train = model.fit(train_input, train_label, epochs=epochs, batch_size=batch_size, callbacks=[cp_callback], \n",
    "                  validation_data=(test_input, test_label))\n",
    "\n",
    "# save model\n",
    "model.save('./model/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['loss'])\n",
    "plt.plot(train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1) [[773.1126 ]\n",
      " [769.07367]\n",
      " [775.6963 ]\n",
      " [786.78876]\n",
      " [801.51904]\n",
      " [810.9117 ]\n",
      " [807.33685]\n",
      " [806.2287 ]\n",
      " [807.74194]\n",
      " [812.88586]\n",
      " [810.9167 ]\n",
      " [803.30457]\n",
      " [796.49866]\n",
      " [800.67004]\n",
      " [823.85754]\n",
      " [826.18085]\n",
      " [832.57007]\n",
      " [839.85626]\n",
      " [844.7038 ]\n",
      " [827.3461 ]]\n"
     ]
    }
   ],
   "source": [
    "# local data\n",
    "# model.load_weights('./model/LSTM_03_check_point/cp-{epoch:04d}.ckpt'.format(epoch=600))\n",
    "testing_data = open_data[-test_count-input_days:]\n",
    "output_prices = []\n",
    "for i in range(test_count):\n",
    "    sc = MinMaxScaler()\n",
    "    test = testing_data[i:i+input_days]\n",
    "    test_mean = np.mean(test)\n",
    "    test = sc.getScalerData(test, offset=offset)\n",
    "    output = np.squeeze(model.predict(np.append(np.expand_dims(test, axis=0), test_x[i:i+1, :, 1:2], axis=-1)), axis=0)\n",
    "    output_prices.append(test_mean * (1 + label_sc.getInverseData(output)))\n",
    "\n",
    "output_prices = np.asarray(output_prices)\n",
    "print(output_prices.shape, output_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(test_data_t[:, 0], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(output_prices, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Time(days)')\n",
    "plt.ylabel('Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlib]",
   "language": "python",
   "name": "conda-env-dlib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
