{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./dataset/Google_Stock_Price/Google_Stock_Price_Train.csv').values\n",
    "test_data = pd.read_csv('./dataset/Google_Stock_Price/Google_Stock_Price_Test.csv').values\n",
    "\n",
    "# parameter\n",
    "input_days = 10\n",
    "local_norm_flag = True\n",
    "epochs = 1000\n",
    "batch_size = 500\n",
    "period = 100\n",
    "offset = 0.5\n",
    "RADAM = True\n",
    "if RADAM:\n",
    "    from keras_radam import RAdam\n",
    "    from keras_lookahead import Lookahead\n",
    "    optimizer = Lookahead(RAdam())\n",
    "else:\n",
    "    optimizer = 'sgd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix data string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 5)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "# the data[4:6] must be fix\n",
    "def str2float(data):\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        try:\n",
    "            data[i] = data[i].replace(',', '')\n",
    "        except AttributeError:\n",
    "            data[i] = data[i]\n",
    "    return np.asarray(data, dtype=np.float)\n",
    "    \n",
    "# fix all data in dataset\n",
    "def fixStr2Float(dataset):\n",
    "    shape = dataset.shape\n",
    "    dataset_t = np.zeros((0, shape[-1]), np.float)\n",
    "    for i, data in enumerate(dataset):\n",
    "        dataset_t = np.append(dataset_t, np.expand_dims(str2float(data), axis=0), axis=0)\n",
    "    return dataset_t\n",
    "\n",
    "# trainsform\n",
    "train_data_t = fixStr2Float(train_data[:, 1:])\n",
    "test_data_t = fixStr2Float(test_data[:, 1:])\n",
    "\n",
    "print(train_data_t.shape)\n",
    "print(test_data_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    __min = 0.\n",
    "    __max = 1.\n",
    "    __range = 1.\n",
    "    __feature_range = (0, 1)\n",
    "    __scale = 1.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def getScalerData(self, dataset, offset=0.1, feature_range=(0, 1)):\n",
    "        data_max = np.max(dataset)\n",
    "        data_min = np.min(dataset)\n",
    "        if len(dataset) == 1:\n",
    "            range_temp = dataset * offset\n",
    "        else:\n",
    "            range_temp = (data_max - data_min) * (1 + offset)\n",
    "        self.__min = data_max - range_temp\n",
    "        self.__max = data_min + range_temp\n",
    "        self.__range = self.__max - self.__min\n",
    "        self.__feature_range = feature_range\n",
    "        self.__scale = (feature_range[1] - feature_range[0]) / self.__range\n",
    "        return self.getTransformData(dataset)\n",
    "    def getTransformData(self, dataset):\n",
    "        return (dataset - self.__min) * self.__scale + self.__feature_range[0]\n",
    "    def getInverseData(self, scalerDataset):\n",
    "        return (scalerDataset - self.__feature_range[0]) / self.__scale + self.__min\n",
    "    def getParameter(self):\n",
    "        return self.__min, self.__max, self.__range, self.__feature_range, self.__scale\n",
    "    def updatePatameter(self, parameter):\n",
    "        self.__min, self.__max, self.__range, self.__feature_range, self.__scale = parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset_global(dataset, day_in=60, day_out=1):\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(dataset[i-day_in:i, :])\n",
    "        y.append(dataset[i:i+day_out, :])\n",
    "    return np.asarray(x), np.asarray(y)\n",
    "\n",
    "def genQuteChange(dataset):\n",
    "    return (dataset[1:] - dataset[:-1]) / dataset[:-1]\n",
    "\n",
    "def createDataset_local(dataset, day_in=60, day_out=1, offset=0.1):\n",
    "    sc = MinMaxScaler()\n",
    "    count = len(dataset)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(day_in, count - day_out + 1):\n",
    "        x.append(sc.getScalerData(dataset[i-day_in:i, :], offset=offset))\n",
    "        y.append(sc.getTransformData(dataset[i:i+day_out, :]))\n",
    "    return np.asarray(x), np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 10, 2) (1248, 1, 1)\n",
      "(30, 10, 2) (30, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# append to a big dataset total\n",
    "dataset = np.append(train_data_t, test_data_t, axis=0)\n",
    "test_count = len(test_data_t)\n",
    "\n",
    "# Split dataset to Volume and Open\n",
    "open_data = dataset[:, :1]\n",
    "volume_data = dataset[:, -1:]\n",
    "\n",
    "# use global norm to volume data (with offset)\n",
    "volume_sc = MinMaxScaler()\n",
    "volume_norm = volume_sc.getScalerData(volume_data, offset=0.05, feature_range=(0, 1))\n",
    "\n",
    "# create dataset\n",
    "volume_dataset = createDataset_global(volume_norm, day_in=input_days)\n",
    "if local_norm_flag:\n",
    "    open_dataset = createDataset_local(dataset[:, :1], day_in=input_days, offset=offset)\n",
    "else:\n",
    "    open_sc = MinMaxScaler()\n",
    "    open_qute = genQuteChange(dataset[:, :1])\n",
    "    open_norm = open_sc.getScalerData(open_qute, offset=0, feature_range=(0, 1))\n",
    "    open_dataset = createDataset_global(open_norm, day_in=input_days)\n",
    "    # fix volume dataset\n",
    "    volume_dataset = (volume_dataset[0][1:], volume_dataset[1][1:])\n",
    "\n",
    "# create total dataset\n",
    "dataset_x = np.append(open_dataset[0], volume_dataset[0], axis=-1)\n",
    "dataset_y = np.append(open_dataset[1], volume_dataset[1], axis=-1)\n",
    "\n",
    "# split to train and test dataset\n",
    "train_x = dataset_x[:-test_count]\n",
    "train_y = dataset_y[:-test_count, :, :1]\n",
    "test_x = dataset_x[-test_count-input_days:]\n",
    "test_y = dataset_y[-test_count-input_days:, :, :1]\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show volume data detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.66417403] [-0.99747065]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = len(volume_data)\n",
    "min_ = 1\n",
    "max_ = 0\n",
    "stat = []\n",
    "sc = MinMaxScaler()\n",
    "volume_data_temp = sc.getScalerData(volume_data, offset=0, feature_range=(0, 35))\n",
    "for i in range(1, count):\n",
    "    temp = (volume_data[i] - volume_data[i-1]) / volume_data[i-1]\n",
    "    stat.append(temp[0])\n",
    "    if temp > max_:\n",
    "        max_ = temp\n",
    "    elif temp < min_:\n",
    "        min_ = temp\n",
    "print(max_, min_)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(volume_data_temp, color = 'blue', label = 'value')\n",
    "plt.plot(stat, color = 'red', label = 'amplitude')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Time(days)')\n",
    "plt.ylabel('Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 50)            10600     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               64128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                5160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 120,329\n",
      "Trainable params: 120,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Training\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (input_days, 2), dropout=0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True, dropout=0.2))\n",
    "model.add(LSTM(units = 50, return_sequences = True, dropout=0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dense(units = 40, activation='relu'))\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "model.summary()\n",
    "plot_model(model, 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with `Open` data and `Volume` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1248 samples, validate on 30 samples\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "1248/1248 [==============================] - 2s 2ms/sample - loss: 0.3555 - val_loss: 0.7563\n",
      "Epoch 2/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3502 - val_loss: 0.7580\n",
      "Epoch 3/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3504 - val_loss: 0.7540\n",
      "Epoch 4/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.3487 - val_loss: 0.7510\n",
      "Epoch 5/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.3445 - val_loss: 0.7490\n",
      "Epoch 6/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3424 - val_loss: 0.7394\n",
      "Epoch 7/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.3369 - val_loss: 0.7360\n",
      "Epoch 8/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3322 - val_loss: 0.7221\n",
      "Epoch 9/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.3276 - val_loss: 0.7176\n",
      "Epoch 10/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3186 - val_loss: 0.7136\n",
      "Epoch 11/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.3150 - val_loss: 0.6929\n",
      "Epoch 12/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.3045 - val_loss: 0.6873\n",
      "Epoch 13/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.2946 - val_loss: 0.6595\n",
      "Epoch 14/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.2851 - val_loss: 0.6517\n",
      "Epoch 15/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.2686 - val_loss: 0.6446\n",
      "Epoch 16/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.2608 - val_loss: 0.6045\n",
      "Epoch 17/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.2382 - val_loss: 0.5945\n",
      "Epoch 18/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.2224 - val_loss: 0.5416\n",
      "Epoch 19/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.2091 - val_loss: 0.5290\n",
      "Epoch 20/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.1778 - val_loss: 0.5173\n",
      "Epoch 21/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.1678 - val_loss: 0.4494\n",
      "Epoch 22/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.1423 - val_loss: 0.4372\n",
      "Epoch 23/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.1243 - val_loss: 0.3689\n",
      "Epoch 24/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.1151 - val_loss: 0.3614\n",
      "Epoch 25/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0963 - val_loss: 0.3567\n",
      "Epoch 26/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.1024 - val_loss: 0.3209\n",
      "Epoch 27/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0997 - val_loss: 0.3285\n",
      "Epoch 28/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0984 - val_loss: 0.3203\n",
      "Epoch 29/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0976 - val_loss: 0.3302\n",
      "Epoch 30/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0961 - val_loss: 0.3336\n",
      "Epoch 31/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0932 - val_loss: 0.3391\n",
      "Epoch 32/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0922 - val_loss: 0.3380\n",
      "Epoch 33/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0890 - val_loss: 0.3392\n",
      "Epoch 34/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0911 - val_loss: 0.3362\n",
      "Epoch 35/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0882 - val_loss: 0.3353\n",
      "Epoch 36/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0895 - val_loss: 0.3349\n",
      "Epoch 37/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0871 - val_loss: 0.3348\n",
      "Epoch 38/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0827 - val_loss: 0.3321\n",
      "Epoch 39/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0850 - val_loss: 0.3313\n",
      "Epoch 40/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0820 - val_loss: 0.3317\n",
      "Epoch 41/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0847 - val_loss: 0.3304\n",
      "Epoch 42/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0818 - val_loss: 0.3302\n",
      "Epoch 43/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0802 - val_loss: 0.3288\n",
      "Epoch 44/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0812 - val_loss: 0.3297\n",
      "Epoch 45/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0796 - val_loss: 0.3286\n",
      "Epoch 46/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0792 - val_loss: 0.3275\n",
      "Epoch 47/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0793 - val_loss: 0.3297\n",
      "Epoch 48/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0778 - val_loss: 0.3286\n",
      "Epoch 49/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0757 - val_loss: 0.3269\n",
      "Epoch 50/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0764 - val_loss: 0.3276\n",
      "Epoch 51/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0744 - val_loss: 0.3263\n",
      "Epoch 52/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0740 - val_loss: 0.3243\n",
      "Epoch 53/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0721 - val_loss: 0.3230\n",
      "Epoch 54/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0717 - val_loss: 0.3224\n",
      "Epoch 55/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0722 - val_loss: 0.3232\n",
      "Epoch 56/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0709 - val_loss: 0.3245\n",
      "Epoch 57/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0711 - val_loss: 0.3217\n",
      "Epoch 58/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0714 - val_loss: 0.3225\n",
      "Epoch 59/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0698 - val_loss: 0.3262\n",
      "Epoch 60/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0690 - val_loss: 0.3205\n",
      "Epoch 61/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0702 - val_loss: 0.3178\n",
      "Epoch 62/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0687 - val_loss: 0.3204\n",
      "Epoch 63/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0691 - val_loss: 0.3205\n",
      "Epoch 64/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0691 - val_loss: 0.3190\n",
      "Epoch 65/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0685 - val_loss: 0.3201\n",
      "Epoch 66/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0678 - val_loss: 0.3200\n",
      "Epoch 67/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0682 - val_loss: 0.3192\n",
      "Epoch 68/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0690 - val_loss: 0.3186\n",
      "Epoch 69/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0689 - val_loss: 0.3166\n",
      "Epoch 70/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0683 - val_loss: 0.3175\n",
      "Epoch 71/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0679 - val_loss: 0.3174\n",
      "Epoch 72/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0676 - val_loss: 0.3195\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0678 - val_loss: 0.3156\n",
      "Epoch 74/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0678 - val_loss: 0.3122\n",
      "Epoch 75/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0681 - val_loss: 0.3159\n",
      "Epoch 76/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0662 - val_loss: 0.3179\n",
      "Epoch 77/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0676 - val_loss: 0.3130\n",
      "Epoch 78/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0663 - val_loss: 0.3140\n",
      "Epoch 79/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0668 - val_loss: 0.3145\n",
      "Epoch 80/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0663 - val_loss: 0.3122\n",
      "Epoch 81/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0663 - val_loss: 0.3122\n",
      "Epoch 82/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0672 - val_loss: 0.3159\n",
      "Epoch 83/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0660 - val_loss: 0.3126\n",
      "Epoch 84/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0665 - val_loss: 0.3110\n",
      "Epoch 85/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0655 - val_loss: 0.3131\n",
      "Epoch 86/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0664 - val_loss: 0.3136\n",
      "Epoch 87/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0651 - val_loss: 0.3128\n",
      "Epoch 88/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0663 - val_loss: 0.3121\n",
      "Epoch 89/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0656 - val_loss: 0.3096\n",
      "Epoch 90/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0654 - val_loss: 0.3126\n",
      "Epoch 91/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0653 - val_loss: 0.3114\n",
      "Epoch 92/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0652 - val_loss: 0.3093\n",
      "Epoch 93/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0669 - val_loss: 0.3087\n",
      "Epoch 94/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0644 - val_loss: 0.3119\n",
      "Epoch 95/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0662 - val_loss: 0.3121\n",
      "Epoch 96/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0649 - val_loss: 0.3102\n",
      "Epoch 97/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0646 - val_loss: 0.3078\n",
      "Epoch 98/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0630 - val_loss: 0.3103\n",
      "Epoch 99/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0641 - val_loss: 0.3081\n",
      "Epoch 100/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0686\n",
      "Epoch 00100: saving model to ./model/LSTM_03_check_point/cp-0100.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From C:\\Users\\DVLAB\\AppData\\anaconda3\\envs\\dlib\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "1248/1248 [==============================] - 0s 300us/sample - loss: 0.0636 - val_loss: 0.3073\n",
      "Epoch 101/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0652 - val_loss: 0.3074\n",
      "Epoch 102/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0634 - val_loss: 0.3091\n",
      "Epoch 103/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0620 - val_loss: 0.3060\n",
      "Epoch 104/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0646 - val_loss: 0.3050\n",
      "Epoch 105/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0630 - val_loss: 0.3088\n",
      "Epoch 106/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0639 - val_loss: 0.3086\n",
      "Epoch 107/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0629 - val_loss: 0.3025\n",
      "Epoch 108/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0644 - val_loss: 0.3059\n",
      "Epoch 109/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0625 - val_loss: 0.3076\n",
      "Epoch 110/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0641 - val_loss: 0.3048\n",
      "Epoch 111/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0627 - val_loss: 0.3055\n",
      "Epoch 112/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0616 - val_loss: 0.3037\n",
      "Epoch 113/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0629 - val_loss: 0.3036\n",
      "Epoch 114/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0621 - val_loss: 0.3056\n",
      "Epoch 115/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0623 - val_loss: 0.3046\n",
      "Epoch 116/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0613 - val_loss: 0.3022\n",
      "Epoch 117/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0605 - val_loss: 0.3049\n",
      "Epoch 118/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0622 - val_loss: 0.3027\n",
      "Epoch 119/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0627 - val_loss: 0.3031\n",
      "Epoch 120/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0620 - val_loss: 0.3026\n",
      "Epoch 121/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0613 - val_loss: 0.3050\n",
      "Epoch 122/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0611 - val_loss: 0.2983\n",
      "Epoch 123/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0604 - val_loss: 0.3023\n",
      "Epoch 124/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0603 - val_loss: 0.3019\n",
      "Epoch 125/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0598 - val_loss: 0.3010\n",
      "Epoch 126/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0602 - val_loss: 0.3004\n",
      "Epoch 127/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0614 - val_loss: 0.3008\n",
      "Epoch 128/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0613 - val_loss: 0.3010\n",
      "Epoch 129/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0603 - val_loss: 0.2967\n",
      "Epoch 130/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0608 - val_loss: 0.3042\n",
      "Epoch 131/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0614 - val_loss: 0.3007\n",
      "Epoch 132/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0610 - val_loss: 0.2990\n",
      "Epoch 133/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0598 - val_loss: 0.3034\n",
      "Epoch 134/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0605 - val_loss: 0.2982\n",
      "Epoch 135/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0605 - val_loss: 0.3005\n",
      "Epoch 136/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0608 - val_loss: 0.3002\n",
      "Epoch 137/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0601 - val_loss: 0.2970\n",
      "Epoch 138/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0605 - val_loss: 0.3028\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0602 - val_loss: 0.2984\n",
      "Epoch 140/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0597 - val_loss: 0.3003\n",
      "Epoch 141/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0610 - val_loss: 0.2980\n",
      "Epoch 142/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0596 - val_loss: 0.2974\n",
      "Epoch 143/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0593 - val_loss: 0.3003\n",
      "Epoch 144/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0589 - val_loss: 0.3004\n",
      "Epoch 145/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0598 - val_loss: 0.2966\n",
      "Epoch 146/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0598 - val_loss: 0.3006\n",
      "Epoch 147/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0603 - val_loss: 0.3016\n",
      "Epoch 148/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0600 - val_loss: 0.2971\n",
      "Epoch 149/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0593 - val_loss: 0.2980\n",
      "Epoch 150/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0600 - val_loss: 0.2998\n",
      "Epoch 151/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0595 - val_loss: 0.2987\n",
      "Epoch 152/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0593 - val_loss: 0.3002\n",
      "Epoch 153/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0586 - val_loss: 0.2957\n",
      "Epoch 154/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0598 - val_loss: 0.2993\n",
      "Epoch 155/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0582 - val_loss: 0.2981\n",
      "Epoch 156/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0582 - val_loss: 0.2993\n",
      "Epoch 157/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0589 - val_loss: 0.2995\n",
      "Epoch 158/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0603 - val_loss: 0.2964\n",
      "Epoch 159/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0599 - val_loss: 0.2976\n",
      "Epoch 160/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0594 - val_loss: 0.2982\n",
      "Epoch 161/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0598 - val_loss: 0.2997\n",
      "Epoch 162/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0612 - val_loss: 0.2969\n",
      "Epoch 163/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0594 - val_loss: 0.2975\n",
      "Epoch 164/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0601 - val_loss: 0.3000\n",
      "Epoch 165/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0590 - val_loss: 0.2986\n",
      "Epoch 166/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0589 - val_loss: 0.2992\n",
      "Epoch 167/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0596 - val_loss: 0.2999\n",
      "Epoch 168/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0595 - val_loss: 0.2968\n",
      "Epoch 169/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0588 - val_loss: 0.2966\n",
      "Epoch 170/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0592 - val_loss: 0.2986\n",
      "Epoch 171/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0595 - val_loss: 0.2966\n",
      "Epoch 172/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0597 - val_loss: 0.3019\n",
      "Epoch 173/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0605 - val_loss: 0.2961\n",
      "Epoch 174/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0595 - val_loss: 0.2967\n",
      "Epoch 175/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0584 - val_loss: 0.2978\n",
      "Epoch 176/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0592 - val_loss: 0.2985\n",
      "Epoch 177/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0587 - val_loss: 0.2965\n",
      "Epoch 178/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0595 - val_loss: 0.2997\n",
      "Epoch 179/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0590 - val_loss: 0.2966\n",
      "Epoch 180/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0591 - val_loss: 0.2998\n",
      "Epoch 181/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0588 - val_loss: 0.2997\n",
      "Epoch 182/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0594 - val_loss: 0.2985\n",
      "Epoch 183/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0581 - val_loss: 0.2990\n",
      "Epoch 184/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0592 - val_loss: 0.2963\n",
      "Epoch 185/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0583 - val_loss: 0.3024\n",
      "Epoch 186/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0597 - val_loss: 0.2985\n",
      "Epoch 187/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0591 - val_loss: 0.3006\n",
      "Epoch 188/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0581 - val_loss: 0.2978\n",
      "Epoch 189/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0592 - val_loss: 0.2984\n",
      "Epoch 190/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0588 - val_loss: 0.2984\n",
      "Epoch 191/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0589 - val_loss: 0.2987\n",
      "Epoch 192/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0592 - val_loss: 0.2974\n",
      "Epoch 193/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0585 - val_loss: 0.2987\n",
      "Epoch 194/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0587 - val_loss: 0.2987\n",
      "Epoch 195/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0594 - val_loss: 0.3020\n",
      "Epoch 196/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0585 - val_loss: 0.2972\n",
      "Epoch 197/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0598 - val_loss: 0.2966\n",
      "Epoch 198/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0588 - val_loss: 0.2996\n",
      "Epoch 199/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0587 - val_loss: 0.2980\n",
      "Epoch 200/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0582\n",
      "Epoch 00200: saving model to ./model/LSTM_03_check_point/cp-0200.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 213us/sample - loss: 0.0581 - val_loss: 0.2973\n",
      "Epoch 201/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0601 - val_loss: 0.2965\n",
      "Epoch 202/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0572 - val_loss: 0.3007\n",
      "Epoch 203/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0593 - val_loss: 0.2963\n",
      "Epoch 204/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0576 - val_loss: 0.2966\n",
      "Epoch 205/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0588 - val_loss: 0.2994\n",
      "Epoch 206/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0590 - val_loss: 0.2990\n",
      "Epoch 207/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0586 - val_loss: 0.2948\n",
      "Epoch 208/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0592 - val_loss: 0.3005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0582 - val_loss: 0.2991\n",
      "Epoch 210/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0582 - val_loss: 0.3004\n",
      "Epoch 211/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0585 - val_loss: 0.2955\n",
      "Epoch 212/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0595 - val_loss: 0.2959\n",
      "Epoch 213/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0584 - val_loss: 0.2974\n",
      "Epoch 214/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0592 - val_loss: 0.2988\n",
      "Epoch 215/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0585 - val_loss: 0.2967\n",
      "Epoch 216/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0586 - val_loss: 0.2977\n",
      "Epoch 217/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0565 - val_loss: 0.2958\n",
      "Epoch 218/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0579 - val_loss: 0.2963\n",
      "Epoch 219/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0583 - val_loss: 0.2996\n",
      "Epoch 220/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0585 - val_loss: 0.2938\n",
      "Epoch 221/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0597 - val_loss: 0.3006\n",
      "Epoch 222/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0588 - val_loss: 0.2984\n",
      "Epoch 223/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0579 - val_loss: 0.2928\n",
      "Epoch 224/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0572 - val_loss: 0.2999\n",
      "Epoch 225/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0581 - val_loss: 0.2955\n",
      "Epoch 226/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0577 - val_loss: 0.2997\n",
      "Epoch 227/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0580 - val_loss: 0.2967\n",
      "Epoch 228/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0584 - val_loss: 0.2967\n",
      "Epoch 229/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0582 - val_loss: 0.2963\n",
      "Epoch 230/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0577 - val_loss: 0.2956\n",
      "Epoch 231/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0573 - val_loss: 0.2972\n",
      "Epoch 232/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0594 - val_loss: 0.2975\n",
      "Epoch 233/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0580 - val_loss: 0.2946\n",
      "Epoch 234/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0584 - val_loss: 0.2955\n",
      "Epoch 235/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0582 - val_loss: 0.2961\n",
      "Epoch 236/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0565 - val_loss: 0.2959\n",
      "Epoch 237/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0583 - val_loss: 0.2982\n",
      "Epoch 238/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0583 - val_loss: 0.2952\n",
      "Epoch 239/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0571 - val_loss: 0.2965\n",
      "Epoch 240/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0574 - val_loss: 0.2952\n",
      "Epoch 241/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0583 - val_loss: 0.3000\n",
      "Epoch 242/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0583 - val_loss: 0.2953\n",
      "Epoch 243/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0578 - val_loss: 0.2967\n",
      "Epoch 244/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0566 - val_loss: 0.2984\n",
      "Epoch 245/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0581 - val_loss: 0.2944\n",
      "Epoch 246/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0577 - val_loss: 0.3023\n",
      "Epoch 247/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0581 - val_loss: 0.2945\n",
      "Epoch 248/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0582 - val_loss: 0.2973\n",
      "Epoch 249/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0579 - val_loss: 0.2991\n",
      "Epoch 250/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0564 - val_loss: 0.2950\n",
      "Epoch 251/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0574 - val_loss: 0.2977\n",
      "Epoch 252/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0585 - val_loss: 0.2935\n",
      "Epoch 253/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0574 - val_loss: 0.2976\n",
      "Epoch 254/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0571 - val_loss: 0.2941\n",
      "Epoch 255/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0577 - val_loss: 0.2976\n",
      "Epoch 256/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0579 - val_loss: 0.2944\n",
      "Epoch 257/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0579 - val_loss: 0.2972\n",
      "Epoch 258/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0563 - val_loss: 0.3000\n",
      "Epoch 259/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0573 - val_loss: 0.2973\n",
      "Epoch 260/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0558 - val_loss: 0.2944\n",
      "Epoch 261/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0564 - val_loss: 0.2992\n",
      "Epoch 262/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0561 - val_loss: 0.2990\n",
      "Epoch 263/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0560 - val_loss: 0.2936\n",
      "Epoch 264/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0573 - val_loss: 0.2953\n",
      "Epoch 265/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0576 - val_loss: 0.2965\n",
      "Epoch 266/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0562 - val_loss: 0.2961\n",
      "Epoch 267/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0575 - val_loss: 0.2954\n",
      "Epoch 268/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0567 - val_loss: 0.3001\n",
      "Epoch 269/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0574 - val_loss: 0.2987\n",
      "Epoch 270/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0569 - val_loss: 0.2976\n",
      "Epoch 271/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0587 - val_loss: 0.3016\n",
      "Epoch 272/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0578 - val_loss: 0.2942\n",
      "Epoch 273/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0567 - val_loss: 0.2966\n",
      "Epoch 274/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0568 - val_loss: 0.2987\n",
      "Epoch 275/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0574 - val_loss: 0.2956\n",
      "Epoch 276/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0578 - val_loss: 0.3003\n",
      "Epoch 277/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0575 - val_loss: 0.2954\n",
      "Epoch 278/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0563 - val_loss: 0.2976\n",
      "Epoch 279/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0567 - val_loss: 0.2975\n",
      "Epoch 280/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0561 - val_loss: 0.2960\n",
      "Epoch 281/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0564 - val_loss: 0.2975\n",
      "Epoch 282/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0566 - val_loss: 0.2985\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0570 - val_loss: 0.2931\n",
      "Epoch 284/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0571 - val_loss: 0.2979\n",
      "Epoch 285/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0579 - val_loss: 0.2947\n",
      "Epoch 286/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0565 - val_loss: 0.2990\n",
      "Epoch 287/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0570 - val_loss: 0.2973\n",
      "Epoch 288/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0565 - val_loss: 0.2997\n",
      "Epoch 289/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0568 - val_loss: 0.2975\n",
      "Epoch 290/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0566 - val_loss: 0.2964\n",
      "Epoch 291/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0556 - val_loss: 0.2985\n",
      "Epoch 292/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0567 - val_loss: 0.2962\n",
      "Epoch 293/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0561 - val_loss: 0.2993\n",
      "Epoch 294/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0548 - val_loss: 0.2946\n",
      "Epoch 295/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0554 - val_loss: 0.2992\n",
      "Epoch 296/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0555 - val_loss: 0.2957\n",
      "Epoch 297/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0575 - val_loss: 0.2988\n",
      "Epoch 298/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0559 - val_loss: 0.2937\n",
      "Epoch 299/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0563 - val_loss: 0.2980\n",
      "Epoch 300/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0517\n",
      "Epoch 00300: saving model to ./model/LSTM_03_check_point/cp-0300.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 200us/sample - loss: 0.0553 - val_loss: 0.2949\n",
      "Epoch 301/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0559 - val_loss: 0.3014\n",
      "Epoch 302/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0568 - val_loss: 0.2998\n",
      "Epoch 303/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0557 - val_loss: 0.2975\n",
      "Epoch 304/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0570 - val_loss: 0.2992\n",
      "Epoch 305/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0559 - val_loss: 0.3016\n",
      "Epoch 306/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0557 - val_loss: 0.2948\n",
      "Epoch 307/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0558 - val_loss: 0.3038\n",
      "Epoch 308/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0553 - val_loss: 0.2914\n",
      "Epoch 309/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0562 - val_loss: 0.3060\n",
      "Epoch 310/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0547 - val_loss: 0.2925\n",
      "Epoch 311/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0567 - val_loss: 0.2999\n",
      "Epoch 312/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0560 - val_loss: 0.2952\n",
      "Epoch 313/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0546 - val_loss: 0.3027\n",
      "Epoch 314/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0553 - val_loss: 0.3004\n",
      "Epoch 315/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0548 - val_loss: 0.2974\n",
      "Epoch 316/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0554 - val_loss: 0.3077\n",
      "Epoch 317/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0549 - val_loss: 0.2957\n",
      "Epoch 318/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0530 - val_loss: 0.3028\n",
      "Epoch 319/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0542 - val_loss: 0.2991\n",
      "Epoch 320/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0548 - val_loss: 0.2964\n",
      "Epoch 321/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0553 - val_loss: 0.2999\n",
      "Epoch 322/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0539 - val_loss: 0.2969\n",
      "Epoch 323/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0537 - val_loss: 0.3021\n",
      "Epoch 324/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0533 - val_loss: 0.2972\n",
      "Epoch 325/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0525 - val_loss: 0.2988\n",
      "Epoch 326/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0541 - val_loss: 0.2970\n",
      "Epoch 327/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0531 - val_loss: 0.3036\n",
      "Epoch 328/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0551 - val_loss: 0.3035\n",
      "Epoch 329/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0534 - val_loss: 0.2998\n",
      "Epoch 330/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0522 - val_loss: 0.2895\n",
      "Epoch 331/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0571 - val_loss: 0.3007\n",
      "Epoch 332/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0537 - val_loss: 0.2998\n",
      "Epoch 333/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0526 - val_loss: 0.2984\n",
      "Epoch 334/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0510 - val_loss: 0.3050\n",
      "Epoch 335/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0540 - val_loss: 0.3156\n",
      "Epoch 336/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0535 - val_loss: 0.2875\n",
      "Epoch 337/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0557 - val_loss: 0.3124\n",
      "Epoch 338/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0538 - val_loss: 0.2911\n",
      "Epoch 339/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0539 - val_loss: 0.2963\n",
      "Epoch 340/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0516 - val_loss: 0.2969\n",
      "Epoch 341/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0518 - val_loss: 0.3013\n",
      "Epoch 342/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0512 - val_loss: 0.2963\n",
      "Epoch 343/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0516 - val_loss: 0.3041\n",
      "Epoch 344/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0512 - val_loss: 0.3063\n",
      "Epoch 345/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0508 - val_loss: 0.3008\n",
      "Epoch 346/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0515 - val_loss: 0.3037\n",
      "Epoch 347/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0486 - val_loss: 0.2950\n",
      "Epoch 348/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0519 - val_loss: 0.3011\n",
      "Epoch 349/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0503 - val_loss: 0.3043\n",
      "Epoch 350/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0490 - val_loss: 0.2961\n",
      "Epoch 351/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0509 - val_loss: 0.3051\n",
      "Epoch 352/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0495 - val_loss: 0.3010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0484 - val_loss: 0.2898\n",
      "Epoch 354/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0496 - val_loss: 0.3035\n",
      "Epoch 355/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0496 - val_loss: 0.3068\n",
      "Epoch 356/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0493 - val_loss: 0.2989\n",
      "Epoch 357/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0480 - val_loss: 0.2963\n",
      "Epoch 358/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0488 - val_loss: 0.2961\n",
      "Epoch 359/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0475 - val_loss: 0.3057\n",
      "Epoch 360/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0484 - val_loss: 0.2986\n",
      "Epoch 361/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0476 - val_loss: 0.3007\n",
      "Epoch 362/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0483 - val_loss: 0.2964\n",
      "Epoch 363/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0470 - val_loss: 0.2962\n",
      "Epoch 364/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0467 - val_loss: 0.3036\n",
      "Epoch 365/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0454 - val_loss: 0.3020\n",
      "Epoch 366/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0479 - val_loss: 0.2917\n",
      "Epoch 367/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0457 - val_loss: 0.2930\n",
      "Epoch 368/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0450 - val_loss: 0.2966\n",
      "Epoch 369/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0452 - val_loss: 0.2929\n",
      "Epoch 370/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0449 - val_loss: 0.2919\n",
      "Epoch 371/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0462 - val_loss: 0.2913\n",
      "Epoch 372/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0432 - val_loss: 0.2939\n",
      "Epoch 373/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0470 - val_loss: 0.2903\n",
      "Epoch 374/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0446 - val_loss: 0.2988\n",
      "Epoch 375/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0448 - val_loss: 0.3061\n",
      "Epoch 376/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0467 - val_loss: 0.3121\n",
      "Epoch 377/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0471 - val_loss: 0.2961\n",
      "Epoch 378/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0451 - val_loss: 0.2724\n",
      "Epoch 379/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0475 - val_loss: 0.2775\n",
      "Epoch 380/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0465 - val_loss: 0.2826\n",
      "Epoch 381/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0435 - val_loss: 0.3000\n",
      "Epoch 382/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0459 - val_loss: 0.2906\n",
      "Epoch 383/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0445 - val_loss: 0.2641\n",
      "Epoch 384/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0475 - val_loss: 0.2733\n",
      "Epoch 385/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0456 - val_loss: 0.3001\n",
      "Epoch 386/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0452 - val_loss: 0.2790\n",
      "Epoch 387/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0426 - val_loss: 0.2929\n",
      "Epoch 388/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0445 - val_loss: 0.2847\n",
      "Epoch 389/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0430 - val_loss: 0.2678\n",
      "Epoch 390/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0461 - val_loss: 0.2929\n",
      "Epoch 391/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0452 - val_loss: 0.2779\n",
      "Epoch 392/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0434 - val_loss: 0.2782\n",
      "Epoch 393/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0431 - val_loss: 0.2972\n",
      "Epoch 394/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0436 - val_loss: 0.2910\n",
      "Epoch 395/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0434 - val_loss: 0.2779\n",
      "Epoch 396/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2853\n",
      "Epoch 397/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0428 - val_loss: 0.2765\n",
      "Epoch 398/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0417 - val_loss: 0.2889\n",
      "Epoch 399/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0423 - val_loss: 0.2964\n",
      "Epoch 400/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0421\n",
      "Epoch 00400: saving model to ./model/LSTM_03_check_point/cp-0400.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 213us/sample - loss: 0.0460 - val_loss: 0.2738\n",
      "Epoch 401/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0420 - val_loss: 0.2842\n",
      "Epoch 402/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0405 - val_loss: 0.2822\n",
      "Epoch 403/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0428 - val_loss: 0.2791\n",
      "Epoch 404/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0421 - val_loss: 0.2826\n",
      "Epoch 405/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0434 - val_loss: 0.2896\n",
      "Epoch 406/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2719\n",
      "Epoch 407/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2738\n",
      "Epoch 408/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2983\n",
      "Epoch 409/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0434 - val_loss: 0.2795\n",
      "Epoch 410/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0435 - val_loss: 0.2793\n",
      "Epoch 411/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2782\n",
      "Epoch 412/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0419 - val_loss: 0.2773\n",
      "Epoch 413/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2944\n",
      "Epoch 414/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0412 - val_loss: 0.2782\n",
      "Epoch 415/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2795\n",
      "Epoch 416/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2753\n",
      "Epoch 417/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2718\n",
      "Epoch 418/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0412 - val_loss: 0.2953\n",
      "Epoch 419/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0429 - val_loss: 0.2850\n",
      "Epoch 420/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0425 - val_loss: 0.2772\n",
      "Epoch 421/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0421 - val_loss: 0.2755\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0433 - val_loss: 0.2819\n",
      "Epoch 423/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0422 - val_loss: 0.2697\n",
      "Epoch 424/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2781\n",
      "Epoch 425/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0422 - val_loss: 0.2742\n",
      "Epoch 426/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2934\n",
      "Epoch 427/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2741\n",
      "Epoch 428/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0451 - val_loss: 0.2710\n",
      "Epoch 429/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2744\n",
      "Epoch 430/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2771\n",
      "Epoch 431/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2860\n",
      "Epoch 432/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0419 - val_loss: 0.2775\n",
      "Epoch 433/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2757\n",
      "Epoch 434/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0431 - val_loss: 0.2893\n",
      "Epoch 435/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2763\n",
      "Epoch 436/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2863\n",
      "Epoch 437/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2938\n",
      "Epoch 438/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2699\n",
      "Epoch 439/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2821\n",
      "Epoch 440/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0418 - val_loss: 0.2774\n",
      "Epoch 441/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0422 - val_loss: 0.2776\n",
      "Epoch 442/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2945\n",
      "Epoch 443/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0409 - val_loss: 0.2798\n",
      "Epoch 444/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2765\n",
      "Epoch 445/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2895\n",
      "Epoch 446/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0411 - val_loss: 0.2636\n",
      "Epoch 447/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0453 - val_loss: 0.2919\n",
      "Epoch 448/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0428 - val_loss: 0.2881\n",
      "Epoch 449/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0440 - val_loss: 0.2731\n",
      "Epoch 450/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0424 - val_loss: 0.2988\n",
      "Epoch 451/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0413 - val_loss: 0.2589\n",
      "Epoch 452/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0435 - val_loss: 0.2997\n",
      "Epoch 453/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0420 - val_loss: 0.2707\n",
      "Epoch 454/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2762\n",
      "Epoch 455/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0414 - val_loss: 0.2921\n",
      "Epoch 456/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0424 - val_loss: 0.2696\n",
      "Epoch 457/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0412 - val_loss: 0.2858\n",
      "Epoch 458/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0423 - val_loss: 0.2790\n",
      "Epoch 459/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0422 - val_loss: 0.2868\n",
      "Epoch 460/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2730\n",
      "Epoch 461/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0421 - val_loss: 0.2873\n",
      "Epoch 462/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0418 - val_loss: 0.2809\n",
      "Epoch 463/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2737\n",
      "Epoch 464/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.3006\n",
      "Epoch 465/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2674\n",
      "Epoch 466/1000\n",
      "1248/1248 [==============================] - ETA: 0s - loss: 0.043 - 0s 138us/sample - loss: 0.0413 - val_loss: 0.2846\n",
      "Epoch 467/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2799\n",
      "Epoch 468/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0427 - val_loss: 0.2694\n",
      "Epoch 469/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0417 - val_loss: 0.2866\n",
      "Epoch 470/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2627\n",
      "Epoch 471/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.3037\n",
      "Epoch 472/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0422 - val_loss: 0.2661\n",
      "Epoch 473/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2903\n",
      "Epoch 474/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2803\n",
      "Epoch 475/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0412 - val_loss: 0.2731\n",
      "Epoch 476/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0413 - val_loss: 0.2992\n",
      "Epoch 477/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0428 - val_loss: 0.2719\n",
      "Epoch 478/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0429 - val_loss: 0.2942\n",
      "Epoch 479/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0412 - val_loss: 0.2726\n",
      "Epoch 480/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0412 - val_loss: 0.2936\n",
      "Epoch 481/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0424 - val_loss: 0.2737\n",
      "Epoch 482/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0419 - val_loss: 0.2960\n",
      "Epoch 483/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0425 - val_loss: 0.2827\n",
      "Epoch 484/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2810\n",
      "Epoch 485/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2817\n",
      "Epoch 486/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2821\n",
      "Epoch 487/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2803\n",
      "Epoch 488/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.2771\n",
      "Epoch 489/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0412 - val_loss: 0.2955\n",
      "Epoch 490/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0411 - val_loss: 0.2619\n",
      "Epoch 491/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0424 - val_loss: 0.3052\n",
      "Epoch 492/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0435 - val_loss: 0.2647\n",
      "Epoch 493/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0422 - val_loss: 0.2919\n",
      "Epoch 494/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.2734\n",
      "Epoch 495/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2879\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0392 - val_loss: 0.2735\n",
      "Epoch 497/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2852\n",
      "Epoch 498/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0427 - val_loss: 0.2790\n",
      "Epoch 499/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0405 - val_loss: 0.2808\n",
      "Epoch 500/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0455\n",
      "Epoch 00500: saving model to ./model/LSTM_03_check_point/cp-0500.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 200us/sample - loss: 0.0422 - val_loss: 0.2822\n",
      "Epoch 501/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0409 - val_loss: 0.2805\n",
      "Epoch 502/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.2812\n",
      "Epoch 503/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2733\n",
      "Epoch 504/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0425 - val_loss: 0.2918\n",
      "Epoch 505/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0425 - val_loss: 0.2711\n",
      "Epoch 506/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2991\n",
      "Epoch 507/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0428 - val_loss: 0.2755\n",
      "Epoch 508/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2929\n",
      "Epoch 509/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0413 - val_loss: 0.2776\n",
      "Epoch 510/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2889\n",
      "Epoch 511/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0407 - val_loss: 0.2781\n",
      "Epoch 512/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0380 - val_loss: 0.2855\n",
      "Epoch 513/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0417 - val_loss: 0.2740\n",
      "Epoch 514/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.2918\n",
      "Epoch 515/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2757\n",
      "Epoch 516/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.2865\n",
      "Epoch 517/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2827\n",
      "Epoch 518/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2761\n",
      "Epoch 519/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0383 - val_loss: 0.2859\n",
      "Epoch 520/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2770\n",
      "Epoch 521/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2886\n",
      "Epoch 522/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2839\n",
      "Epoch 523/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2828\n",
      "Epoch 524/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2865\n",
      "Epoch 525/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0409 - val_loss: 0.2774\n",
      "Epoch 526/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0411 - val_loss: 0.2798\n",
      "Epoch 527/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2847\n",
      "Epoch 528/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2853\n",
      "Epoch 529/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0418 - val_loss: 0.2841\n",
      "Epoch 530/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2794\n",
      "Epoch 531/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0403 - val_loss: 0.2916\n",
      "Epoch 532/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0419 - val_loss: 0.2728\n",
      "Epoch 533/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2862\n",
      "Epoch 534/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2817\n",
      "Epoch 535/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2839\n",
      "Epoch 536/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0399 - val_loss: 0.2906\n",
      "Epoch 537/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2778\n",
      "Epoch 538/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.3002\n",
      "Epoch 539/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2840\n",
      "Epoch 540/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2833\n",
      "Epoch 541/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0417 - val_loss: 0.2851\n",
      "Epoch 542/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2854\n",
      "Epoch 543/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2837\n",
      "Epoch 544/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2727\n",
      "Epoch 545/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2952\n",
      "Epoch 546/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2675\n",
      "Epoch 547/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0419 - val_loss: 0.2992\n",
      "Epoch 548/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2660\n",
      "Epoch 549/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2937\n",
      "Epoch 550/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0428 - val_loss: 0.2908\n",
      "Epoch 551/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0425 - val_loss: 0.2675\n",
      "Epoch 552/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2992\n",
      "Epoch 553/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2781\n",
      "Epoch 554/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2955\n",
      "Epoch 555/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2714\n",
      "Epoch 556/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0424 - val_loss: 0.3043\n",
      "Epoch 557/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2704\n",
      "Epoch 558/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.3026\n",
      "Epoch 559/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2802\n",
      "Epoch 560/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2882\n",
      "Epoch 561/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2807\n",
      "Epoch 562/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0420 - val_loss: 0.2818\n",
      "Epoch 563/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0414 - val_loss: 0.2904\n",
      "Epoch 564/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2805\n",
      "Epoch 565/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2779\n",
      "Epoch 567/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0374 - val_loss: 0.2891\n",
      "Epoch 568/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2768\n",
      "Epoch 569/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2814\n",
      "Epoch 570/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2865\n",
      "Epoch 571/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2792\n",
      "Epoch 572/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2835\n",
      "Epoch 573/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2822\n",
      "Epoch 574/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2794\n",
      "Epoch 575/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2760\n",
      "Epoch 576/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0391 - val_loss: 0.2931\n",
      "Epoch 577/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2763\n",
      "Epoch 578/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2968\n",
      "Epoch 579/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2735\n",
      "Epoch 580/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.3014\n",
      "Epoch 581/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2683\n",
      "Epoch 582/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2945\n",
      "Epoch 583/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2710\n",
      "Epoch 584/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2857\n",
      "Epoch 585/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2893\n",
      "Epoch 586/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2827\n",
      "Epoch 587/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2935\n",
      "Epoch 588/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2793\n",
      "Epoch 589/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2915\n",
      "Epoch 590/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0420 - val_loss: 0.2777\n",
      "Epoch 591/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2855\n",
      "Epoch 592/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0380 - val_loss: 0.2800\n",
      "Epoch 593/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0378 - val_loss: 0.2850\n",
      "Epoch 594/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0391 - val_loss: 0.2835\n",
      "Epoch 595/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2804\n",
      "Epoch 596/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2777\n",
      "Epoch 597/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0403 - val_loss: 0.2811\n",
      "Epoch 598/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2837\n",
      "Epoch 599/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2795\n",
      "Epoch 600/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0441\n",
      "Epoch 00600: saving model to ./model/LSTM_03_check_point/cp-0600.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 200us/sample - loss: 0.0418 - val_loss: 0.2938\n",
      "Epoch 601/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2826\n",
      "Epoch 602/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2998\n",
      "Epoch 603/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2803\n",
      "Epoch 604/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2855\n",
      "Epoch 605/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2926\n",
      "Epoch 606/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2845\n",
      "Epoch 607/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2953\n",
      "Epoch 608/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0409 - val_loss: 0.2843\n",
      "Epoch 609/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2912\n",
      "Epoch 610/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2846\n",
      "Epoch 611/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0391 - val_loss: 0.2832\n",
      "Epoch 612/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2843\n",
      "Epoch 613/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2795\n",
      "Epoch 614/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2778\n",
      "Epoch 615/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2892\n",
      "Epoch 616/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0420 - val_loss: 0.2803\n",
      "Epoch 617/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0380 - val_loss: 0.2880\n",
      "Epoch 618/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2821\n",
      "Epoch 619/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0413 - val_loss: 0.2893\n",
      "Epoch 620/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2887\n",
      "Epoch 621/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0376 - val_loss: 0.2844\n",
      "Epoch 622/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0405 - val_loss: 0.2863\n",
      "Epoch 623/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2912\n",
      "Epoch 624/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2869\n",
      "Epoch 625/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2841\n",
      "Epoch 626/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2911\n",
      "Epoch 627/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2807\n",
      "Epoch 628/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2880\n",
      "Epoch 629/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0373 - val_loss: 0.2802\n",
      "Epoch 630/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2803\n",
      "Epoch 631/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2869\n",
      "Epoch 632/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2745\n",
      "Epoch 633/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2915\n",
      "Epoch 634/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0382 - val_loss: 0.2856\n",
      "Epoch 635/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2892\n",
      "Epoch 636/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2894\n",
      "Epoch 637/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0394 - val_loss: 0.2826\n",
      "Epoch 638/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0414 - val_loss: 0.2822\n",
      "Epoch 639/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0401 - val_loss: 0.2891\n",
      "Epoch 640/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0388 - val_loss: 0.2796\n",
      "Epoch 641/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2921\n",
      "Epoch 642/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0418 - val_loss: 0.2849\n",
      "Epoch 643/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0390 - val_loss: 0.2762\n",
      "Epoch 644/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2852\n",
      "Epoch 645/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2753\n",
      "Epoch 646/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0397 - val_loss: 0.2887\n",
      "Epoch 647/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2797\n",
      "Epoch 648/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2837\n",
      "Epoch 649/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2840\n",
      "Epoch 650/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2767\n",
      "Epoch 651/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2870\n",
      "Epoch 652/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2822\n",
      "Epoch 653/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2817\n",
      "Epoch 654/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2825\n",
      "Epoch 655/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2884\n",
      "Epoch 656/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2756\n",
      "Epoch 657/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.3000\n",
      "Epoch 658/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0423 - val_loss: 0.2717\n",
      "Epoch 659/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2874\n",
      "Epoch 660/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2790\n",
      "Epoch 661/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0392 - val_loss: 0.2723\n",
      "Epoch 662/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0401 - val_loss: 0.2853\n",
      "Epoch 663/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0370 - val_loss: 0.2739\n",
      "Epoch 664/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2917\n",
      "Epoch 665/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2697\n",
      "Epoch 666/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0401 - val_loss: 0.2944\n",
      "Epoch 667/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2762\n",
      "Epoch 668/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2945\n",
      "Epoch 669/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2845\n",
      "Epoch 670/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2963\n",
      "Epoch 671/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2700\n",
      "Epoch 672/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2926\n",
      "Epoch 673/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2856\n",
      "Epoch 674/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2837\n",
      "Epoch 675/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.2772\n",
      "Epoch 676/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2870\n",
      "Epoch 677/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0403 - val_loss: 0.2807\n",
      "Epoch 678/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2927\n",
      "Epoch 679/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2814\n",
      "Epoch 680/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0407 - val_loss: 0.2854\n",
      "Epoch 681/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2844\n",
      "Epoch 682/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0379 - val_loss: 0.2724\n",
      "Epoch 683/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2906\n",
      "Epoch 684/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2714\n",
      "Epoch 685/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0416 - val_loss: 0.2957\n",
      "Epoch 686/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2669\n",
      "Epoch 687/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.3008\n",
      "Epoch 688/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.2800\n",
      "Epoch 689/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2848\n",
      "Epoch 690/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0392 - val_loss: 0.2790\n",
      "Epoch 691/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0402 - val_loss: 0.2924\n",
      "Epoch 692/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2763\n",
      "Epoch 693/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2814\n",
      "Epoch 694/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2781\n",
      "Epoch 695/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2826\n",
      "Epoch 696/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2871\n",
      "Epoch 697/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2763\n",
      "Epoch 698/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2838\n",
      "Epoch 699/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0407 - val_loss: 0.2734\n",
      "Epoch 700/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0352\n",
      "Epoch 00700: saving model to ./model/LSTM_03_check_point/cp-0700.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 200us/sample - loss: 0.0383 - val_loss: 0.2907\n",
      "Epoch 701/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2828\n",
      "Epoch 702/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0376 - val_loss: 0.2892\n",
      "Epoch 703/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0393 - val_loss: 0.2732\n",
      "Epoch 704/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.3033\n",
      "Epoch 706/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0425 - val_loss: 0.2666\n",
      "Epoch 707/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0404 - val_loss: 0.3047\n",
      "Epoch 708/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0409 - val_loss: 0.2633\n",
      "Epoch 709/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0391 - val_loss: 0.2954\n",
      "Epoch 710/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2720\n",
      "Epoch 711/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2880\n",
      "Epoch 712/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2788\n",
      "Epoch 713/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0413 - val_loss: 0.2738\n",
      "Epoch 714/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2925\n",
      "Epoch 715/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2642\n",
      "Epoch 716/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.3014\n",
      "Epoch 717/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0420 - val_loss: 0.2674\n",
      "Epoch 718/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.3035\n",
      "Epoch 719/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2719\n",
      "Epoch 720/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2969\n",
      "Epoch 721/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0392 - val_loss: 0.2735\n",
      "Epoch 722/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2835\n",
      "Epoch 723/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2892\n",
      "Epoch 724/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2801\n",
      "Epoch 725/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2850\n",
      "Epoch 726/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0411 - val_loss: 0.2787\n",
      "Epoch 727/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2783\n",
      "Epoch 728/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2754\n",
      "Epoch 729/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0372 - val_loss: 0.2843\n",
      "Epoch 730/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2747\n",
      "Epoch 731/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2768\n",
      "Epoch 732/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0379 - val_loss: 0.3006\n",
      "Epoch 733/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2678\n",
      "Epoch 734/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0412 - val_loss: 0.2932\n",
      "Epoch 735/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2740\n",
      "Epoch 736/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0425 - val_loss: 0.2839\n",
      "Epoch 737/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2775\n",
      "Epoch 738/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0383 - val_loss: 0.2821\n",
      "Epoch 739/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2746\n",
      "Epoch 740/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2886\n",
      "Epoch 741/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2746\n",
      "Epoch 742/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2863\n",
      "Epoch 743/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2824\n",
      "Epoch 744/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2903\n",
      "Epoch 745/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2808\n",
      "Epoch 746/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2757\n",
      "Epoch 747/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2893\n",
      "Epoch 748/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2785\n",
      "Epoch 749/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2871\n",
      "Epoch 750/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0403 - val_loss: 0.2811\n",
      "Epoch 751/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2817\n",
      "Epoch 752/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0382 - val_loss: 0.2793\n",
      "Epoch 753/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2822\n",
      "Epoch 754/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0380 - val_loss: 0.2865\n",
      "Epoch 755/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2695\n",
      "Epoch 756/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0409 - val_loss: 0.2915\n",
      "Epoch 757/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2706\n",
      "Epoch 758/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0386 - val_loss: 0.3006\n",
      "Epoch 759/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2693\n",
      "Epoch 760/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2951\n",
      "Epoch 761/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2746\n",
      "Epoch 762/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2954\n",
      "Epoch 763/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0418 - val_loss: 0.2730\n",
      "Epoch 764/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2841\n",
      "Epoch 765/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2828\n",
      "Epoch 766/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0416 - val_loss: 0.2787\n",
      "Epoch 767/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2857\n",
      "Epoch 768/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2696\n",
      "Epoch 769/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2868\n",
      "Epoch 770/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2719\n",
      "Epoch 771/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2897\n",
      "Epoch 772/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2762\n",
      "Epoch 773/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2797\n",
      "Epoch 774/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2846\n",
      "Epoch 775/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0378 - val_loss: 0.2805\n",
      "Epoch 776/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2875\n",
      "Epoch 777/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2760\n",
      "Epoch 778/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2846\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2731\n",
      "Epoch 780/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2854\n",
      "Epoch 781/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2901\n",
      "Epoch 782/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2743\n",
      "Epoch 783/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.3057\n",
      "Epoch 784/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2734\n",
      "Epoch 785/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0383 - val_loss: 0.2967\n",
      "Epoch 786/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2751\n",
      "Epoch 787/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0398 - val_loss: 0.2901\n",
      "Epoch 788/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2839\n",
      "Epoch 789/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2834\n",
      "Epoch 790/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0378 - val_loss: 0.2785\n",
      "Epoch 791/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2863\n",
      "Epoch 792/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0383 - val_loss: 0.2742\n",
      "Epoch 793/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2877\n",
      "Epoch 794/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0393 - val_loss: 0.2884\n",
      "Epoch 795/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2802\n",
      "Epoch 796/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2868\n",
      "Epoch 797/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2783\n",
      "Epoch 798/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2837\n",
      "Epoch 799/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2794\n",
      "Epoch 800/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0376\n",
      "Epoch 00800: saving model to ./model/LSTM_03_check_point/cp-0800.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 213us/sample - loss: 0.0391 - val_loss: 0.2794\n",
      "Epoch 801/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2899\n",
      "Epoch 802/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2732\n",
      "Epoch 803/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2838\n",
      "Epoch 804/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2721\n",
      "Epoch 805/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2861\n",
      "Epoch 806/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2904\n",
      "Epoch 807/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2816\n",
      "Epoch 808/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2891\n",
      "Epoch 809/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2793\n",
      "Epoch 810/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2901\n",
      "Epoch 811/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0380 - val_loss: 0.2725\n",
      "Epoch 812/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2920\n",
      "Epoch 813/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0414 - val_loss: 0.2727\n",
      "Epoch 814/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2845\n",
      "Epoch 815/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2795\n",
      "Epoch 816/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2765\n",
      "Epoch 817/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2977\n",
      "Epoch 818/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0405 - val_loss: 0.2766\n",
      "Epoch 819/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2876\n",
      "Epoch 820/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2778\n",
      "Epoch 821/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2826\n",
      "Epoch 822/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2799\n",
      "Epoch 823/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2855\n",
      "Epoch 824/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2807\n",
      "Epoch 825/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2873\n",
      "Epoch 826/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2733\n",
      "Epoch 827/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0390 - val_loss: 0.2906\n",
      "Epoch 828/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2689\n",
      "Epoch 829/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2884\n",
      "Epoch 830/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0403 - val_loss: 0.2872\n",
      "Epoch 831/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2826\n",
      "Epoch 832/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2775\n",
      "Epoch 833/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2832\n",
      "Epoch 834/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2869\n",
      "Epoch 835/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2789\n",
      "Epoch 836/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2860\n",
      "Epoch 837/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0370 - val_loss: 0.2778\n",
      "Epoch 838/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2830\n",
      "Epoch 839/1000\n",
      "1248/1248 [==============================] - 0s 113us/sample - loss: 0.0391 - val_loss: 0.2736\n",
      "Epoch 840/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2876\n",
      "Epoch 841/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0414 - val_loss: 0.2732\n",
      "Epoch 842/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2857\n",
      "Epoch 843/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2812\n",
      "Epoch 844/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0399 - val_loss: 0.2793\n",
      "Epoch 845/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0383 - val_loss: 0.2761\n",
      "Epoch 846/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2826\n",
      "Epoch 847/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0401 - val_loss: 0.2762\n",
      "Epoch 848/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0382 - val_loss: 0.2825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2798\n",
      "Epoch 850/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2835\n",
      "Epoch 851/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2720\n",
      "Epoch 852/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0381 - val_loss: 0.2834\n",
      "Epoch 853/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0383 - val_loss: 0.2749\n",
      "Epoch 854/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0384 - val_loss: 0.2821\n",
      "Epoch 855/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0406 - val_loss: 0.2887\n",
      "Epoch 856/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2782\n",
      "Epoch 857/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0391 - val_loss: 0.2905\n",
      "Epoch 858/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0404 - val_loss: 0.2740\n",
      "Epoch 859/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0403 - val_loss: 0.2895\n",
      "Epoch 860/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2814\n",
      "Epoch 861/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0392 - val_loss: 0.2801\n",
      "Epoch 862/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0381 - val_loss: 0.2828\n",
      "Epoch 863/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2827\n",
      "Epoch 864/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2758\n",
      "Epoch 865/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2922\n",
      "Epoch 866/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0401 - val_loss: 0.2717\n",
      "Epoch 867/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2966\n",
      "Epoch 868/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2721\n",
      "Epoch 869/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2897\n",
      "Epoch 870/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2830\n",
      "Epoch 871/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2709\n",
      "Epoch 872/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.3008\n",
      "Epoch 873/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0416 - val_loss: 0.2703\n",
      "Epoch 874/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0403 - val_loss: 0.2881\n",
      "Epoch 875/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2748\n",
      "Epoch 876/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0409 - val_loss: 0.2887\n",
      "Epoch 877/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0390 - val_loss: 0.2800\n",
      "Epoch 878/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2783\n",
      "Epoch 879/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0391 - val_loss: 0.2758\n",
      "Epoch 880/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.2768\n",
      "Epoch 881/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0385 - val_loss: 0.2790\n",
      "Epoch 882/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2763\n",
      "Epoch 883/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0388 - val_loss: 0.2853\n",
      "Epoch 884/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.2831\n",
      "Epoch 885/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2860\n",
      "Epoch 886/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0373 - val_loss: 0.2791\n",
      "Epoch 887/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0372 - val_loss: 0.2896\n",
      "Epoch 888/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2816\n",
      "Epoch 889/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0398 - val_loss: 0.2911\n",
      "Epoch 890/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2863\n",
      "Epoch 891/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0384 - val_loss: 0.2778\n",
      "Epoch 892/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2895\n",
      "Epoch 893/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0408 - val_loss: 0.2693\n",
      "Epoch 894/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2853\n",
      "Epoch 895/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2796\n",
      "Epoch 896/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2850\n",
      "Epoch 897/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0390 - val_loss: 0.2845\n",
      "Epoch 898/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2821\n",
      "Epoch 899/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0384 - val_loss: 0.2840\n",
      "Epoch 900/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0443\n",
      "Epoch 00900: saving model to ./model/LSTM_03_check_point/cp-0900.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 200us/sample - loss: 0.0396 - val_loss: 0.2864\n",
      "Epoch 901/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0392 - val_loss: 0.2774\n",
      "Epoch 902/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0377 - val_loss: 0.2873\n",
      "Epoch 903/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2672\n",
      "Epoch 904/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2817\n",
      "Epoch 905/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0381 - val_loss: 0.2740\n",
      "Epoch 906/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0391 - val_loss: 0.2839\n",
      "Epoch 907/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0395 - val_loss: 0.2774\n",
      "Epoch 908/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2720\n",
      "Epoch 909/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0392 - val_loss: 0.2937\n",
      "Epoch 910/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2702\n",
      "Epoch 911/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2975\n",
      "Epoch 912/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2706\n",
      "Epoch 913/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0406 - val_loss: 0.2874\n",
      "Epoch 914/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0374 - val_loss: 0.2778\n",
      "Epoch 915/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0395 - val_loss: 0.2836\n",
      "Epoch 916/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2653\n",
      "Epoch 917/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0415 - val_loss: 0.2915\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2721\n",
      "Epoch 919/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2821\n",
      "Epoch 920/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2828\n",
      "Epoch 921/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0407 - val_loss: 0.2767\n",
      "Epoch 922/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2803\n",
      "Epoch 923/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.2736\n",
      "Epoch 924/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0381 - val_loss: 0.2859\n",
      "Epoch 925/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0375 - val_loss: 0.2746\n",
      "Epoch 926/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.2856\n",
      "Epoch 927/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0423 - val_loss: 0.2780\n",
      "Epoch 928/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0384 - val_loss: 0.2883\n",
      "Epoch 929/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0373 - val_loss: 0.2813\n",
      "Epoch 930/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0401 - val_loss: 0.2779\n",
      "Epoch 931/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2864\n",
      "Epoch 932/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2775\n",
      "Epoch 933/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2866\n",
      "Epoch 934/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2919\n",
      "Epoch 935/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2777\n",
      "Epoch 936/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0398 - val_loss: 0.2849\n",
      "Epoch 937/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0417 - val_loss: 0.2825\n",
      "Epoch 938/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0410 - val_loss: 0.2871\n",
      "Epoch 939/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0396 - val_loss: 0.2685\n",
      "Epoch 940/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2877\n",
      "Epoch 941/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2728\n",
      "Epoch 942/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2886\n",
      "Epoch 943/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0404 - val_loss: 0.2691\n",
      "Epoch 944/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0382 - val_loss: 0.2893\n",
      "Epoch 945/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0389 - val_loss: 0.2760\n",
      "Epoch 946/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0391 - val_loss: 0.2847\n",
      "Epoch 947/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0384 - val_loss: 0.2744\n",
      "Epoch 948/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2920\n",
      "Epoch 949/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0384 - val_loss: 0.2839\n",
      "Epoch 950/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0391 - val_loss: 0.2771\n",
      "Epoch 951/1000\n",
      "1248/1248 [==============================] - 0s 150us/sample - loss: 0.0389 - val_loss: 0.2948\n",
      "Epoch 952/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2718\n",
      "Epoch 953/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0380 - val_loss: 0.2822\n",
      "Epoch 954/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0391 - val_loss: 0.2718\n",
      "Epoch 955/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2820\n",
      "Epoch 956/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0389 - val_loss: 0.2720\n",
      "Epoch 957/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0379 - val_loss: 0.2799\n",
      "Epoch 958/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2797\n",
      "Epoch 959/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0396 - val_loss: 0.2833\n",
      "Epoch 960/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2760\n",
      "Epoch 961/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2994\n",
      "Epoch 962/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0402 - val_loss: 0.2719\n",
      "Epoch 963/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0400 - val_loss: 0.2903\n",
      "Epoch 964/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2884\n",
      "Epoch 965/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2769\n",
      "Epoch 966/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2889\n",
      "Epoch 967/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0385 - val_loss: 0.2697\n",
      "Epoch 968/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0410 - val_loss: 0.2889\n",
      "Epoch 969/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2767\n",
      "Epoch 970/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0386 - val_loss: 0.2886\n",
      "Epoch 971/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2817\n",
      "Epoch 972/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0408 - val_loss: 0.2722\n",
      "Epoch 973/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0415 - val_loss: 0.2895\n",
      "Epoch 974/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2719\n",
      "Epoch 975/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0387 - val_loss: 0.2890\n",
      "Epoch 976/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0394 - val_loss: 0.2693\n",
      "Epoch 977/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0386 - val_loss: 0.2837\n",
      "Epoch 978/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0393 - val_loss: 0.2633\n",
      "Epoch 979/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0376 - val_loss: 0.2896\n",
      "Epoch 980/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0400 - val_loss: 0.2691\n",
      "Epoch 981/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0383 - val_loss: 0.2850\n",
      "Epoch 982/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0387 - val_loss: 0.2728\n",
      "Epoch 983/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0409 - val_loss: 0.2802\n",
      "Epoch 984/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0383 - val_loss: 0.2833\n",
      "Epoch 985/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2724\n",
      "Epoch 986/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0397 - val_loss: 0.2789\n",
      "Epoch 987/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0379 - val_loss: 0.2783\n",
      "Epoch 988/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0378 - val_loss: 0.2755\n",
      "Epoch 989/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0402 - val_loss: 0.2802\n",
      "Epoch 990/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2722\n",
      "Epoch 991/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0399 - val_loss: 0.2914\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2738\n",
      "Epoch 993/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0394 - val_loss: 0.2841\n",
      "Epoch 994/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0393 - val_loss: 0.2777\n",
      "Epoch 995/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0378 - val_loss: 0.2825\n",
      "Epoch 996/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0388 - val_loss: 0.2824\n",
      "Epoch 997/1000\n",
      "1248/1248 [==============================] - 0s 125us/sample - loss: 0.0383 - val_loss: 0.2833\n",
      "Epoch 998/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0381 - val_loss: 0.2930\n",
      "Epoch 999/1000\n",
      "1248/1248 [==============================] - 0s 138us/sample - loss: 0.0397 - val_loss: 0.2753\n",
      "Epoch 1000/1000\n",
      " 500/1248 [===========>..................] - ETA: 0s - loss: 0.0433\n",
      "Epoch 01000: saving model to ./model/LSTM_03_check_point/cp-1000.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<keras_lookahead.optimizers.Lookahead object at 0x000002063F031F60>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "1248/1248 [==============================] - 0s 225us/sample - loss: 0.0395 - val_loss: 0.2852\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "name = 'LSTM_03'\n",
    "checkpoint_file = './model/' + name + '_check_point/cp-{epoch:04d}.ckpt'\n",
    "try:\n",
    "    os.mkdir('./model/' + name + '_check_point/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# get what we want\n",
    "train_input = train_x\n",
    "train_label = train_y\n",
    "test_input = test_x\n",
    "test_label = test_y\n",
    "train_label = np.squeeze(train_label, axis=1)\n",
    "test_label = np.squeeze(test_label, axis=1)\n",
    "\n",
    "# create callback function\n",
    "cp_callback = ModelCheckpoint(checkpoint_file, save_weights_only=True, verbose=1, period=period)\n",
    "\n",
    "# train the model\n",
    "train = model.fit(train_input, train_label, epochs=epochs, batch_size=batch_size, callbacks=[cp_callback], \n",
    "                  validation_data=(test_input, test_label))\n",
    "\n",
    "# save model\n",
    "model.save('./model/' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl8HHX9+PHXO5ts7jvpmV6UAqUHvSiXch/lKgrKrYhK1Z+IflWwBQFFUb5flUsRqIKiCMipFQrFFsqhUJpy9qTpnZ5prua+9v374zObbJLN0TabpNn38/HYx+7MfGbmM9nNvOdzzGdEVTHGGGMAYvo6A8YYY/oPCwrGGGOaWVAwxhjTzIKCMcaYZhYUjDHGNLOgYIwxppkFBWO6SUT+LCI/72bazSJy5sFux5jeZkHBGGNMMwsKxhhjmllQMAOKV21zo4h8LCJVIvKIiAwWkZdFpEJEFotIZkj62SKySkTKRGSpiIwPWTZVRN731vs7kNBmXxeIyIfeuv8VkckHmOfrRKRAREpEZIGIDPPmi4jcIyJ7RKTcO6aJ3rLzRGS1l7ftIvLDA/qDGdOGBQUzEF0CnAUcAVwIvAzcDOTgfvM3AIjIEcCTwPeAXGAh8C8R8YuIH/gH8FcgC3jG2y7eutOAR4FvANnAw8ACEYnfn4yKyOnAL4FLgaHAFuApb/HZwMnecWQAlwHF3rJHgG+oaiowEXhtf/ZrTEcsKJiB6LequltVtwNvActU9QNVrQNeAKZ66S4DXlLVf6tqA/BrIBE4ETgeiAPuVdUGVX0WWB6yj+uAh1V1mao2qepjQJ233v64CnhUVd/38jcPOEFERgMNQCpwFCCqukZVd3rrNQBHi0iaqpaq6vv7uV9jwrKgYAai3SGfa8JMp3ifh+GuzAFQ1QCwDRjuLduurUeM3BLyeRTwA6/qqExEyoAR3nr7o20eKnGlgeGq+hrwO+ABYLeIzBeRNC/pJcB5wBYReUNETtjP/RoTlgUFE8124E7ugKvDx53YtwM7geHevKCRIZ+3AXeqakbIK0lVnzzIPCTjqqO2A6jq/ao6HZiAq0a60Zu/XFUvAgbhqrme3s/9GhOWBQUTzZ4GzheRM0QkDvgBrgrov8A7QCNwg4jEisjFwMyQdf8AfFNEjvMahJNF5HwRSd3PPDwBXCsiU7z2iF/gqrs2i8ix3vbjgCqgFmjy2jyuEpF0r9prH9B0EH8HY5pZUDBRS1XXAVcDvwX24hqlL1TVelWtBy4GvgKU4tofng9ZNx/XrvA7b3mBl3Z/87AEuBV4Dlc6GQtc7i1OwwWfUlwVUzGu3QPgS8BmEdkHfNM7DmMOmthDdowxxgRZScEYY0wzCwrGGGOaWVAwxhjTzIKCMcaYZrF9nYH9lZOTo6NHj+7rbBhjzCFlxYoVe1U1t6t0h1xQGD16NPn5+X2dDWOMOaSIyJauU1n1kTHGmBAWFIwxxjSzoGCMMabZIdemYIwxB6KhoYHCwkJqa2v7OisRlZCQQF5eHnFxcQe0vgUFY0xUKCwsJDU1ldGjR9N68NuBQ1UpLi6msLCQMWPGHNA2rPrIGBMVamtryc7OHrABAUBEyM7OPqjSkAUFY0zUGMgBIehgjzF6gkJTI+T/CWr39XVOjDGm34qeoPD2PfDi9+C/v+3rnBhjolBZWRm///3v93u98847j7KysgjkKLzoCQqTv+jeNyzp23wYY6JSR0Ghqanzh+YtXLiQjIyMSGWrnegJCpmj4ew7YfsK2PlxX+fGGBNl5s6dy4YNG5gyZQrHHnssp512GldeeSWTJk0C4HOf+xzTp09nwoQJzJ8/v3m90aNHs3fvXjZv3sz48eO57rrrmDBhAmeffTY1NTU9ns/o6pI67ix49RYoWgtDJ/d1bowxfeSn/1rF6h0927549LA0br9wQofL77rrLlauXMmHH37I0qVLOf/881m5cmVz19FHH32UrKwsampqOPbYY7nkkkvIzs5utY3169fz5JNP8oc//IFLL72U5557jquv7tknsUZXUEjPc+/l2/o2H8aYqDdz5sxW9xLcf//9vPDCCwBs27aN9evXtwsKY8aMYcqUKQBMnz6dzZs393i+oiso+JMhZQjsWtnXOTHG9KHOruh7S3JycvPnpUuXsnjxYt555x2SkpI49dRTw95rEB8f3/zZ5/NFpPooetoUgsacDFvf7etcGGOiTGpqKhUVFWGXlZeXk5mZSVJSEmvXruXdd/vuHBVdJQWA1CFQXQyqEAU3shhj+ofs7GxOOukkJk6cSGJiIoMHD25eNmvWLB566CEmT57MkUceyfHHH99n+Yy+oJCcA011UF8J8al9nRtjTBR54oknws6Pj4/n5ZdfDrss2G6Qk5PDypUtVd8//OEPezx/EI3VR0k57r1qb9/mwxhj+qHoCwqZo937ntV9mg1jjOmPoi8o5M2A2ETY+EZf58QYY/qd6AsKsfEuMGxf0dc5McaYfieiQUFEZonIOhEpEJG5YZbfIyIfeq9PRaR3Rn1KzoHa8l7ZlTHGHEoi1vtIRHzAA8BZQCGwXEQWqGpzZb6q/k9I+u8AUyOVn1b8KVAXvr+wMcZEs0iWFGYCBaq6UVXrgaeAizpJfwXwZATz0yI+zXVJNcaYXnKgQ2cD3HvvvVRXV/dwjsKLZFAYDoQOMlTozWtHREYBY4DXOlg+R0TyRSS/qKjo4HMWn+qCQqDzIWuNMaanHCpBIZI3r4W7XVg7SHs58Kyqhj1Lq+p8YD7AjBkzOtpG9wVvWquvhIT0g96cMcZ0JXTo7LPOOotBgwbx9NNPU1dXx+c//3l++tOfUlVVxaWXXkphYSFNTU3ceuut7N69mx07dnDaaaeRk5PD66+/HtF8RjIoFAIjQqbzgB0dpL0c+HYE89Ja6hD3XrYVhkzqtd0aY/qJl+fCrk96dptDJsG5d3W4OHTo7FdffZVnn32W9957D1Vl9uzZvPnmmxQVFTFs2DBeeuklwI2JlJ6ezt13383rr79OTk5Oz+Y5jEhWHy0HxonIGBHx4078C9omEpEjgUzgnQjmpbUh3rMUbLRUY0wfePXVV3n11VeZOnUq06ZNY+3ataxfv55JkyaxePFifvSjH/HWW2+Rnt77NRkRKymoaqOIXA8sAnzAo6q6SkTuAPJVNRggrgCeUtWDrxbqrmQv2lq3VGOiUydX9L1BVZk3bx7f+MY32i1bsWIFCxcuZN68eZx99tncdtttvZq3iA6Ip6oLgYVt5t3WZvonkcxDWHFJ7r2hdxpujDEmdOjsc845h1tvvZWrrrqKlJQUtm/fTlxcHI2NjWRlZXH11VeTkpLCn//851br9kb1UfSNkgrurmYEGnr+ARXGGBNO6NDZ5557LldeeSUnnHACACkpKTz++OMUFBRw4403EhMTQ1xcHA8++CAAc+bM4dxzz2Xo0KERb2iW3qy16QkzZszQ/Pz8g9/QncNgxrVwzp0Hvy1jTL+3Zs0axo8f39fZ6BXhjlVEVqjqjK7Wjb6xj4LiEq2kYIwxbURxUEiyoGCMMW1EcVBIhIaqvs6FMaYXHWrV5QfiYI8xeoNCYgZUl/R1LowxvSQhIYHi4uIBHRhUleLiYhISEg54G9HZ+wggayxsXNrXuTDG9JK8vDwKCwvpkfHT+rGEhATy8vIOeP3oDQrZY+GjJ6CuEuJT+jo3xpgIi4uLY8yYMX2djX4vequPsg937yUb+jYfxhjTj0RvUMgc5d7LC/s2H8YY049Eb1CITXTvjbV9mw9jjOlHojgo+N17Y13f5sMYY/qR6A0Kvnj3bkHBGGOaRW9QiPWCQlN93+bDGGP6kegNCj6rPjLGmLaiNyg0lxQsKBhjTFD0BoXmkoJVHxljTFD0BgUR19hsJQVjjGkW0aAgIrNEZJ2IFIjI3A7SXCoiq0VklYg8Ecn8tBMbbyUFY4wJEbGxj0TEBzwAnAUUAstFZIGqrg5JMw6YB5ykqqUiMihS+QnL57eSgjHGhIhkSWEmUKCqG1W1HngKuKhNmuuAB1S1FEBV90QwP+35k9yAeMYYY4DIBoXhwLaQ6UJvXqgjgCNE5D8i8q6IzIpgftpLHQYVO3t1l8YY059FMihImHltn24RC4wDTgWuAP4oIhntNiQyR0TyRSS/R8dCTx9uA+IZY0yISAaFQmBEyHQesCNMmn+qaoOqbgLW4YJEK6o6X1VnqOqM3NzcnsthYhbUlPbc9owx5hAXyaCwHBgnImNExA9cDixok+YfwGkAIpKDq07aGME8tebzQ6Cx13ZnjDH9XcSCgqo2AtcDi4A1wNOqukpE7hCR2V6yRUCxiKwGXgduVNXiSOWpHV8sNDX02u6MMaa/i+jjOFV1IbCwzbzbQj4r8H3v1fti4iBgQcEYY4Ki945mcNVHGoBAU1/nxBhj+oUoDwpeQcmqkIwxBoj6oOANimfPVDDGGCDag0JMnHu3HkjGGANEe1Cw6iNjjGklyoOCVR8ZY0yo6A4KzdVHVlIwxhiI9qDg84KCVR8ZYwxgQcG9W1Awxhgg2oOCVR8ZY0wr0R0UYr2G5kZ7+poxxkC0B4WkbPdetbdv82GMMf1EdAeFZO+R0FW9+xRQY4zpr6I8KHgP7Knswae5GWPMISy6g0KsHxIzoXJ3X+fEGGP6hegOCgApg636yBhjPBYUknOh0oKCMcaABQVIyoKasr7OhTHG9AsWFGLibOhsY4zxRDQoiMgsEVknIgUiMjfM8q+ISJGIfOi9vh7J/IQVE2tBwRhjPLGR2rCI+IAHgLOAQmC5iCxQ1dVtkv5dVa+PVD66FBNrz2g2xhhPJEsKM4ECVd2oqvXAU8BFEdzfgYnx2dhHxhjjiWRQGA5sC5ku9Oa1dYmIfCwiz4rIiHAbEpE5IpIvIvlFRT18o5lVHxljTLNIBgUJM0/bTP8LGK2qk4HFwGPhNqSq81V1hqrOyM3N7dlcWlAwxphmkQwKhUDolX8esCM0gaoWq2pwiNI/ANMjmJ/wfHHWpmCMMZ5IBoXlwDgRGSMifuByYEFoAhEZGjI5G1gTwfyEF+OzkoIxxngi1vtIVRtF5HpgEeADHlXVVSJyB5CvqguAG0RkNtAIlABfiVR+OhQTa09eM8YYT8SCAoCqLgQWtpl3W8jnecC8SOahSzGxoE2gChKuGcQYY6KH3dEc48VFa1cwxhgLCi1BwdoVjDHGgoIFBWOMaWZBoTkoWGOzMcZYULA2BWOMaWZBIcbn3q36yBhjLCjgi3PvFhSMMcaCQnP1kd3AZowxFhSIT3PvtfZITmOMsaCQMti9V/bwkNzGGHMIsqCQ4g3FXbm7b/NhjDH9gAWFxEz3Xlvet/kwxph+wIJCjPU+MsaYIAsKNsyFMcY0s6BgQcEYY5pZUIiJAcSCgjHG0M2gICLfFZE0cR4RkfdF5OxIZ67XxMRaUDDGGLpfUviqqu4DzgZygWuBuyKWq97mi7OgYIwxdD8oBJ9TeR7wJ1X9KGRexyuJzBKRdSJSICJzO0n3BRFREZnRzfz0rJhYGyXVGGPoflBYISKv4oLCIhFJBQKdrSAiPuAB4FzgaOAKETk6TLpU4AZg2f5kvEfF+KykYIwxdD8ofA2YCxyrqtVAHK4KqTMzgQJV3aiq9cBTwEVh0v0M+D+gtpt56XkxsTYgnjHG0P2gcAKwTlXLRORq4MdAV7cADwe2hUwXevOaichUYISqvtjZhkRkjojki0h+UVEExiiyhmZjjAG6HxQeBKpF5BjgJmAL8Jcu1gnX5qDNC0VigHuAH3S1c1Wdr6ozVHVGbm5uN7O8H6xNwRhjgO4HhUZVVVz1z32qeh+Q2sU6hcCIkOk8YEfIdCowEVgqIpuB44EFfdLYbCUFY4wBILab6SpEZB7wJeCzXiNyXBfrLAfGicgYYDtwOXBlcKGqlgM5wWkRWQr8UFXzu5/9HmJBwRhjgO6XFC4D6nD3K+zCtQ38qrMVVLURuB5YBKwBnlbVVSJyh4jMPog89zwLCsYYA3SzpKCqu0Tkb8CxInIB8J6qdtWmgKouBBa2mXdbB2lP7U5eIsKCgjHGAN0f5uJS4D3gi8ClwDIR+UIkM9ar7D4FY4wBut+mcAvuHoU9ACKSCywGno1UxnqVlRSMMQbofptCTDAgeIr3Y93+zxdnN68ZYwzdLym8IiKLgCe96cto01ZwSEvKhr2f9nUujDGmz3W3oflGEbkEOAl3U9p8VX0hojnrTdmHw6eLoKkRfN2Nk8YYM/B0+wyoqs8Bz0UwLxFV19jEpr1VHDUkrf3CwRMh0AC7V8KwKb2fOWOM6Sc6bRcQkQoR2RfmVSEi+3orkz3hwaUbOPe+t6isC9OgHAwERet6N1PGGNPPdBoUVDVVVdPCvFJVNcwld/91zIgMVOHXi8Kc+OOS3Htj3w3Uaowx/cHA6UHUhZmjs0hLiOWp5VupbWgz+F1sgntvrOv9jBljTD8SNUEhOT6W+y6fSm1DgKXr2gy/HRvv3q2kYIyJclETFAA+My6HnJR4Xl65s/WCYEmhYhc8cg4sf6T3M2eMMf1AVPW/jPPFMHVkBp9sb/N8IF8siA8+eBzqymHbu+Dzw7Qv9U1GjTGmj0RVSQFg8vB0NhZVUVHb5g7m2AQXEABSBsOC6+GVm6G+yu52NsZEjegLCiMyAFi5vU2P2oYqL8Hl8P/ehYxR8O4D8Ith8LMcWHqXW95Y725yM8aYASjqgsKk4ekAfFxYFj5BxkhIyoLvfgQXPdAyf+kv4ZGz4ee58JeLeiGnxhjT+6IuKGQl+8nLTOTjtu0KQQGvqkgEpl4NPymHH22BsWfAtmVu2Za34dmvwYbXoGwrVO3tncwbY0yERV1QAJicl84nhW2CwvgL3fuEi9uvkJgBlz0O5/4fJGa6eSufhb9+Hu6dBL8aC/+8Hsq3Q8XuyGZ+oKmrhNpD6uZ4Ywa0qOp9FDRxeDoLP9lFeU0D6Yneo6Yve7zzlfxJcNw3XOnh37fBsGnw6cuw5l9u+Qd/dS+Ak74Hw6a6MZWSstzLhHfPBKgtgx/vablfpCt7CyB7rCvNGWN6VFQGhdHZyQBsL61pCQrd5U+G83/jPk+9Cja9CY9d2DrNf+5tPX3KXMgaA9njYPg0O5mFqvXadl7+EVx4b+dpAQoWw+OXwCWPwKSB8/A/Y/qLiAYFEZkF3Af4gD+q6l1tln8T+DbQBFQCc1R1dSTzBDA03d2strO8hqOHHeQQTmNOhv9ZBanD3Cirhe9BySZ453ctad64q/U6Z/4Ecse7QJGc60oSTQ3uYT8DzY4PoHSzey3+CdxW4h5/2tbWd+HNX8Nhp7qxqDa9AXvXw6gTW5/8Ny517yWbIp3z7tn6LuQdG/6Y9pcqNNV3v8TUX6hCxU5IG9bz2w4E4KMnYNKlEOvv+e2bdiIWFETEBzwAnAUUAstFZEGbk/4TqvqQl342cDcwK1J5ChqangjAzvIeGtYiPc/b8GT3AjjrDqgth1XPwyfPwtZ3WtIv/knr9T/3IPzjW+7zGbdB8iA45nLY+RHkHAEJYQJXfTV8+gpM+LwreezbCR8+7qquGutctdYxl0NDjav6aqx3QSdYSmms7/ifbP2/ISEdRsxsv0wVNiyBw07r/ES4fYWr5nlhTuv57/0BGmvgwyfgyHNb5hetgdd+5l6h8h+BJT+FiV+AM29vabPxJ3e8756iCoEmKC6A3x8H33nfVVsFbXkH/jQLTr0ZTv3Rwe/v/cfgX9+F834NM69rv3z3asg6DOISDn5fByIQcF2341Nbz/+p6+bN9fmQmAW/nQoX3g8TPuet54011tHvJdAECMSEaeJc+Rz889uuva4n/sZdqS0Hf2r4vESJSJYUZgIFqroRQESeAi4CmoOCqoa2MCYDGsH8NMtNjccXI+zqqaAQTozPlQCO/bp7lW1zJ/7Rn4F1L8POD1vSBgMCwJI73PuC61tvz+eH9BFQsqH1/H98q/WYTa/9PGTZN1unTR8BR10Ayx5smXfhfa79IyEdVr0Ab/4G6ivcsuP/HwyZ7NpQ4hLh3P+FJy9vWVd8rsrnwydh63/dP1Nw3Y68EvKP3d2n3ZVthbfvdgGz2uvptWiee/n8cPMOqKtwxxA88VQVu95iR53XvX0AbH4b/nw+fOkfMPY0F8BevtG1IwE8fQ2c9F2Y/EU3XbHDve8Juc7Z8l/YvSr8ST3U7090VYkX3geLbnZ/53991y1b+MP261eXwIMnwKQvwiV/bL1s50fwwjfhq6+4v8GBeOtu97v8+r87TrPkJ/Cf+9zfOxiUA4GW5WVbYP6pUF8Jz361JSjcMxE0AD/sYGj6O7Jg6BT4xhvtl9WUuveqPe2XtVW2zeXrQNvwKovg14fDaT+GU27s3jqlmyFz9IHtb9EtcOR5MPqkA1s/QiIZFIYD20KmC4Hj2iYSkW8D3wf8wOnhNiQic4A5ACNHjjzojPlihMGp8eworznobXVbxgj4yovu86lz3fvSu9w/WUN11+s31bcPCLB/g/iVb2sdEKDlRBTOu79vPR0aEAC0CRZ8p2W6q4BwsB44Dva2ObE01UNVEdw9Hg4/Eza9BdctgYU3uUB11bPuJLF+MZx8IwQaISbWXQnWV7uS1M4PYOQJLiAAPD8Hblzf0nGgfLt73/0JPP91WPNPOOpCVwps609e6aeroLBnlXtljIJlD3V97I+e494/ecYFEl98y1MCF3zHBaaXfuAC2GGndr29tpb8tOXzrpXw5/NcZ4ov/8PNCwTcbxWgpqwlKNRXtqy39qWWaW1ygTk5uyV4dmbnh/Cf++GkG8IvX/7Hlra8jtw70V2Y3FzY9f7aWnCDK6mBuzjqTlBY+xI8dSVc/AeYfGn39rPqBfdbSx7kqpjf+Z3r9t6PRDIohGtNbVcSUNUHgAdE5Ergx8A1YdLMB+YDzJgxo0dKE0MzEiNbUuiOU+e6V3WJu6o9YhYULndX9Hs/dfW0QybBuw/CEee47puJGe7K/vVfuCvoQUe7E+NR57tieN50d8Wzb7ur9tj0hruSbGqEwUdDeSEUrW3Jw1EXwNoXQWLc1VxXRn8WNr/Vfn7ese7kXLq5Zd4xV7r64KDDz3RXskMmu8efbv1v621ceD+s+JNrhwB34jvtZvfPWrKxfUAIunu8ey9Y7N4/fhqK17vPfwtpjxh3JvzhdJj2ZZj9W5h/SktpJW14S7qqPW5/wZ9r22qPNf9q6XUGsNo7cTaEXGS8+Wv39/jsDyBlUMv8d34PI0KujV4PKdmFev2Xbr+n3OTaLUJLVb/w6u5vLXaBYedHbvqTZ9zrlt0tVUyr/+naX6ZcBQX/hpwj3XG9/xhccF/7apLiDfCQd+W68XV49yF34+Zpt7SkefBE+NZ/XbXkxpCr+/xHW2+rfKsLCkErn4OJl7hqxczRLu/lISfwf9/qgkJTg/s9xvigpqRleWNdS3tLQ42r3isucPNX/MnND16YlGx0v5/0kO+1rYrdLoglZrYEBGjfEWT9Yq+jyNjW85+60r2ve9kNpnnid1rWrat0JcAzboPkHDfvlZvdKAlDJsG1L3ecr1DrXnbtjkvvcr/Lb7zZvfUOQiSDQiEwImQ6D+jskuEp4MFOlveoIekJrN7RT/rHJ2W11K8H6/HThrYsv+h37deZfX/H20vMhNwjXBVIuCvW6hJ3413WGBg+3f1zhf4jBJrcP+XulRCb6NJVF7sqmuyx7grb53f/1Pt2uCfWjT2tZf3Sze5KyJ/kTmbl21xjfGhDenpe66CQOgymX+NewSuwWb+EY7/mrsKevKJ1lVtnNrzmTshtBa/43/9LS+AN2re9ddrHZrt8gzvGruxe5U7eQcG2kZ0fu7vkx53lAveied07hmDnhKZ6N/5WOGsWuAuJtv58nmvTCbX49vbpygtd4A6tbvndjNZpgtV9L4dcOdeWwas/dsfbWSlg/qmuY0HQaz+H1+5sKfGedYe74AlVXw2/GOp+l9OucQEp6G9fgKyxro3tg7+1VCW2VV0C9091n69+DtLyYF+hO7kOPabl2O+Z4D6nDm29/u6VbvtTr3JVPMFOI6fOg898H9a9BCOOb0m/6nn3GnkC5M2AV+bBjvfdhd7Oj9r/bku3tv5OfxKmyu+2Uhew25bOe4GoRqYaX0RigU+BM4DtwHLgSlVdFZJmnKqu9z5fCNyuqjPCbS9oxowZmp+ff9D5u/Ol1fz13S2suWMWYl1Ee5+qu9rWADxzjbtrPDGjZfnm/7ieR22/m4pdLkDseH//93n6re0bsnvSyTfCm7+K3PbD+ewP4a1f9+4+98fY012Q7i+ufBri01wHga6Mn+0Cb3cd/21XEuhKYpbLxyNndpxmytVw9s/g/8a0nv+5h2DKFd3PUwgRWdHV+RUiGBS8TJwH3Ivrkvqoqt4pIncA+aq6QETuA84EGoBS4PrQoBFOTwWFh97YwF0vr2X1HeeQ5I/K2zUOXY+e277qyYSXkNFyL4g5tGSPa6kGDfrCo64K7gB0NyhEtN+Vqi5U1SNUdayq3unNu01VF3ifv6uqE1R1iqqe1lVA6EnBm9bKqm1Y7ENOaT+5R+FgZRx8p4lWLv6j6xkUdOzXYe4WOPmmlnnjZ/fsPk3ktA0IAEnZ7ef1sKjtjJvhBYXyGgsKh5yKnV2nCYo/yJsTOzLjq/uX/rQfu6J/0Clz4fInwqdNHwFzt7mb+I48D0a16bI49BhXVfH1JXDct+Bb77geLJO/6HoFXfa46xET7K1z+i0tI/4OnugaooNiE2HyZZ3n/auL9u9Yg3xd3IQ3Z+mBbffzD3e+/JxftHwe/VnXvtUZf0rHy866A24IaRO4qZsXJBkj3SCaPWWQ1/6RPqLzdD0gautN0i0oHLqOuQI+erL1vGDf8rfvcT1bnvkKjDsbrnomfEPe5+fD+lfdwIYX3g//6qArZEdOvdk9qa+p3svTle6eiL979zR8ezl88Bd38vcnt7SNrF/kbkI7bV7HD2/yJ7vG1Fu84Bdocj3GHjzRTQ+aALO8E19emNqA8Re2n3fMFa6jwPRrXc+k28tg+/stw67kHtW6W2rQJY+07i0FLV0oX73V3ehYtCb8cVy3xLUZPXyymz7um65Xzik3uWMM9soJ59xfQeoIV4ncAAAW6UlEQVRgePrLXv6vdN/v2oXupszUofCX2e6EnzbMNeaef7frmFBf7Xr+gAu8vji4c4hL+/3VrgvvR0+6YLf2Jdez6s7Brfd/4wbXYaNtz7PO7oEYNtU1IF/1TMu9C6G/veO+2br7sS8emuo63l5Q8iAXQPesat8DKgIi2qYQCT3VprBm5z7Ove8tHrhyGudPHtr1Cqb/UHVdDn87rWXe5x92J4ug4g3uHzPG57roBhrhrd94dwQnup4tFTvhlbnwud/DL/Na7+P0W2HixS29WIJu+ND1xgL4+eCW+0SCJ8pNb7qruaw2DYQdeeoq1yU4aMLFrhtjuPWDJ5h52yG+k6vbA6EKuz5xJ8KnrnBDsXz8tLsnIi7Rncx/6XXvbNuvPlzQnf27lsfZ/v1LrsH2xg3tA8HCm+C9h1u2+/Jc13Pskj92PUZYXaX7fuMS2y9b8jPXAB/sxROqsd71pgvt4Vey0f1OXvuZO3mPv6D1Oi98E0q3wFdfbjney/7menUVF7jpcPu6d5LrOg5u0Mf6Ktj1sWsvSEhz+Xj6y3DBvW4Il2Bg/tI/XAmxocq1C/VAZ5h+0dAcCT0VFCrrGpl4+yJumnUk/+/Uw3sgZ6ZXBe8+PeoCmDnHjUF1MP84oSe2q551XUjB9a1/1qsqajsI351D3Y2HKUM6vlu3K7X74HfHwqDx7gScOarjtDVeg3FoL63etH6xO+mNbXOPaf6f4MXvufG8gqWG28ta99nfvRJGHs+AsGslVO6Gw73qocdmu4uQ74dpEm2ocRckbYcG6UjwdxiBG9q6GxSitvooJT6WnBQ/20q6cTex6X9ScuErC12R3Z908Nu7+jn41/da7k0ImniJ60K45T/tR2U94zZX0rh++YHvNyGt+wGlr4JB0LgOulDOuNZdAR8921VRpQxpHaDjUwZOQAAYMhGY2DJ9TSfdVsOVYjpz5dO9M65XJ6K2pABw5t1vcMTgFH5/1fQe2Z45xO1Z44aKuOqZPv/HNKanWUmhG1ITYqmobezrbJj+YtB4uHZhX+fCmD4VtV1SwVUh7bOgYIwxzaI6KKQlxFFRa11SjTEmKKqDglUfGWNMa1EfFCotKBhjTLOoDgop8XHUNDTR0NSN5wgYY0wUiOqgkJrgOl9ZacEYYxwLCmDtCsYY44nyoOAGxdtnPZCMMQaI8qBgI6UaY0xrUR0UslP8ABRX1fdxTowxpn+I7qCQ7IJCSWU3xjQ3xpgoENGgICKzRGSdiBSIyNwwy78vIqtF5GMRWSIinYwb3PMykvyIWEnBGGOCIhYURMQHPACcCxwNXCEiR7dJ9gEwQ1UnA88C/xep/ITjixGS4nxU1zf15m6NMabfimRJYSZQoKobVbUeeAq4KDSBqr6uqsEHGrwLtHn8VeQlxPmobbCgYIwxENmgMBwIfWJJoTevI18DXg63QETmiEi+iOQXFRX1YBZdUKixoGCMMUBkg0K4ZyOGfaKPiFwNzAB+FW65qs5X1RmqOiM3N7cHswjxcTHUNdgwF8YYA5F9yE4hMCJkOg/Y0TaRiJwJ3AKcoqq93g0oIdaqj4wxJiiSJYXlwDgRGSMifuByoNXDTEVkKvAwMFtV90QwLx1KiIuhttGCgjHGQASDgqo2AtcDi4A1wNOqukpE7hCR2V6yXwEpwDMi8qGIdPIE7MhwDc1WfWSMMRDhZzSr6kJgYZt5t4V8PjOS+++OhDifDXNhjDGeqL6jGSA53p6+ZowxQVEfFIakxbN7Xy2qYTtGGWNMVIn6oDA0PZG6xgAlNtSFMcZYUAiOlFpabUHBGGOiPiikxHuP5KyzbqnGGGNBwQsKVXXW2GyMMVEfFJKbSwoWFIwxJuqDgpUUjDGmRdQHhWQLCsYY0yzqg4I1NBtjTIuoDwoJcTHEiJUUjDEGLCggIqTEx1pDszHGYEEBcFVIVlIwxhgLCoBrbLaSgjHGWFAALCgYY0yQBQUgO9nP3kob+8gYYywoAMMzE9leWt3X2TDGmD5nQQEYlpHIvtpGa2w2xkS9iAYFEZklIutEpEBE5oZZfrKIvC8ijSLyhUjmpTPpiXEA7Ku1x3IaY6JbxIKCiPiAB4BzgaOBK0Tk6DbJtgJfAZ6IVD66IzXB3dVsj+U0xkS7SJYUZgIFqrpRVeuBp4CLQhOo6mZV/RgIRDAfXUpNcCWFP/93c19mwxhj+lwkg8JwYFvIdKE3r98Jjn/0xLKtbN5b1ce5McaYvhPJoCBh5ukBbUhkjojki0h+UVHRQWarvSS/r/nznL/mo3pA2TTGmENeJINCITAiZDoP2HEgG1LV+ao6Q1Vn5Obm9kjmQo0fmsZfvjqT/71kEp/urmTszQspr7ZGZ2NM9IlkUFgOjBORMSLiBy4HFkRwfwfl5CNy+cJ0F8MCCqf8+vU+zpExxvS+iAUFVW0ErgcWAWuAp1V1lYjcISKzAUTkWBEpBL4IPCwiqyKVn+7wxQiLv38KAGXVDYye+xJbi+2mNmNM9JBDrf58xowZmp+fH9F9FOyp4My732yevv+KqVw4eSgi4ZpJjDGm/xORFao6o6t0dkdzGIcPSuW/c0/nipmuOumGJz/gyj8sswZoY8yAZ0GhA8MyEvnlxZNZ9/NZpCfG8c7GYq5+ZBn//HA79Y19eluFMcZEjFUfdUNjU4CbnvuY59/f3jzvzPGDyctMbH4NSktg0vB0AOJ8LtaqqlU5GWP6he5WH1lQ6CZV5ZPt5Tz69ib+8WHXPWuPGpLK2l0VnH7UIEZmJXFYbjJD0hLITvEzbWSmBQtjTK+yoBBh1fWNVNY2sq+2kXc2FnPf4vUcNSSVtwv2dnsb00dlcvmxIyivaWB7WQ3ZyX5GZicTCCgTh6fhi4kh2e8jM9lPfWOAzcVVrNxezgWTh5EY52PNrn2MzU0hPjYGEaGxKUCsV0ppbAoQUJfPjCQ/0Lrk0hRQfDEWmIyJFhYU+oHy6gbeKihi8erdvLZ2D4l+H7v31fX4fmJjhMZAy/eYkxLP3srW+8lNjaeows3z+2JA4PjDsomPjeHfq3cDcMyIDNISYtlWUs3Rw9LYWFTF8YdlU1RZxxen57FiSykfFZZTUdvA6UcOokmVY0dn8f6WUhL9PqaOzCAvM4llm0qYOiKDNTv3cfIRuewqr2VIegIJcb5Wefp0dwW5KfFkJvt7/G9ijGnNgkI/V1hazZC0BN7bVEJdY4Dc1Hi2lVTjixFW79zHzrJahmYk0NikPLV8GyJwwmHZFFfVkZ4YR5I/ltKqenaW1zI4LZ4NRVVsLakmO9nPhOHpfFJYRmnIXdmjs5PYWlJNoM3XnZoQ26ujww5NT+CUI3J5/v3t1De5Bvskv4/rPnsY/3PWEb2WD2OijQUFA0BlXWPzgH8A5TUNVNY1Miw9gdqGAAlxMdQ1BiiqqCMhzkei38eu8lpyUvzsLK8lJyWeV1fvYm9FPcMyEvDFCFNGZFDT0MSefXVU1DUyfkgqG4qqWLapmPe3lhEfG0NuSjz7ahvw+2JYsnYPGUlxlHUxdEhoCWfeuUfxmXE5HDk4tblKzBhz4CwomH5nV3ktKQmxrN9dwfayGnaV15K/uZTzJg/ljXVFvLe5mG0lNWHXTU+M4+5Lj2Hxmt2UVjVQUFTJ4bkpnHh4NieOzSE72U9msp8txVVkJPpJT4rbr7wFAkp9U6BdFZcxA4UFBXNIevHjHdQ2uJLLsk3FLF3X/VFxTz4ilzc/dem/cuJoEv0+DstJ5uJpeTydv42NRZU0BeDR/2zivsunICKccdQgtpZU83T+Nv70n81MGp7Ot087nKaAkpEUx5QRGby3uYThGYlkJMax8JOdpCbEcfSwNI4aksrjy7YyMiuJuBghLTGObSXV7NpXy5eOH0VNQxMp8bHNjfsNTQFKq+sRhNzUeCpqG0iM81Fa3cCyTcWMyUmmtiHA+KGpVNQ2kp3sb1dKamwK0NCkVNc3kpnkJyZGKK9uIDne1yptcWUdWcn+sL3cVJV9tY2kJcQSUDe8i6qyoaiSsbkpHfaMq28MINLS5TpoR1kNVXWNHJabQozA5uJqhmUkEB/bEmD31TawraSaCcPSw267KaAUV9WRmeRvt/3O1DU2ER/r61b370BAiemic0VDU4DYGOlwWw1NgbD5C3bcCASUVTv2MSnPHWdVXSPJISX1zoR2FIkECwpmwCirrmfJmj08nb+NZZtKuO6zY1izs2K/enodqoakJQCwt7KuVWcCgLSEWCblpfOfguLmeYNS47lkeh4PLt3QPG94RiLby8KXwMLxxQhZyX6KKupI9vtce1dpDU0h+z8mL536JmXNzn1ht5Gd7GdUdhLvby1rNf8Ur+NBWmIsyzeXkpEUR0ZiHJtDxhgblZ1Ekj+WPftcB4VVO9w+clL87K2sB1zPvcLS6lYdN4alJ3DU0DQ+2lZGcZVLd/E09wiXytpGXvU6VGQn+7nwmGF8VFhGjAhD0hMYkZmEqvLEsq1U1jcydUQGhaU13HL+eDbvrebFj3ewfk9lq31Nzstgc3EVa3dVEOcT8jKTaGgKUFhaw/ihaUwYlsazKwoBGJmVxHUnH0ZjU4DVO/YxLCORD7aV8cHW0lZteuOHplFZ18C2khqGpicgwGlHDSIjKY7ahgAXTB7K1JGZ3f4uQ1lQMFGhtqEJX4wQI8JDb2xwDfU79vHa2j1U1rl/toykOC46ZhifHZfLH9/eyLsbS5g2MoO9lfVMGp5OU0BpDChfPmEU+VtK2bCnksMHpRAfF8Nra/ZQXFXPpr1VfObwHKaPymRneQ2L1+yhtLqea08cw0eFZazYUtppPvenQT8xzkdNQ1OreX5fDE2qrU7MfaE7bUO+GCGgSk+cWoamJ7CzvPbgNzRA/OaLx3DJ9LwDWteCgjERFKyCSU90bRcB72QdbJco2FNBdX0TIzKTqKxrZERWUrttVNY1UtvQRJLfh98XQ1VdU3M1kKryTH4h00ZlMiIrkdiYGHwxwpbiKkZmJdHQpLyyahenHJGLqpKWEIcINAaU3ftqqW1oYntZLWXV9Zx19GD+9u5WJgxPY0haAoPTEthTUcfo7CSq65vYU1FHRmIciX4fr6zchS9G+MzhOVTWNZKTEk9MDHxSWM7hg1LISPLTFFAqaxtpUuXfq3cxc0w2o7KSUGi+96WxKUB9U4Blm0r4YGsZF00ZBkCG9/cqrW5ABFZsKeXY0VnUNwYYkZVIbUMAnwgl1fWUVNUxfVQW5dUN7K2q46NtZYzOSeawnGR8MdJcNbezvKa5ug1gZ3ktg9LiSU+MY+3OCq/XnXLh5GEUFFXS0BSgoraRoV4J4d2NxRw9LA0RYVtJNUcMTqWitoGymgbe3VhMaVU9px01iMFpCZRU1VOwp5LYGGHaqEwS4nw8uWwrFx4zjFifsHj1bmoamshK9nPcmGyGpCegquRvKaW+MUCi30dJZT2NgQBjc1PISvZTWt1AQlwMmUl+lm0qZt2uSibnpbOvpoGsZD/DMhJ5a/1eZo7JZGRWMv7YA6tisqBgjDGmmY2SaowxZr9ZUDDGGNPMgoIxxphmFhSMMcY0s6BgjDGmWUSDgojMEpF1IlIgInPDLI8Xkb97y5eJyOhI5scYY0znIhYURMQHPACcCxwNXCEiR7dJ9jWgVFUPB+4B/jdS+THGGNO1SJYUZgIFqrpRVeuBp4CL2qS5CHjM+/wscIbYI8mMMabPdG+kpgMzHNgWMl0IHNdRGlVtFJFyIBtoNaiNiMwB5niTlSKy7gDzlNN221HAjjk62DFHh4M55lHdSRTJoBDuir/t7dPdSYOqzgfmH3SGRPK7c0ffQGLHHB3smKNDbxxzJKuPCoERIdN5QNsn3jenEZFYIB0oiWCejDHGdCKSQWE5ME5ExoiIH7gcWNAmzQLgGu/zF4DX9FAbjMkYYwaQiFUfeW0E1wOLAB/wqKquEpE7gHxVXQA8AvxVRApwJYTLI5Ufz0FXQR2C7Jijgx1zdIj4MR9yo6QaY4yJHLuj2RhjTDMLCsYYY5pFTVDoasiNQ5WIjBCR10VkjYisEpHvevOzROTfIrLee8/05ouI3O/9HT4WkWl9ewQHRkR8IvKBiLzoTY/xhkpZ7w2d4vfmD4ihVEQkQ0SeFZG13nd9QhR8x//j/aZXisiTIpIwEL9nEXlURPaIyMqQefv93YrINV769SJyTbh9dUdUBIVuDrlxqGoEfqCq44HjgW97xzYXWKKq44Al3jS4v8E47zUHeLD3s9wjvgusCZn+X+Ae73hLcUOowMAZSuU+4BVVPQo4BnfsA/Y7FpHhwA3ADFWdiOuscjkD83v+MzCrzbz9+m5FJAu4HXeD8Ezg9mAg2W+qOuBfwAnAopDpecC8vs5XhI71n8BZwDpgqDdvKLDO+/wwcEVI+uZ0h8oLd8/LEuB04EXcTZB7gdi23zeu99sJ3udYL5309THs5/GmAZva5nuAf8fB0Q6yvO/tReCcgfo9A6OBlQf63QJXAA+HzG+Vbn9eUVFSIPyQG8P7KC8R4xWZpwLLgMGquhPAex/kJRsIf4t7gZuAgDedDZSpaqM3HXpMrYZSAYJDqRxKDgOKgD95VWZ/FJFkBvB3rKrbgV8DW4GduO9tBQP7ew61v99tj33n0RIUujWcxqFMRFKA54Dvqeq+zpKGmXfI/C1E5AJgj6quCJ0dJql2Y9mhIhaYBjyoqlOBKlqqE8I55I/Zq/q4CBgDDAOScVUnbQ2k77k7OjrOHjv+aAkK3Rly45AlInG4gPA3VX3em71bRIZ6y4cCe7z5h/rf4iRgtohsxo28ezqu5JDhDZUCrY9pIAylUggUquoyb/pZXJAYqN8xwJnAJlUtUtUG4HngRAb29xxqf7/bHvvOoyUodGfIjUOSiAjuzvA1qnp3yKLQIUSuwbU1BOd/2evFcDxQHiymHgpUdZ6q5qnqaNz3+JqqXgW8jhsqBdof7yE9lIqq7gK2iciR3qwzgNUM0O/YsxU4XkSSvN948JgH7Pfcxv5+t4uAs0Uk0ytlne3N23993cDSiw055wGfAhuAW/o6Pz14XJ/BFRM/Bj70Xufh6lOXAOu99ywvveB6Ym0APsH17ujz4zjAYz8VeNH7fBjwHlAAPAPEe/MTvOkCb/lhfZ3vAzzWKUC+9z3/A8gc6N8x8FNgLbAS+CsQPxC/Z+BJXLtJA+6K/2sH8t0CX/WOvwC49kDzY8NcGGOMaRYt1UfGGGO6wYKCMcaYZhYUjDHGNLOgYIwxppkFBWOMMc0sKBjTi0Tk1ODIrsb0RxYUjDHGNLOgYEwYInK1iLwnIh+KyMPe8xsqReQ3IvK+iCwRkVwv7RQRedcb3/6FkLHvDxeRxSLykbfOWG/zKSHPRvibd8euMf2CBQVj2hCR8cBlwEmqOgVoAq7CDcr2vqpOA97AjV8P8BfgR6o6GXeXaXD+34AHVPUY3Lg9waEmpgLfwz3b4zDceE7G9AuxXScxJuqcAUwHlnsX8Ym4AckCwN+9NI8Dz4tIOpChqm948x8DnhGRVGC4qr4AoKq1AN723lPVQm/6Q9xY+m9H/rCM6ZoFBWPaE+AxVZ3XaqbIrW3SdTZGTGdVQnUhn5uw/0PTj1j1kTHtLQG+ICKDoPl5uaNw/y/BETqvBN5W1XKgVEQ+683/EvCGumdaFIrI57xtxItIUq8ehTEHwK5QjGlDVVeLyI+BV0UkBjd65bdxD7eZICIrcE/2usxb5RrgIe+kvxG41pv/JeBhEbnD28YXe/EwjDkgNkqqMd0kIpWqmtLX+TAmkqz6yBhjTDMrKRhjjGlmJQVjjDHNLCgYY4xpZkHBGGNMMwsKxhhjmllQMMYY0+z/AzPdb51wfm1KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.history['loss'])\n",
    "plt.plot(train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) [781.38037627 777.96356681 783.53069614 783.95978458 791.14662736\n",
      " 803.36596461 803.94513478 799.24824469 798.45378062 798.525732\n",
      " 798.69100163 799.62576529 799.46177803 803.81199664 806.74995209\n",
      " 820.14866334 827.76285383 834.87086449 832.11521305 816.51730545]\n"
     ]
    }
   ],
   "source": [
    "# local data\n",
    "# model.load_weights('./model/LSTM_03_check_point/cp-{epoch:04d}.ckpt'.format(epoch=600))\n",
    "if local_norm_flag:\n",
    "    testing_data = open_data[-test_count-input_days:]\n",
    "    output_prices = []\n",
    "    for i in range(test_count):\n",
    "        sc = MinMaxScaler()\n",
    "        test = testing_data[i:i+input_days]\n",
    "        test = sc.getScalerData(test, offset=offset)\n",
    "        output = model.predict(np.append(np.expand_dims(test, axis=0), test_x[i:i+1, :, 1:2], axis=-1))\n",
    "        output_prices.append(sc.getInverseData(output[0][0]))\n",
    "else:\n",
    "    output = model.predict(test_input)\n",
    "    output_qute = 1 + open_sc.getInverseData(output)[-test_count:]\n",
    "    value_init = open_data[-test_count-1:-1]\n",
    "    output_prices = value_init * output_qute\n",
    "output_prices = np.asarray(output_prices)\n",
    "print(output_prices.shape, output_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(test_data_t[:, 0], color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(output_prices, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Time(days)')\n",
    "plt.ylabel('Real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248,) [314.7193744  313.45442601 315.93532314 ... 790.39947988 792.14086123\n",
      " 782.11357543]\n"
     ]
    }
   ],
   "source": [
    "# local data\n",
    "# model.load_weights('./model/LSTM_03_check_point/cp-{epoch:04d}.ckpt'.format(epoch=600))\n",
    "if local_norm_flag:\n",
    "    train_count = len(train_data_t) - input_days\n",
    "    testing_data = open_data[:-test_count]\n",
    "    output_prices = []\n",
    "    for i in range(train_count):\n",
    "        sc = MinMaxScaler()\n",
    "        test = testing_data[i:i+input_days]\n",
    "        test = sc.getScalerData(test, offset=offset)\n",
    "        output = model.predict(np.append(np.expand_dims(test, axis=0), train_x[i:i+1, :, 1:2], axis=-1))\n",
    "        output_prices.append(sc.getInverseData(output[0][0]))\n",
    "    output_prices = np.asarray(output_prices)\n",
    "    print(output_prices.shape, output_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "if local_norm_flag:\n",
    "    plt.plot(train_data_t[input_days:, 0], color = 'red', label = 'Real Google Stock Price')\n",
    "    plt.plot(output_prices, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "    plt.title('Prediction')\n",
    "    plt.xlabel('Time(days)')\n",
    "    plt.ylabel('Real')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlib]",
   "language": "python",
   "name": "conda-env-dlib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
